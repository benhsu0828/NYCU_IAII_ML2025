# NYCU-IAII-ML2025 - Classification

> ğŸ† åŸºæ–¼ ConvNeXt Tiny æ¶æ§‹ï¼Œåœ¨é©—è­‰é›†ä¸Šé”åˆ° **99.91%** çš„æº–ç¢ºç‡

## ğŸ“Š å°ˆæ¡ˆæ¦‚è¦½

| é …ç›® | æ•¸å€¼/æè¿° |
|------|-----------|
| **æœ€ä½³æº–ç¢ºç‡** | ğŸ¯ **99.91%** (ConvNeXt Tiny) |
| **æ¨¡å‹æ¶æ§‹** | ConvNeXt Tiny (Facebook AI Research 2022) |
| **ä»»å‹™é¡å‹** | 50é¡è§’è‰²åˆ†é¡ |
| **æ¨¡å‹å¤§å°** | 28.6M åƒæ•¸ |

### ğŸŒŸ å°ˆæ¡ˆç‰¹è‰²
- âœ… **é ˜å…ˆæ€§èƒ½**: 99.91% æº–ç¢ºç‡ï¼Œè¶…è¶Š EfficientNet ç­‰ä¸»æµæ¨¡å‹
- âœ… **æ¶æ§‹å…ˆé€²**: æ¡ç”¨ 2022 å¹´æœ€æ–°çš„ ConvNeXt æ¶æ§‹
- âœ… **å®Œæ•´å·¥å…·éˆ**: åŒ…å«è¨“ç·´ã€æ¨ç†ã€åˆ†æã€å¯è¦–åŒ–å®Œæ•´è§£æ±ºæ–¹æ¡ˆ
- âœ… **æ·±åº¦åˆ†æ**: æä¾›æ··æ·†çŸ©é™£ã€æ³¨æ„åŠ›ç†±åŠ›åœ–ã€é€šé“åˆ†æç­‰è©³ç´°è§£è®€

## ğŸ† æ¨¡å‹æ€§èƒ½

### è¨“ç·´çµæœ
| æ¨¡å‹ | æº–ç¢ºç‡ | æª”æ¡ˆåç¨± |
|------|--------|----------|
| ConvNeXt Tiny | **99.91%** | `convnext_tiny_epoch_013_acc_99.91.pth` |
| ConvNeXt Tiny | 99.90% | `convnext_tiny_epoch_015_acc_99.90.pth` |
| ConvNeXt Tiny | 99.89% | `convnext_tiny_epoch_010_acc_99.89.pth` |
| EfficientNet B3 | 99.9% | `best_efficientnet_b3_acc99.9.pth` |

### ğŸ¯ å°ˆæ¡ˆäº®é»
- âœ… **è¶…é«˜æº–ç¢ºç‡**: é©—è­‰é›†é”åˆ° 99.91%
- âœ… **æŠ—éæ“¬åˆ**: ConvNeXt æ¶æ§‹å¤©ç„¶å…·å‚™æŠ—éæ“¬åˆèƒ½åŠ›
- âœ… **å¤šæ¨¡å‹æ”¯æ´**: åŒæ™‚æä¾› ConvNeXtã€EfficientNetã€MemoryViT ç­‰é¸æ“‡
- âœ… **å®Œæ•´å·¥å…·éˆ**: åŒ…å«è¨“ç·´ã€æ¨ç†ã€åˆ†æã€å¯è¦–åŒ–å…¨å¥—å·¥å…·

### ï¿½ è©³ç´°åˆ†æå ±å‘Š
![Confusion Matrix](image/convnext_tiny_confusion_matrix.png)

**æ··æ·†çŸ©é™£åˆ†æçµæœ**:
- 50 å€‹è§’è‰²çš„åˆ†é¡æº–ç¢ºç‡å‡è¶…é 99%
- å°è§’ç·šå…ƒç´ çªå‡ºï¼Œè¡¨ç¤ºåˆ†é¡æº–ç¢º
- æ¥µå°‘çš„éŒ¯èª¤åˆ†é¡æ¡ˆä¾‹ï¼ˆè©³è¦‹ `convnext_tiny_classification_report.csv`ï¼‰
- å„é¡åˆ¥é–“çš„å€åˆ†åº¦å¾ˆé«˜

## ğŸ¨ æ¨¡å‹å¯è¦–åŒ–åˆ†æ

### ç¬¬ä¸€å±¤æ¬Šé‡ç‰¹å¾µ
![First Layer Weights](image/convnext_tiny_first_layer_weights.png)

ConvNeXt ç¬¬ä¸€å±¤å­¸ç¿’åˆ°çš„ç‰¹å¾µåŒ…æ‹¬ï¼š
- **é‚Šç·£æª¢æ¸¬å™¨**: ç”¨æ–¼è­˜åˆ¥å­—ç¬¦ç­†ç•«
- **æ–¹å‘æª¢æ¸¬å™¨**: è­˜åˆ¥ä¸åŒæ–¹å‘çš„ç·šæ¢
- **ç´‹ç†æª¢æ¸¬å™¨**: æ•æ‰å­—ç¬¦çš„ç´°ç¯€ç‰¹å¾µ

### ç‰¹å¾µåœ–éŸ¿æ‡‰
![Feature Maps](image/convnext_tiny_feature_maps.png)

ç‰¹å¾µåœ–é¡¯ç¤ºæ¨¡å‹å°è¼¸å…¥å­—ç¬¦çš„éŸ¿æ‡‰ï¼š
- ä¸åŒé€šé“å°ˆæ³¨æ–¼ä¸åŒçš„å­—ç¬¦ç‰¹å¾µ
- ç­†ç•«çµæ§‹å¾—åˆ°æœ‰æ•ˆæå–
- èƒŒæ™¯é›œè¨Šè¢«æˆåŠŸæŠ‘åˆ¶

### ğŸ”¥ æ³¨æ„åŠ›ç†±åŠ›åœ–
![Attention Heatmap](image/convnext_tiny_attention_heatmap.png)

æ³¨æ„åŠ›ç†±åŠ›åœ–æ­ç¤ºæ¨¡å‹çš„é—œæ³¨ç„¦é»ï¼š
- **ç´…è‰²å€åŸŸ**: æ¨¡å‹é«˜åº¦é—œæ³¨çš„å­—ç¬¦ç­†ç•«
- **è—è‰²å€åŸŸ**: èƒŒæ™¯æˆ–ä¸é‡è¦å€åŸŸ
- **é©—è­‰æ•ˆæœ**: æ¨¡å‹æˆåŠŸèšç„¦æ–¼å­—ç¬¦æœ¬èº«ï¼Œå¿½ç•¥èƒŒæ™¯é›œè¨Š

### ğŸ“Š é€šé“éŸ¿æ‡‰åˆ†æ
![Channel Analysis](image/convnext_tiny_channel_analysis.png)

é€šé“åˆ†æé¡¯ç¤ºå„ç‰¹å¾µé€šé“çš„éŸ¿æ‡‰æ¨¡å¼ï¼š
- **æœ€å¤§éŸ¿æ‡‰å€¼**: é¡¯ç¤ºå„é€šé“çš„æ¿€æ´»å¼·åº¦
- **å¹³å‡éŸ¿æ‡‰å€¼**: åæ˜ é€šé“çš„æ•´é«”è²¢ç»åº¦
- **æ­£å€¼æ¯”ä¾‹**: è¡¨ç¤ºé€šé“çš„æ¿€æ´»é »ç‡
- **ç™¼ç¾**: ConvNeXt çš„ä¸åŒé€šé“å°ˆç²¾æ–¼ä¸åŒé¡å‹çš„è¦–è¦ºç‰¹å¾µ

## ğŸš€ å¿«é€Ÿé–‹å§‹

### ç’°å¢ƒè¨­ç½®
```bash
# å‰µå»ºè™›æ“¬ç’°å¢ƒ
conda create -n convnext_classifier python=3.8 -y
conda activate convnext_classifier

# å®‰è£ä¾è³´
pip install requirements.txt
```

### è³‡æ–™è™•ç†

å…ˆä½¿ç”¨src/dataSplit.pyé€²è¡Œtrainå’Œvalçš„åˆ†å‰²
```bash
cd src
# å…ˆä½¿ç”¨src/dataSplit.pyé€²è¡Œtrainå’Œvalçš„åˆ†å‰²
python dataSplit.py

#é€²è¡Œè³‡æ–™å¢å¼·
python data_augmentation.py
```
### æ¨¡å‹è¨“ç·´

#### ğŸ“‹ å®Œæ•´è¨“ç·´æµç¨‹

æˆ‘å€‘çš„è¨“ç·´ç¨‹å¼ `EfficientNet_character_classifier.py` æ”¯æ´å¤šç¨®æ¨¡å‹æ¶æ§‹ï¼ŒåŒ…æ‹¬ EfficientNet å’Œ ConvNeXt ç³»åˆ—ã€‚ä»¥ä¸‹æ˜¯å®Œæ•´çš„è¨“ç·´æµç¨‹ï¼š

##### 1ï¸âƒ£ **å•Ÿå‹•è¨“ç·´ç¨‹å¼**
```bash
cd src
python EfficientNet_character_classifier.py
```

##### 2ï¸âƒ£ **æ¨¡å‹é¸æ“‡éšæ®µ**
ç¨‹å¼æœƒæä¾›ä»¥ä¸‹é¸é …ï¼š

```
ğŸ¯ é¸æ“‡ EfficientNet æ¨¡å‹:
ğŸš€ é€Ÿåº¦å„ªå…ˆ:
  1. efficientnet_b0 - æœ€å¿« (5.3Måƒæ•¸)
  2. efficientnet_b1 - å¾ˆå¿« (7.8Måƒæ•¸)
  3. efficientnet_b2 - å¿« (9.2Måƒæ•¸)

âš–ï¸ å¹³è¡¡é¸æ“‡:
  4. efficientnet_b3 - å¹³è¡¡ (12Måƒæ•¸) [ç•¶å‰ä½¿ç”¨]
  5. efficientnet_b4 - æ›´æº–ç¢º (19Måƒæ•¸)

ğŸ›¡ï¸ æŠ—éæ“¬åˆ (æ¨è–¦è§£æ±ºKaggleå•é¡Œ):
  6. efficientnetv2_s.in1k - V2å°ç‰ˆ (21Måƒæ•¸)
  7. efficientnetv2_m.in21k_ft_in1k - V2ä¸­ç‰ˆ (54Måƒæ•¸) â­æ¨è–¦

ğŸ† æ¥µè‡´æ€§èƒ½:
  8. efficientnet_b5 - é«˜æº–ç¢º (30Måƒæ•¸)
  9. convnext_tiny - ConvNeXt Tiny (28Måƒæ•¸) ğŸ”¥æ¨è–¦
  10. convnext_base - ConvNeXt Base (89Måƒæ•¸) ğŸ”¥æœ€å¼·
```

**æ¨è–¦é¸æ“‡**ï¼š
- **åˆå­¸è€…**ï¼šé¸æ“‡ 4 (efficientnet_b3) - å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºç‡
- **è§£æ±ºéæ“¬åˆ**ï¼šé¸æ“‡ 7 (efficientnetv2_m) - V2 æ¶æ§‹æŠ—éæ“¬åˆèƒ½åŠ›å¼·
- **è¿½æ±‚æ¥µè‡´**ï¼šé¸æ“‡ 9 (convnext_tiny) - æœ€æ–°æ¶æ§‹ï¼Œ99.91% æº–ç¢ºç‡

##### 3ï¸âƒ£ **æŠ—éæ“¬åˆæ¨¡å¼**
ç¨‹å¼æœƒè©¢å•æ˜¯å¦å•Ÿç”¨æŠ—éæ“¬åˆæ¨¡å¼ï¼š

```
ğŸ›¡ï¸ æ˜¯å¦å•Ÿç”¨æŠ—éæ“¬åˆæ¨¡å¼ï¼Ÿ(é©åˆè§£æ±ºKaggleæ¸¬è©¦é›†æº–ç¢ºç‡ä½çš„å•é¡Œ) (y/N):
```

**æŠ—éæ“¬åˆæ¨¡å¼ç‰¹é»**ï¼š
- ğŸ”§ **æé«˜ Dropout**: å¾ 0.2 å¢åŠ åˆ° 0.4
- ğŸ”§ **å¢å¼· Label Smoothing**: å¾ 0.1 å¢åŠ åˆ° 0.15
- ğŸ”§ **æ›´å¼·æ¬Šé‡è¡°æ¸›**: å¾ 0.01 å¢åŠ åˆ° 0.02
- ğŸ”§ **Drop Path æ­£å‰‡åŒ–**: å¢åŠ åˆ° 0.4

##### 4ï¸âƒ£ **è¨“ç·´æ¨¡å¼é¸æ“‡**
```
ğŸ”„ è¨“ç·´æ¨¡å¼é¸æ“‡:
1. å¾é ­é–‹å§‹è¨“ç·´ (é è¨­)
2. å¾æª¢æŸ¥é»ç¹¼çºŒè¨“ç·´
```

**æ–·é»çºŒè¨“åŠŸèƒ½**ï¼š
- è‡ªå‹•æœå°‹ç¾æœ‰çš„ `.pth` æª”æ¡ˆ
- æ¢å¾©è¨“ç·´é€²åº¦ã€å„ªåŒ–å™¨ç‹€æ…‹
- ä¿æŒæœ€ä½³æº–ç¢ºç‡è¨˜éŒ„

##### 5ï¸âƒ£ **è‡ªå‹•åŒ–é…ç½®**
ç¨‹å¼æœƒè‡ªå‹•é€²è¡Œä»¥ä¸‹é…ç½®ï¼š

**è³‡æ–™è·¯å¾‘æª¢æ¸¬**ï¼š
```
ğŸ“‚ ä½¿ç”¨è³‡æ–™: ğŸ¨ ä½¿ç”¨å¢å¼·è¨“ç·´è³‡æ–™ + é è™•ç†é©—è­‰è³‡æ–™
ğŸ“ è¨“ç·´è·¯å¾‘: Dataset/augmented/train
ğŸ“ é©—è­‰è·¯å¾‘: Dataset/preprocessed/val
```

**Batch Size å„ªåŒ–**ï¼š
```
âš™ï¸ å°‹æ‰¾æœ€ä½³ batch size (ç¯„åœ: 16-128)
   Batch 16: 45.2 åœ–ç‰‡/ç§’
   Batch 32: 52.1 åœ–ç‰‡/ç§’
   Batch 64: 48.3 åœ–ç‰‡/ç§’
   Batch 128: âŒ GPU è¨˜æ†¶é«”ä¸è¶³
âœ… é¸æ“‡ batch size: 32 (é€Ÿåº¦: 52.1 åœ–ç‰‡/ç§’)
```

##### 6ï¸âƒ£ **è¨“ç·´éç¨‹ç›£æ§**
```
ğŸ“Š è¨“ç·´è¨­å®š:
   Batch size: 32
   å­¸ç¿’ç‡: 3e-5
   è¨“ç·´è¼ªæ•¸: 30
   æ—©åœè€å¿ƒ: 10

Epoch [1/30] (45.2s)
  Train: Loss=2.1234, Acc=65.23%
  Val:   Loss=1.8765, Acc=72.45%
  LR: 3.00e-05
```

**è‡ªå‹•ä¿å­˜æ©Ÿåˆ¶**ï¼š
- ğŸ”„ **æª¢æŸ¥é»ä¿å­˜**: æ¯ 5 å€‹ epoch ä¿å­˜ä¸€æ¬¡
- ğŸ† **æœ€ä½³æ¨¡å‹ä¿å­˜**: é©—è­‰æº–ç¢ºç‡æå‡æ™‚è‡ªå‹•ä¿å­˜
- ğŸ“ **æª”æ¡ˆå‘½åæ ¼å¼**: `convnext_tiny_epoch_013_acc_99.91.pth`

##### 7ï¸âƒ£ **è¨“ç·´å®Œæˆ**
```
âœ… è¨“ç·´å®Œæˆï¼
ğŸ† æœ€ä½³é©—è­‰æº–ç¢ºç‡: 99.91%
ğŸ“ æœ€ä½³æ¨¡å‹å·²ä¿å­˜ç‚º: convnext_tiny_epoch_013_acc_99.91.pth
```

#### ğŸ¯ **è¨“ç·´æŠ€å·§èˆ‡å„ªåŒ–**

##### **è³‡æ–™å¢å¼·ç­–ç•¥**
```python
# è¨“ç·´æ™‚çš„è³‡æ–™å¢å¼·
transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),      # æ°´å¹³ç¿»è½‰
    transforms.RandomRotation(degrees=15),        # æ—‹è½‰ Â±15Â°
    transforms.ColorJitter(                       # é¡è‰²è®ŠåŒ–
        brightness=0.2, contrast=0.2, 
        saturation=0.2, hue=0.1
    ),
    transforms.RandomAffine(                      # ä»¿å°„è®Šæ›
        degrees=0, translate=(0.1, 0.1), 
        scale=(0.9, 1.1)
    ),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
```

##### **å­¸ç¿’ç‡èª¿åº¦**
```python
# ä½¿ç”¨ Cosine Annealing å­¸ç¿’ç‡èª¿åº¦
scheduler = optim.lr_scheduler.CosineAnnealingLR(
    optimizer, T_max=epochs, eta_min=lr/100
)
```

##### **æ¢¯åº¦è£å‰ª**
```python
# é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

#### ğŸ“Š **è¨“ç·´çµæœåˆ†æ**

å®Œæˆè¨“ç·´å¾Œï¼Œç¨‹å¼æœƒè‡ªå‹•ç”Ÿæˆï¼š

1. **è¨“ç·´æ­·å²åœ–è¡¨** - `{model_name}_training_history.png`
2. **æœ€ä½³æ¨¡å‹æª”æ¡ˆ** - `{model_name}_epoch_XXX_acc_XX.XX.pth`
3. **è¨“ç·´æ—¥èªŒ** - æ§åˆ¶å°è¼¸å‡ºå®Œæ•´è¨“ç·´éç¨‹

#### ğŸ”§ **è‡ªè¨‚è¨“ç·´åƒæ•¸**

å¦‚éœ€è‡ªè¨‚è¨“ç·´åƒæ•¸ï¼Œå¯ç›´æ¥ä¿®æ”¹ç¨‹å¼ä¸­çš„è¨­å®šï¼š

```python
# åœ¨ EfficientNet_character_classifier.py çš„ main() å‡½æ•¸ä¸­
epochs = int(input("ç¸½è¨“ç·´è¼ªæ•¸ (é è¨­ 30): ") or "30")
lr = float(input("å­¸ç¿’ç‡ (é è¨­ 3e-5): ") or "3e-5")
```

æˆ–ç›´æ¥åœ¨ç¨‹å¼ç¢¼ä¸­ä¿®æ”¹ï¼š
```python
CONFIG = {
    'model_name': 'convnext_tiny',
    'num_epochs': 15,
    'batch_size': 32,
    'learning_rate': 0.001,
    'anti_overfitting': True,
    'patience': 10,
    'weight_decay': 0.02
}
```

### ğŸ’¡ ä½¿ç”¨æœ€ä½³æ¨¡å‹é€²è¡Œæ¨ç†

python Ass2-Classification\src\EfficientNet_inference.py
#### æ–¹æ³• 1: ä½¿ç”¨åˆ†é¡å™¨
```python
from EfficientNet_character_classifier import CharacterClassifier

# è¼‰å…¥æœ€ä½³ ConvNeXt æ¨¡å‹ (99.91% æº–ç¢ºç‡)
classifier = CharacterClassifier()
model_path = "src/convnext_tiny_epoch_013_acc_99.91.pth"
classifier.load_model(model_path)

# é æ¸¬å–®å¼µåœ–ç‰‡
result = classifier.predict_image("your_character_image.jpg")
print(f"é æ¸¬çµæœ: {result['class_name']} (ä¿¡å¿ƒåº¦: {result['confidence']:.4f})")
```

#### æ–¹æ³• 2: ä½¿ç”¨æ¨ç†ç¨‹å¼
```python
from model_inference import ModelInference

# åˆå§‹åŒ–æ¨ç†å™¨
inferencer = ModelInference("src/convnext_tiny_epoch_013_acc_99.91.pth")

# æ‰¹é‡è™•ç†
results = inferencer.predict_batch("test_images_folder/")
for image_name, prediction in results.items():
    print(f"{image_name}: {prediction}")
```

### ğŸ“Š æ¨¡å‹åˆ†æ (ä½¿ç”¨ç¾æœ‰çµæœ)

æˆ‘å€‘å·²ç¶“ç‚ºæœ€ä½³æ¨¡å‹ç”Ÿæˆäº†å®Œæ•´çš„åˆ†æå ±å‘Šï¼š

```bash
# æŸ¥çœ‹æ··æ·†çŸ©é™£ (å·²ç”Ÿæˆ)
# æª”æ¡ˆ: image/convnext_tiny_confusion_matrix.png

# æŸ¥çœ‹åˆ†é¡å ±å‘Š (å·²ç”Ÿæˆ)  
# æª”æ¡ˆ: src/convnext_tiny_classification_report.csv

# æŸ¥çœ‹æ¯é¡åˆ¥æº–ç¢ºç‡ (å·²ç”Ÿæˆ)
# æª”æ¡ˆ: src/convnext_tiny_per_class_accuracy.csv

# æŸ¥çœ‹é€šé“åˆ†æ (å·²ç”Ÿæˆ)
# æª”æ¡ˆ: src/convnext_tiny_channel_analysis.csv
```

## ğŸ“Š æ¨¡å‹åˆ†æå·¥å…·

### 1. æ··æ·†çŸ©é™£åˆ†æ
```bash
python model_confusion_matrix_analyzer.py
```
- ç”Ÿæˆè©³ç´°çš„æ··æ·†çŸ©é™£
- æ¯é¡åˆ¥æº–ç¢ºç‡çµ±è¨ˆ
- éŒ¯èª¤åˆ†é¡æ¨£æœ¬åˆ†æ

### 2. ç¬¬ä¸€å±¤æ¬Šé‡å¯è¦–åŒ–
```bash
python model_first_layer_visualizer.py
```
- æ¬Šé‡è¦–è¦ºåŒ–
- ç‰¹å¾µåœ–åˆ†æ
- æ³¨æ„åŠ›ç†±åŠ›åœ–
- é€šé“éŸ¿æ‡‰åˆ†æ

### 3. æ¨¡å‹æ¯”è¼ƒ
```bash
python performance_comparison.py
```

## ğŸ“ å°ˆæ¡ˆçµæ§‹

```
ğŸ“¦ ConvNeXt å­—ç¬¦åˆ†é¡å°ˆæ¡ˆ
â”œâ”€â”€ ğŸ“„ README.md                           # æœ¬æª”æ¡ˆ
â”œâ”€â”€ ğŸ“ src/                                # æºä»£ç¢¼ç›®éŒ„
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¯ ä¸»è¦ç¨‹å¼
â”‚   â”‚   â”œâ”€â”€ EfficientNet_character_classifier.py  # ä¸»è¨“ç·´ç¨‹å¼ (æ”¯æ´ ConvNeXt)
â”‚   â”‚   â”œâ”€â”€ model_inference.py                    # æ¨¡å‹æ¨ç†ç¨‹å¼
â”‚   â”‚   â”œâ”€â”€ model_confusion_matrix_analyzer.py    # æ··æ·†çŸ©é™£åˆ†æå·¥å…·
â”‚   â”‚   â””â”€â”€ model_first_layer_visualizer.py       # æ¬Šé‡å¯è¦–åŒ–å·¥å…·
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ† æœ€ä½³æ¨¡å‹æª”æ¡ˆ
â”‚   â”‚   â”œâ”€â”€ convnext_tiny_epoch_013_acc_99.91.pth     # ğŸ¥‡ æœ€ä½³ ConvNeXt æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ convnext_tiny_epoch_015_acc_99.90.pth     # ğŸ¥ˆ æ¬¡ä½³ ConvNeXt æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ convnext_tiny_epoch_010_acc_99.89.pth     # ğŸ¥‰ ç¬¬ä¸‰ ConvNeXt æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ best_efficientnet_b3_acc99.9.pth          # æœ€ä½³ EfficientNet æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ best_efficientnet_b3_acc99.8.pth          # EfficientNet å‚™é¸
â”‚   â”‚   â””â”€â”€ character_class_mapping.json              # é¡åˆ¥æ˜ å°„æª”æ¡ˆ
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š åˆ†æçµæœæª”æ¡ˆ
â”‚   â”‚   â”œâ”€â”€ convnext_tiny_classification_report.csv   # è©³ç´°åˆ†é¡å ±å‘Š
â”‚   â”‚   â”œâ”€â”€ convnext_tiny_per_class_accuracy.csv      # æ¯é¡åˆ¥æº–ç¢ºç‡
â”‚   â”‚   â”œâ”€â”€ convnext_tiny_channel_analysis.csv        # é€šé“éŸ¿æ‡‰åˆ†æ
â”‚   â”‚   â”œâ”€â”€ convnext_tiny_attention_heatmap.png       # æ³¨æ„åŠ›ç†±åŠ›åœ–
â”‚   â”‚   â””â”€â”€ convnext_tiny_channel_analysis.png        # é€šé“åˆ†æåœ–è¡¨
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”§ å·¥å…·ç¨‹å¼
â”‚   â”‚   â”œâ”€â”€ data_augmentation.py         # è³‡æ–™å¢å¼·
â”‚   â”‚   â”œâ”€â”€ performance_comparison.py    # æ€§èƒ½æ¯”è¼ƒ
â”‚   â”‚   â”œâ”€â”€ MemoryViT_character_classifier.py  # MemoryViT å¯¦é©—
â”‚   â”‚   â”œâ”€â”€ ResNet_character_classifier.py     # ResNet æ¯”è¼ƒå¯¦é©—
â”‚   â”‚   â””â”€â”€ MobileNet_character_classifier.py  # è¼•é‡åŒ–æ¨¡å‹å¯¦é©—
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“š èªªæ˜æ–‡æª”
â”‚       â”œâ”€â”€ README_confusion_matrix.md        # æ··æ·†çŸ©é™£å·¥å…·èªªæ˜
â”‚       â””â”€â”€ README_first_layer_visualization.md  # å¯è¦–åŒ–å·¥å…·èªªæ˜
â”‚
â”œâ”€â”€ ğŸ“ image/                              # å¯è¦–åŒ–çµæœ
â”‚   â”œâ”€â”€ convnext_tiny_confusion_matrix.png    # æ··æ·†çŸ©é™£åœ–
â”‚   â”œâ”€â”€ convnext_tiny_feature_maps.png        # ç‰¹å¾µåœ–
â”‚   â””â”€â”€ convnext_tiny_first_layer_weights.png # ç¬¬ä¸€å±¤æ¬Šé‡
â”‚
â””â”€â”€ ğŸ“ Dataset/                           # è³‡æ–™é›† (æœªåŒ…å«åœ¨æ­¤å±•ç¤º)
    â”œâ”€â”€ preprocessed/
    â”‚   â”œâ”€â”€ train/     # è¨“ç·´è³‡æ–™
    â”‚   â”œâ”€â”€ val/       # é©—è­‰è³‡æ–™
    â”‚   â””â”€â”€ test/      # æ¸¬è©¦è³‡æ–™
    â””â”€â”€ raw/           # åŸå§‹è³‡æ–™
```

### ğŸ”‘ é—œéµæª”æ¡ˆèªªæ˜

| æª”æ¡ˆ | ç”¨é€” | é‡è¦æ€§ |
|------|------|--------|
| `convnext_tiny_epoch_013_acc_99.91.pth` | ğŸ¥‡ æœ€ä½³æ¨¡å‹ | â­â­â­â­â­ |
| `EfficientNet_character_classifier.py` | è¨“ç·´ç¨‹å¼ | â­â­â­â­â­ |
| `model_inference.py` | æ¨ç†ç¨‹å¼ | â­â­â­â­ |
| `convnext_tiny_classification_report.csv` | æ€§èƒ½åˆ†æ | â­â­â­â­ |
| `character_class_mapping.json` | é¡åˆ¥å°æ‡‰ | â­â­â­â­ |

## ğŸ¯ æ”¯æ´çš„æ¨¡å‹æ¶æ§‹

| æ¨¡å‹ | åƒæ•¸é‡ | ç‰¹è‰² | æ¨è–¦ç”¨é€” |
|------|--------|------|----------|
| **ConvNeXt Tiny** | 28.6M | æŠ—éæ“¬åˆã€é«˜ç²¾åº¦ | ğŸ† **æœ€ä½³é¸æ“‡** |
| EfficientNet B0-B7 | 5.3M-66M | é«˜æ•ˆç‡ã€å¯æ“´å±• | å¹³è¡¡æ€§èƒ½èˆ‡é€Ÿåº¦ |
| ResNet ç³»åˆ— | 11M-60M | ç©©å®šå¯é  | åŸºæº–æ¯”è¼ƒ |
| MobileNet V3 | 5.4M | è¼•é‡åŒ– | è¡Œå‹•è£ç½®éƒ¨ç½² |

## ğŸ“ˆ æ€§èƒ½å„ªåŒ–æŠ€å·§

### æŠ—éæ“¬åˆç­–ç•¥
```python
# åœ¨ EfficientNet_character_classifier.py ä¸­å•Ÿç”¨
anti_overfitting_config = {
    'dropout_rate': 0.4,        # æé«˜ dropout
    'label_smoothing': 0.15,    # æ¨™ç±¤å¹³æ»‘
    'weight_decay': 0.02,       # æ¬Šé‡è¡°æ¸›
    'use_v2_models': True       # ä½¿ç”¨ V2 æ¶æ§‹
}
```

### è³‡æ–™å¢å¼·
```python
# ä½¿ç”¨ data_augmentation.py
augmentation_config = {
    'rotation_range': 15,
    'brightness_range': 0.2,
    'contrast_range': 0.2,
    'noise_level': 0.1
}
```

## ğŸ” æ¨¡å‹è§£é‡‹æ€§

### ConvNeXt çš„å„ªå‹¢
1. **Layer Scale**: ç©©å®šæ·±å±¤ç¶²è·¯è¨“ç·´
2. **Stochastic Depth**: æ¸›å°‘éæ“¬åˆ
3. **GELU æ¿€æ´»å‡½æ•¸**: æ›´å¥½çš„æ¢¯åº¦æµå‹•
4. **æ·±åº¦å¯åˆ†é›¢å·ç©**: æ•ˆç‡èˆ‡ç²¾åº¦å¹³è¡¡

### æ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æ
- æ¨¡å‹å°ˆæ³¨æ–¼å­—ç¬¦çš„ç­†ç•«ç‰¹å¾µ
- æœ‰æ•ˆå¿½ç•¥èƒŒæ™¯é›œè¨Š
- å°å­—ç¬¦çµæ§‹æœ‰è‰¯å¥½çš„ç†è§£èƒ½åŠ›

## ğŸ› ï¸ ç–‘é›£æ’è§£

### å¸¸è¦‹å•é¡Œ
1. **CUDA è¨˜æ†¶é«”ä¸è¶³**
   ```python
   # æ¸›å°‘ batch_size
   batch_size = 16  # åŸæœ¬ 32
   ```

2. **æ¨¡å‹è¼‰å…¥å¤±æ•—**
   ```python
   # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆè·¯å¾‘
   model_path = "src/convnext_tiny_epoch_013_acc_99.91.pth"
   ```

3. **æ¨ç†é€Ÿåº¦æ…¢**
   ```python
   # ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
   model_name = 'efficientnet_b0'  # æ›¿ä»£ convnext_tiny
   ```

## ğŸ“š åƒè€ƒæ–‡ç»

- [ConvNeXt: A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)
- [timm: PyTorch Image Models](https://github.com/rwightman/pytorch-image-models)

## ğŸ¤ è²¢ç»

æ­¡è¿æäº¤ Issues å’Œ Pull Requests ä¾†æ”¹é€²é€™å€‹å°ˆæ¡ˆï¼

## ğŸ“„ æˆæ¬Š

æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Šæ¢æ¬¾ã€‚