#!/usr/bin/env python3
"""
ğŸ”® Mac EfficientNet æ¨ç†å·¥å…· - ç°¡åŒ–ç‰ˆæœ¬

ç´” Python å¯¦ç¾ï¼Œä¸ä¾è³´é¡å¤–å¥—ä»¶ã€‚
é©åˆå¿«é€Ÿæ¸¬è©¦ç›®éŒ„çµæ§‹å’Œè¼¸å‡ºæ ¼å¼ã€‚
"""

import os
import glob
import csv
import random

# æ¨¡æ“¬çš„è¾›æ™®æ£®å®¶åº­è§’è‰²é¡åˆ¥
SIMPSON_CHARACTERS = [
    "abraham_grampa_simpson",
    "agnes_skinner", 
    "apu_nahasapeemapetilon",
    "barney_gumble",
    "bart_simpson",
    "brandine_spuckler",
    "carl_carlson",
    "charles_montgomery_burns",
    "chief_wiggum",
    "cletus_spuckler",
    "comic_book_guy",
    "disco_stu",
    "dolph_starbeam",
    "duff_man",
    "edna_krabappel",
    "fat_tony",
    "gary_chalmers",
    "gil",
    "groundskeeper_willie",
    "homer_simpson",
    "jimbo_jones",
    "kearney_zzyzwicz",
    "kent_brockman",
    "krusty_the_clown",
    "lenny_leonard",
    "lionel_hutz",
    "lisa_simpson",
    "lunchlady_doris",
    "maggie_simpson",
    "marge_simpson",
    "martin_prince",
    "mayor_quimby",
    "milhouse_van_houten",
    "miss_hoover",
    "moe_szyslak",
    "ned_flanders",
    "nelson_muntz",
    "otto_mann",
    "patty_bouvier",
    "principal_skinner",
    "professor_john_frink",
    "rainier_wolfcastle",
    "ralph_wiggum",
    "selma_bouvier",
    "sideshow_bob",
    "sideshow_mel",
    "snake_jailbird",
    "timothy_lovejoy",
    "troy_mclure",
    "waylon_smithers"
]

def predict_test_dataset_simple(test_dir="Dataset/test", output_file="predictions.csv"):
    """
    ç°¡åŒ–ç‰ˆæœ¬çš„æ¸¬è©¦è³‡æ–™é›†é æ¸¬ï¼ˆä½¿ç”¨æ¨¡æ“¬é æ¸¬ï¼‰
    
    Args:
        test_dir: æ¸¬è©¦åœ–ç‰‡ç›®éŒ„
        output_file: è¼¸å‡º CSV æª”æ¡ˆåç¨±
        
    Returns:
        list: é æ¸¬çµæœåˆ—è¡¨
    """
    print(f"ğŸ­ Mac EfficientNet æ¨ç†å·¥å…· - ç°¡åŒ–ç‰ˆæœ¬")
    print(f"ğŸ“ è™•ç†æ¸¬è©¦è³‡æ–™é›†: {test_dir}")
    
    # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif', '*.webp']
    
    # æ”¶é›†æ‰€æœ‰åœ–ç‰‡è·¯å¾‘
    image_paths = []
    for ext in image_extensions:
        pattern = os.path.join(test_dir, ext)
        image_paths.extend(glob.glob(pattern))
    
    # æŒ‰æª”åæ•¸å­—æ’åº
    def sort_key(path):
        filename = os.path.basename(path)
        try:
            number = int(filename.split('.')[0])
            return number
        except:
            return 0
    
    image_paths.sort(key=sort_key)
    
    if not image_paths:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡ï¼")
        return None
    
    print(f"ğŸ” æ‰¾åˆ° {len(image_paths)} å¼µåœ–ç‰‡")
    
    # è¨­å®šéš¨æ©Ÿç¨®å­ä»¥ä¾¿é‡ç¾çµæœ
    random.seed(42)
    
    # æº–å‚™çµæœåˆ—è¡¨
    results = []
    
    # æ¨¡æ“¬é æ¸¬
    print("ğŸ² é–‹å§‹æ¨¡æ“¬æ¨ç†...")
    total = len(image_paths)
    
    for i, image_path in enumerate(image_paths):
        filename = os.path.basename(image_path)
        
        # æ¨¡æ“¬é æ¸¬ï¼ˆéš¨æ©Ÿé¸æ“‡è§’è‰²ï¼‰
        predicted_class = random.choice(SIMPSON_CHARACTERS)
        
        results.append({
            'filename': filename,
            'prediction': predicted_class
        })
        
        # é¡¯ç¤ºé€²åº¦
        if (i + 1) % 1000 == 0 or (i + 1) == total:
            progress = (i + 1) / total * 100
            print(f"   é€²åº¦: {i+1}/{total} ({progress:.1f}%)")
    
    # ä¿å­˜ CSV
    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['filename', 'prediction'])  # æ¨™é¡Œåˆ—
        
        for result in results:
            writer.writerow([result['filename'], result['prediction']])
    
    print(f"ğŸ’¾ é æ¸¬çµæœå·²ä¿å­˜è‡³: {output_file}")
    
    # çµ±è¨ˆé æ¸¬é¡åˆ¥åˆ†å¸ƒ
    prediction_counts = {}
    for result in results:
        pred = result['prediction']
        prediction_counts[pred] = prediction_counts.get(pred, 0) + 1
    
    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
    print(f"\nğŸ“Š é æ¸¬çµ±è¨ˆ:")
    print(f"   ç¸½åœ–ç‰‡æ•¸: {len(results)}")
    print(f"   é æ¸¬é¡åˆ¥åˆ†å¸ƒ (å‰10å):")
    
    # æŒ‰æ•¸é‡æ’åºä¸¦é¡¯ç¤ºå‰10å
    sorted_counts = sorted(prediction_counts.items(), key=lambda x: x[1], reverse=True)
    for i, (class_name, count) in enumerate(sorted_counts[:10]):
        print(f"     {class_name}: {count}")
    
    # é¡¯ç¤ºå‰å¹¾å€‹çµæœ
    print(f"\nğŸ“‹ å‰ 10 å€‹é æ¸¬çµæœ:")
    print(f"{'æª”å':<15} {'é æ¸¬çµæœ'}")
    print("-" * 50)
    for i in range(min(10, len(results))):
        result = results[i]
        print(f"{result['filename']:<15} {result['prediction']}")
    
    return results

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ Mac EfficientNet æ¨ç†å·¥å…· - ç°¡åŒ–ç‰ˆæœ¬")
    print("=" * 50)
    print("âš ï¸  æ³¨æ„: é€™æ˜¯ç°¡åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨æ¨¡æ“¬é æ¸¬çµæœ")
    print("ğŸ“ ä¸éœ€è¦å®‰è£é¡å¤–å¥—ä»¶ï¼Œç´” Python å¯¦ç¾")
    print("ğŸ¯ è¼¸å‡ºæ ¼å¼: CSV (æª”å, é æ¸¬çµæœ)")
    print("")
    
    # è¨­å®šæ¸¬è©¦ç›®éŒ„
    test_dir = input("æ¸¬è©¦åœ–ç‰‡ç›®éŒ„ (é è¨­: Dataset/test): ").strip()
    if not test_dir:
        test_dir = "Dataset/test"
    
    # æª¢æŸ¥æ¸¬è©¦ç›®éŒ„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_dir):
        print(f"âŒ æ¸¬è©¦ç›®éŒ„ä¸å­˜åœ¨: {test_dir}")
        
        # æä¾›å»ºè­°
        current_dir = os.getcwd()
        print(f"ğŸ“ ç›®å‰å·¥ä½œç›®éŒ„: {current_dir}")
        
        # å°‹æ‰¾å¯èƒ½çš„æ¸¬è©¦ç›®éŒ„
        possible_dirs = [
            "Dataset/test",
            "../Dataset/test", 
            "Ass2-Classification/Dataset/test"
        ]
        
        print("ğŸ” å»ºè­°çš„æ¸¬è©¦ç›®éŒ„:")
        for dir_path in possible_dirs:
            if os.path.exists(dir_path):
                print(f"   âœ… {dir_path}")
            else:
                print(f"   âŒ {dir_path}")
        
        return 1
    
    # è¨­å®šè¼¸å‡ºæª”æ¡ˆ
    output_file = input("è¼¸å‡ºæª”æ¡ˆåç¨± (é è¨­: predictions_simple.csv): ").strip()
    if not output_file:
        output_file = "predictions_simple.csv"
    
    # åŸ·è¡Œç°¡åŒ–æ¨ç†
    try:
        print(f"\nğŸš€ é–‹å§‹ç°¡åŒ–æ¨ç†...")
        results = predict_test_dataset_simple(test_dir, output_file)
        
        if results is not None:
            print(f"\nğŸ‰ ç°¡åŒ–æ¨ç†å®Œæˆï¼")
            print(f"ğŸ“„ çµæœå·²ä¿å­˜è‡³: {output_file}")
            print(f"ğŸ”¢ å…±è™•ç† {len(results)} å¼µåœ–ç‰‡")
            
            # æç¤ºå¦‚ä½•ä½¿ç”¨å¯¦éš›æ¨¡å‹
            print(f"\nğŸ’¡ å‡ç´šåˆ°å®Œæ•´ç‰ˆçš„æ­¥é©Ÿ:")
            print(f"   1. å®‰è£ä¾è³´: pip install -r requirements.txt")
            print(f"   2. å–å¾—è¨“ç·´å¥½çš„ .pth æ¨¡å‹æª”æ¡ˆ") 
            print(f"   3. ä½¿ç”¨å®Œæ•´ç‰ˆ: python src/mac_inference.py --model your_model.pth")
            
            # æç¤ºæŸ¥çœ‹çµæœ
            print(f"\nğŸ“– æŸ¥çœ‹çµæœ:")
            print(f"   cat {output_file}")
            print(f"   head -20 {output_file}")
            
        else:
            print("âŒ ç°¡åŒ–æ¨ç†å¤±æ•—ï¼")
            return 1
            
    except Exception as e:
        print(f"âŒ æ¨ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
