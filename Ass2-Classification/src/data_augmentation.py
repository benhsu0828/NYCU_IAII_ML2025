#!/usr/bin/env python
"""
è³‡æ–™å¢å¼·è…³æœ¬ - é‡å°é è™•ç†çš„è¾›æ™®æ£®è§’è‰²è³‡æ–™
çµåˆ data_aggV1.py å’Œ data_aggV2.py çš„å¢å¼·æ–¹æ³•
"""

import os
import random
import shutil
from PIL import Image, UnidentifiedImageError
import torch
import torchvision.transforms.v2 as T
from pathlib import Path
import argparse
from tqdm import tqdm
import platform

def get_default_paths():
    """æ ¹æ“šé‹è¡Œç’°å¢ƒè‡ªå‹•é¸æ“‡é è¨­è·¯å¾‘"""
    
    # æª¢æ¸¬æ˜¯å¦åœ¨ WSL ç’°å¢ƒä¸­
    is_wsl = "microsoft" in platform.uname().release.lower() or "WSL" in os.environ.get("WSL_DISTRO_NAME", "")
    
    if is_wsl:
        # WSL è·¯å¾‘æ ¼å¼
        base_path = "/mnt/e/NYCU/NYCU_IAII_ML2025/Ass2-Classification"
        input_dir = f"{base_path}/Dataset/preprocessed/train"
        output_dir = f"{base_path}/Dataset/augmented/train"
        backgrounds_dir = f"{base_path}/backgrounds"  # DTD è³‡æ–™é›†æ ¹ç›®éŒ„
    else:
        # Windows è·¯å¾‘æ ¼å¼
        input_dir = "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/preprocessed/train"
        output_dir = "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/augmented/train"
        backgrounds_dir = "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/backgrounds"  # DTD è³‡æ–™é›†æ ¹ç›®éŒ„
    
    return input_dir, output_dir, backgrounds_dir

# ===== è‡ªå®šç¾©å™ªè²å¢å¼·é¡åˆ¥ (ä¾†è‡ª data_aggV1.py) =====

class AddGaussianNoise(object):
    """æ·»åŠ é«˜æ–¯å™ªè²"""
    def __init__(self, mean=0., std=1.):
        self.std = std
        self.mean = mean

    def __call__(self, tensor):
        return tensor + torch.randn(tensor.size()) * self.std + self.mean

class AddSpeckleNoise(object):
    """æ·»åŠ æ•£æ–‘å™ªè²"""
    def __init__(self, noise_level=0.1):
        self.noise_level = noise_level

    def __call__(self, tensor):
        noise = torch.randn_like(tensor) * self.noise_level
        noisy_tensor = tensor * (1 + noise)
        return torch.clamp(noisy_tensor, 0, 1)

class AddPoissonNoise(object):
    """æ·»åŠ æ³Šæ¾å™ªè²"""
    def __init__(self, lam=1.0):
        self.lam = lam

    def __call__(self, tensor):
        noise = torch.poisson(self.lam * torch.ones(tensor.shape))
        noisy_tensor = tensor + noise / 255.0
        return torch.clamp(noisy_tensor, 0, 1)

class AddSaltPepperNoise(object):
    """æ·»åŠ æ¤’é¹½å™ªè² (èˆ‡ä½ çš„ data_aggV1.py å®Œå…¨ä¸€è‡´)"""
    def __init__(self, salt_prob=0.05, pepper_prob=0.05):
        self.salt_prob = salt_prob
        self.pepper_prob = pepper_prob

    def __call__(self, tensor):
        noise = torch.rand(tensor.size())
        tensor = tensor.clone()  # é˜²æ­¢ä¿®æ”¹åŸå§‹ tensor
        tensor[(noise < self.salt_prob)] = 1  # Salt noise: setting some pixels to 1
        tensor[(noise > 1 - self.pepper_prob)] = 0  # Pepper noise: setting some pixels to 0
        return tensor

# ===== è³‡æ–™å¢å¼·ç­–ç•¥å®šç¾© =====

def get_augmentation_transforms(device='cpu'):
    """
    å®šç¾©è³‡æ–™å¢å¼·è®Šæ› (æ”¯æ´ GPU åŠ é€Ÿ)
    
    Args:
        device: 'cuda' æˆ– 'cpu'
    """
    transform = T.Compose([
        T.ToTensor(),  # Convert PIL image to tensor

        T.RandomApply([T.RandomHorizontalFlip()], p=0.1),
        T.RandomApply([T.RandomVerticalFlip()], p=0.1),
        T.RandomApply([T.RandomRotation(10)], p=0.1),

        T.RandomApply([T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)], p=0.1),
        T.RandomGrayscale(p=0.1),
        T.RandomInvert(p=0.1),
        T.RandomPosterize(bits=2, p=0.1),
        T.RandomApply([T.RandomSolarize(threshold=1.0)], p=0.05),
        T.RandomApply([T.RandomAdjustSharpness(sharpness_factor=2)], p=0.1),

        T.RandomApply([AddGaussianNoise(0., 0.05)], p=0.1),  # mean and std
        T.RandomApply([AddPoissonNoise(lam=0.1)], p=0.1),  # mean and std
        T.RandomApply([AddSpeckleNoise(noise_level=0.1)], p=0.1),
        T.RandomApply([AddSaltPepperNoise(salt_prob=0.05, pepper_prob=0.05)], p=0.1),

        T.RandomApply([T.RandomPerspective(distortion_scale=0.6, p=1.0)], p=0.1),
        T.RandomApply([T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))], p=0.1),
        T.RandomApply([T.ElasticTransform(alpha=250.0)], p=0.1),

        T.RandomApply([T.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.))], p=0.1),

        T.RandomApply([AddGaussianNoise(0., 0.001)], p=1.0),  # mean and std
        T.ToPILImage()  # Convert tensor back to PIL image for saving
    ])
    
    return transform

def create_background_composite(foreground_img, background_img):
    """
    å‰µå»ºèƒŒæ™¯åˆæˆåœ–ç‰‡ (å®Œå…¨ä½¿ç”¨ä½ çš„ data_aggV2.py çš„é‚è¼¯)
    
    Args:
        foreground_img: PIL Imageï¼Œå‰æ™¯åœ–ç‰‡
        background_img: PIL Imageï¼ŒèƒŒæ™¯åœ–ç‰‡
    
    Returns:
        PIL Image: åˆæˆå¾Œçš„åœ–ç‰‡
    """
    # è½‰æ›ç‚º RGBA (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    img = foreground_img.convert("RGBA")

    # å‰µå»ºé®ç½© (å®Œå…¨è¤‡è£½ä½ çš„é‚è¼¯)
    mask = Image.new("L", img.size, 0)
    for x in range(img.width):
        for y in range(img.height):
            r, g, b, a = img.getpixel((x, y))
            if (r < 20 and g < 20 and b < 20) or (r > 235 and g > 235 and b > 235):
                mask.putpixel((x, y), 0)
            else:
                mask.putpixel((x, y), 255)

    # èƒŒæ™¯è™•ç† (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    background_image = background_img.convert("RGBA")

    # æ·»åŠ éš¨æ©Ÿé‚Šè· (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    padding_x = random.randint(10, 30)
    padding_y = random.randint(10, 30)
    new_size = (img.width + 2 * padding_x, img.height + 2 * padding_y)

    # èª¿æ•´èƒŒæ™¯å°ºå¯¸ (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    background_image = background_image.resize(new_size)

    # åˆæˆåœ–ç‰‡ (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    paste_position = (padding_x, padding_y)
    background_image.paste(img, paste_position, mask)

    # è¿”å› RGB æ ¼å¼
    return background_image.convert("RGB")

def load_background_images(backgrounds_dir, max_per_category=10, total_limit=200):
    """
    è¼‰å…¥ DTD (Describable Textures Dataset) èƒŒæ™¯åœ–ç‰‡
    
    Args:
        backgrounds_dir: èƒŒæ™¯åœ–ç‰‡æ ¹ç›®éŒ„ (æ‡‰è©²åŒ…å« images/ å­ç›®éŒ„)
        max_per_category: æ¯å€‹ç´‹ç†é¡åˆ¥æœ€å¤šè¼‰å…¥å¤šå°‘å¼µåœ–ç‰‡
        total_limit: ç¸½å…±æœ€å¤šè¼‰å…¥å¤šå°‘å¼µåœ–ç‰‡
    
    Returns:
        list: èƒŒæ™¯åœ–ç‰‡åˆ—è¡¨ (PIL Image ç‰©ä»¶)
    """
    if not os.path.exists(backgrounds_dir):
        print(f"âš ï¸  èƒŒæ™¯è³‡æ–™å¤¾ä¸å­˜åœ¨: {backgrounds_dir}")
        return []
    
    # DTD è³‡æ–™é›†çš„åœ–ç‰‡é€šå¸¸åœ¨ backgrounds/images/ åº•ä¸‹
    images_dir = Path(backgrounds_dir) / "images"
    if not images_dir.exists():
        # å¦‚æœæ²’æœ‰ images å­ç›®éŒ„ï¼Œç›´æ¥æœå°‹ç•¶å‰ç›®éŒ„
        images_dir = Path(backgrounds_dir)
        print(f"ğŸ“ åœ¨æ ¹ç›®éŒ„æœå°‹èƒŒæ™¯åœ–ç‰‡: {images_dir}")
    else:
        print(f"ğŸ“ åœ¨ DTD images ç›®éŒ„æœå°‹èƒŒæ™¯åœ–ç‰‡: {images_dir}")
    
    # æ”¶é›†æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
    all_background_files = []
    category_counts = {}
    
    # éè¿´æœå°‹æ‰€æœ‰å­ç›®éŒ„ä¸­çš„åœ–ç‰‡
    for category_dir in images_dir.iterdir():
        if category_dir.is_dir():
            category_name = category_dir.name
            category_files = []
            
            # æœå°‹è©²é¡åˆ¥ç›®éŒ„ä¸‹çš„æ‰€æœ‰åœ–ç‰‡
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.JPG', '*.JPEG']:
                category_files.extend(list(category_dir.glob(ext)))
            
            # éš¨æ©Ÿé¸æ“‡è©²é¡åˆ¥çš„éƒ¨åˆ†åœ–ç‰‡
            if category_files:
                selected_count = min(len(category_files), max_per_category)
                selected_files = random.sample(category_files, selected_count)
                all_background_files.extend(selected_files)
                category_counts[category_name] = selected_count
                
                print(f"  ğŸ“‚ {category_name}: {selected_count}/{len(category_files)} å¼µåœ–ç‰‡")
    
    # å¦‚æœç¸½æ•¸è¶…éé™åˆ¶ï¼Œé€²è¡ŒäºŒæ¬¡éš¨æ©Ÿé¸æ“‡
    if len(all_background_files) > total_limit:
        print(f"ğŸ² åœ–ç‰‡ç¸½æ•¸ {len(all_background_files)} è¶…éé™åˆ¶ {total_limit}ï¼Œé€²è¡Œéš¨æ©Ÿé¸æ“‡...")
        all_background_files = random.sample(all_background_files, total_limit)
    
    # è¼‰å…¥èƒŒæ™¯åœ–ç‰‡
    backgrounds = []
    successful_loads = 0
    failed_loads = 0
    
    print(f"ğŸ”„ é–‹å§‹è¼‰å…¥ {len(all_background_files)} å¼µèƒŒæ™¯åœ–ç‰‡...")
    
    for bg_file in tqdm(all_background_files, desc="è¼‰å…¥èƒŒæ™¯åœ–ç‰‡"):
        try:
            bg_img = Image.open(bg_file).convert("RGB")
            
            # èª¿æ•´åœ–ç‰‡å°ºå¯¸ä»¥ç¯€çœè¨˜æ†¶é«” (å¦‚æœåœ–ç‰‡å¤ªå¤§)
            if max(bg_img.size) > 512:
                ratio = 512 / max(bg_img.size)
                new_size = (int(bg_img.size[0] * ratio), int(bg_img.size[1] * ratio))
                bg_img = bg_img.resize(new_size, Image.Resampling.LANCZOS)
            
            backgrounds.append(bg_img)
            successful_loads += 1
            
        except Exception as e:
            failed_loads += 1
            if failed_loads <= 5:  # åªé¡¯ç¤ºå‰5å€‹éŒ¯èª¤ï¼Œé¿å…åˆ·å±
                print(f"    âŒ ç„¡æ³•è¼‰å…¥èƒŒæ™¯åœ–ç‰‡ {bg_file.name}: {e}")
    
    print(f"\nâœ… èƒŒæ™¯åœ–ç‰‡è¼‰å…¥å®Œæˆ:")
    print(f"   ğŸ“Š æˆåŠŸè¼‰å…¥: {successful_loads} å¼µ")
    if failed_loads > 0:
        print(f"   âš ï¸  è¼‰å…¥å¤±æ•—: {failed_loads} å¼µ")
    
    print(f"   ğŸ¯ å„é¡åˆ¥åˆ†å¸ƒ:")
    for category, count in sorted(category_counts.items()):
        print(f"      {category}: {count} å¼µ")
    
    return backgrounds

def process_images_gpu_batch(image_files, output_class_dir, transform, backgrounds,
                           augment_per_image, use_background_aug, background_prob,
                           device, batch_size, class_name):
    """
    GPU æ‰¹é‡è™•ç†åœ–ç‰‡å¢å¼·
    
    Args:
        image_files: åœ–ç‰‡æª”æ¡ˆåˆ—è¡¨
        output_class_dir: è¼¸å‡ºé¡åˆ¥ç›®éŒ„
        transform: å¢å¼·è®Šæ›
        backgrounds: èƒŒæ™¯åœ–ç‰‡åˆ—è¡¨
        augment_per_image: æ¯å¼µåœ–ç‰‡å¢å¼·æ•¸é‡
        use_background_aug: æ˜¯å¦ä½¿ç”¨èƒŒæ™¯å¢å¼·
        background_prob: èƒŒæ™¯å¢å¼·æ©Ÿç‡
        device: GPU è¨­å‚™
        batch_size: æ‰¹é‡å¤§å°
        class_name: é¡åˆ¥åç¨±
    
    Returns:
        int: å¢å¼·åœ–ç‰‡æ•¸é‡
    """
    augmented_count = 0
    total_batches = (len(image_files) + batch_size - 1) // batch_size
    
    print(f"  ğŸš€ ä½¿ç”¨ GPU æ‰¹é‡è™•ç† (æ‰¹é‡å¤§å°: {batch_size})")
    
    for batch_idx in tqdm(range(total_batches), desc=f"  GPUå¢å¼· {class_name}"):
        try:
            # æº–å‚™ç•¶å‰æ‰¹é‡çš„åœ–ç‰‡
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(image_files))
            batch_files = image_files[start_idx:end_idx]
            
            # è¼‰å…¥æ‰¹é‡åœ–ç‰‡
            batch_images = []
            batch_info = []  # å„²å­˜æª”æ¡ˆè³‡è¨Š
            
            for img_file in batch_files:
                try:
                    img = Image.open(img_file).convert("RGB")
                    batch_images.append(img)
                    batch_info.append({
                        'file': img_file,
                        'name': img_file.stem,
                        'ext': img_file.suffix
                    })
                except Exception as e:
                    print(f"    âš ï¸ è¼‰å…¥å¤±æ•— {img_file.name}: {e}")
            
            if not batch_images:
                continue
            
            # è½‰æ›ç‚º tensor æ‰¹é‡
            tensors = []
            for img in batch_images:
                tensor = T.ToTensor()(img)
                tensors.append(tensor)
            
            # æ‰¹é‡ç§»åˆ° GPU
            batch_tensor = torch.stack(tensors).to(device)
            
            # å°æ¯å¼µåœ–ç‰‡ç”Ÿæˆå¤šå€‹å¢å¼·ç‰ˆæœ¬
            for aug_idx in range(augment_per_image):
                # æ‰¹é‡æ‡‰ç”¨è®Šæ› (åœ¨ GPU ä¸Š)
                if transform:
                    # å°æ¯å€‹ tensor å–®ç¨æ‡‰ç”¨è®Šæ› (å› ç‚ºéš¨æ©Ÿæ€§)
                    augmented_batch = []
                    for i in range(batch_tensor.size(0)):
                        single_tensor = batch_tensor[i].unsqueeze(0)
                        # ç§»å› CPU æš«æ™‚è™•ç† (å› ç‚ºæŸäº›è®Šæ›å¯èƒ½ä¸æ”¯æ´ GPU)
                        single_tensor_cpu = single_tensor.cpu()
                        single_pil = T.ToPILImage()(single_tensor_cpu[0])
                        
                        # æ‡‰ç”¨è®Šæ›
                        augmented_pil = transform(single_pil)
                        augmented_batch.append(augmented_pil)
                    
                    # è™•ç†èƒŒæ™¯åˆæˆå’Œä¿å­˜
                    for i, (augmented_img, info) in enumerate(zip(augmented_batch, batch_info)):
                        aug_methods = ["trans"]
                        current_img = augmented_img
                        
                        # èƒŒæ™¯å¢å¼·
                        if use_background_aug and backgrounds and random.random() < background_prob:
                            bg_img = random.choice(backgrounds)
                            current_img = create_background_composite(current_img, bg_img)
                            aug_methods.append("bg")
                        
                        # ä¿å­˜
                        methods_str = "_".join(aug_methods)
                        aug_filename = f"{info['name']}_aug_{methods_str}_{aug_idx:02d}{info['ext']}"
                        aug_path = output_class_dir / aug_filename
                        current_img.save(aug_path, quality=95)
                        augmented_count += 1
            
            # æ¸…ç† GPU è¨˜æ†¶é«”
            if device.type == 'cuda':
                torch.cuda.empty_cache()
        
        except Exception as e:
            print(f"    âŒ æ‰¹é‡è™•ç†éŒ¯èª¤ (batch {batch_idx}): {e}")
            # ç™¼ç”ŸéŒ¯èª¤æ™‚æ¸…ç† GPU è¨˜æ†¶é«”
            if device.type == 'cuda':
                torch.cuda.empty_cache()
    
    return augmented_count

def augment_dataset(input_dir, output_dir, backgrounds_dir=None, 
                   augment_per_image=2, use_background_aug=True, use_transform_aug=True,
                   max_bg_per_category=10, max_total_backgrounds=200, background_prob=0.3,
                   use_gpu=True, batch_size=32):
    """
    å°æ•´å€‹è³‡æ–™é›†é€²è¡Œå¢å¼· (æ”¯æ´ GPU åŠ é€Ÿ)
    
    Args:
        input_dir: è¼¸å…¥è³‡æ–™å¤¾ (åŒ…å«é¡åˆ¥å­è³‡æ–™å¤¾)
        output_dir: è¼¸å‡ºè³‡æ–™å¤¾
        backgrounds_dir: èƒŒæ™¯åœ–ç‰‡è³‡æ–™å¤¾ (DTD è³‡æ–™é›†æ ¹ç›®éŒ„)
        augment_per_image: æ¯å¼µåœ–ç‰‡ç”Ÿæˆçš„å¢å¼·ç‰ˆæœ¬æ•¸é‡
        use_background_aug: æ˜¯å¦ä½¿ç”¨èƒŒæ™¯åˆæˆå¢å¼·
        use_transform_aug: æ˜¯å¦ä½¿ç”¨è®Šæ›å¢å¼·
        max_bg_per_category: æ¯å€‹ç´‹ç†é¡åˆ¥æœ€å¤šè¼‰å…¥çš„èƒŒæ™¯åœ–ç‰‡æ•¸
        max_total_backgrounds: ç¸½å…±æœ€å¤šè¼‰å…¥çš„èƒŒæ™¯åœ–ç‰‡æ•¸
        background_prob: ä½¿ç”¨èƒŒæ™¯å¢å¼·çš„æ©Ÿç‡
        use_gpu: æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿ
        batch_size: GPU æ‰¹é‡è™•ç†å¤§å°
    """
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    # GPU è¨­å®š
    device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {device}")
    
    if device.type == 'cuda':
        print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        print(f"ğŸ“¦ æ‰¹é‡å¤§å°: {batch_size}")
    
    # å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾
    output_path.mkdir(parents=True, exist_ok=True)
    
    # è¼‰å…¥èƒŒæ™¯åœ–ç‰‡ (DTD è³‡æ–™é›†)
    backgrounds = []
    if use_background_aug and backgrounds_dir:
        backgrounds = load_background_images(
            backgrounds_dir, 
            max_per_category=max_bg_per_category,
            total_limit=max_total_backgrounds
        )
    
    # æº–å‚™å¢å¼·è®Šæ›
    transform = get_augmentation_transforms(device=device.type) if use_transform_aug else None
    
    # è™•ç†æ¯å€‹é¡åˆ¥
    class_dirs = [d for d in input_path.iterdir() if d.is_dir()]
    
    print(f"ğŸ¯ é–‹å§‹å¢å¼· {len(class_dirs)} å€‹é¡åˆ¥çš„è³‡æ–™...")
    
    for class_dir in class_dirs:
        class_name = class_dir.name
        print(f"\nğŸ“ è™•ç†é¡åˆ¥: {class_name}")
        
        # å‰µå»ºè¼¸å‡ºé¡åˆ¥è³‡æ–™å¤¾
        output_class_dir = output_path / class_name
        output_class_dir.mkdir(exist_ok=True)
        
        # ç²å–è©²é¡åˆ¥çš„æ‰€æœ‰åœ–ç‰‡
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(list(class_dir.glob(ext)))
        
        print(f"  ğŸ“· æ‰¾åˆ° {len(image_files)} å¼µåŸå§‹åœ–ç‰‡")
        
        # å…ˆè¤‡è£½åŸå§‹åœ–ç‰‡
        for img_file in image_files:
            shutil.copy2(img_file, output_class_dir / img_file.name)
        
        # ç”Ÿæˆå¢å¼·ç‰ˆæœ¬
        augmented_count = 0
        
        if device.type == 'cuda' and use_transform_aug and len(image_files) > batch_size:
            # GPU æ‰¹é‡è™•ç†æ¨¡å¼
            augmented_count = process_images_gpu_batch(
                image_files, output_class_dir, transform, backgrounds,
                augment_per_image, use_background_aug, background_prob,
                device, batch_size, class_name
            )
        else:
            # CPU å–®å¼µè™•ç†æ¨¡å¼ (åŸå§‹é‚è¼¯)
            for img_file in tqdm(image_files, desc=f"  å¢å¼· {class_name}"):
                try:
                    # è¼‰å…¥åŸå§‹åœ–ç‰‡
                    original_img = Image.open(img_file).convert("RGB")
                    base_name = img_file.stem
                    ext = img_file.suffix
                    
                    # ç”Ÿæˆå¤šå€‹å¢å¼·ç‰ˆæœ¬
                    for aug_idx in range(augment_per_image):
                        current_img = original_img.copy()
                        aug_methods = []
                        
                        # æ–¹æ³• 1: è®Šæ›å¢å¼· (ä½¿ç”¨ä½ çš„ data_aggV1.py è®Šæ›)
                        if use_transform_aug and transform:
                            current_img = transform(current_img)
                            aug_methods.append("trans")
                        
                        # æ–¹æ³• 2: èƒŒæ™¯åˆæˆå¢å¼· (ä½¿ç”¨ä½ çš„ data_aggV2.py é‚è¼¯)
                        if use_background_aug and backgrounds and random.random() < background_prob:
                            # éš¨æ©Ÿé¸æ“‡ä¸€å¼µèƒŒæ™¯åœ–ç‰‡
                            bg_img = random.choice(backgrounds)
                            current_img = create_background_composite(current_img, bg_img)
                            aug_methods.append("bg")
                        
                        # å¦‚æœæœ‰æ‡‰ç”¨å¢å¼·ï¼Œå‰‡ä¿å­˜
                        if aug_methods:
                            methods_str = "_".join(aug_methods)
                            aug_filename = f"{base_name}_aug_{methods_str}_{aug_idx:02d}{ext}"
                            aug_path = output_class_dir / aug_filename
                            current_img.save(aug_path, quality=95)
                            augmented_count += 1
                    
                except Exception as e:
                    print(f"    âŒ è™•ç† {img_file} æ™‚å‡ºéŒ¯: {e}")
        
        print(f"  âœ… å®Œæˆï¼Œç”Ÿæˆäº† {augmented_count} å¼µå¢å¼·åœ–ç‰‡")
        
        # çµ±è¨ˆè©²é¡åˆ¥çš„ç¸½åœ–ç‰‡æ•¸
        total_images = len(list(output_class_dir.glob("*")))
        print(f"  ğŸ“Š è©²é¡åˆ¥ç¸½åœ–ç‰‡æ•¸: {total_images}")

def main():
    """ä¸»å‡½æ•¸"""
    # ç²å–ç’°å¢ƒé©é…çš„é è¨­è·¯å¾‘
    default_input, default_output, default_backgrounds = get_default_paths()
    
    parser = argparse.ArgumentParser(description="è¾›æ™®æ£®è§’è‰²è³‡æ–™å¢å¼·")
    parser.add_argument("--input_dir", type=str, 
                       default=default_input,
                       help="è¼¸å…¥è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--output_dir", type=str,
                       default=default_output,
                       help="è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--backgrounds_dir", type=str,
                       default=default_backgrounds,
                       help="èƒŒæ™¯åœ–ç‰‡è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--augment_per_image", type=int, default=3,
                       help="æ¯å¼µåœ–ç‰‡ç”Ÿæˆçš„å¢å¼·ç‰ˆæœ¬æ•¸é‡")
    parser.add_argument("--no_background", action="store_true",
                       help="ä¸ä½¿ç”¨èƒŒæ™¯åˆæˆå¢å¼·")
    parser.add_argument("--no_transform", action="store_true", 
                       help="ä¸ä½¿ç”¨è®Šæ›å¢å¼·")
    parser.add_argument("--max_bg_per_category", type=int, default=10,
                       help="æ¯å€‹ç´‹ç†é¡åˆ¥æœ€å¤šè¼‰å…¥å¤šå°‘å¼µèƒŒæ™¯åœ–ç‰‡")
    parser.add_argument("--max_total_backgrounds", type=int, default=200,
                       help="ç¸½å…±æœ€å¤šè¼‰å…¥å¤šå°‘å¼µèƒŒæ™¯åœ–ç‰‡")
    parser.add_argument("--background_prob", type=float, default=0.4,
                       help="ä½¿ç”¨èƒŒæ™¯å¢å¼·çš„æ©Ÿç‡ (0.0-1.0)")
    parser.add_argument("--no_gpu", action="store_true",
                       help="ä¸ä½¿ç”¨ GPU åŠ é€Ÿï¼Œå¼·åˆ¶ä½¿ç”¨ CPU")
    parser.add_argument("--batch_size", type=int, default=32,
                       help="GPU æ‰¹é‡è™•ç†å¤§å° (åƒ…åœ¨ä½¿ç”¨ GPU æ™‚æœ‰æ•ˆ)")
    
    args = parser.parse_args()
    
    print("ğŸ¨ è¾›æ™®æ£®è§’è‰²è³‡æ–™å¢å¼·è…³æœ¬")
    print("=" * 50)
    print(f"ğŸ“‚ è¼¸å…¥è³‡æ–™å¤¾: {args.input_dir}")
    print(f"ğŸ“‚ è¼¸å‡ºè³‡æ–™å¤¾: {args.output_dir}")
    print(f"ğŸ–¼ï¸  èƒŒæ™¯è³‡æ–™å¤¾: {args.backgrounds_dir}")
    print(f"ğŸ”¢ æ¯å¼µåœ–ç‰‡å¢å¼·æ•¸é‡: {args.augment_per_image}")
    print(f"ğŸŒ… èƒŒæ™¯åˆæˆå¢å¼·: {'é—œé–‰' if args.no_background else 'é–‹å•Ÿ'}")
    print(f"ğŸ”„ è®Šæ›å¢å¼·: {'é—œé–‰' if args.no_transform else 'é–‹å•Ÿ'}")
    if not args.no_background:
        print(f"ğŸ“Š æ¯é¡åˆ¥æœ€å¤šèƒŒæ™¯æ•¸: {args.max_bg_per_category}")
        print(f"ğŸ“Š èƒŒæ™¯ç¸½æ•¸é™åˆ¶: {args.max_total_backgrounds}")
        print(f"ğŸ² èƒŒæ™¯ä½¿ç”¨æ©Ÿç‡: {args.background_prob:.1%}")
    
    # GPU è¨­å®šè³‡è¨Š
    use_gpu = not args.no_gpu and torch.cuda.is_available()
    print(f"ğŸš€ GPU åŠ é€Ÿ: {'é–‹å•Ÿ' if use_gpu else 'é—œé–‰'}")
    if use_gpu:
        print(f"ğŸ“¦ GPU æ‰¹é‡å¤§å°: {args.batch_size}")
    
    # æª¢æŸ¥è¼¸å…¥è³‡æ–™å¤¾
    if not os.path.exists(args.input_dir):
        print(f"âŒ è¼¸å…¥è³‡æ–™å¤¾ä¸å­˜åœ¨: {args.input_dir}")
        return
    
    # é–‹å§‹å¢å¼·
    augment_dataset(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        backgrounds_dir=args.backgrounds_dir if not args.no_background else None,
        augment_per_image=args.augment_per_image,
        use_background_aug=not args.no_background,
        use_transform_aug=not args.no_transform,
        max_bg_per_category=args.max_bg_per_category,
        max_total_backgrounds=args.max_total_backgrounds,
        background_prob=args.background_prob,
        use_gpu=use_gpu,
        batch_size=args.batch_size
    )
    
    print(f"\nâœ… è³‡æ–™å¢å¼·å®Œæˆï¼")
    print(f"ğŸ“Š å¢å¼·å¾Œçš„è³‡æ–™ä¿å­˜åœ¨: {args.output_dir}")

if __name__ == "__main__":
    main()