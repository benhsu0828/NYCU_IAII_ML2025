#!/usr/bin/env python
"""
è³‡æ–™å¢å¼·è…³æœ¬ - é‡å°é è™•ç†çš„è¾›æ™®æ£®è§’è‰²è³‡æ–™
çµåˆ data_aggV1.py å’Œ data_aggV2.py çš„å¢å¼·æ–¹æ³•
"""

import os
import random
import shutil
from PIL import Image, UnidentifiedImageError
import torch
import torchvision.transforms.v2 as T
from pathlib import Path
import argparse
from tqdm import tqdm
import platform

def get_default_paths():
    """æ ¹æ“šé‹è¡Œç’°å¢ƒè‡ªå‹•é¸æ“‡é è¨­è·¯å¾‘"""
    
    # æª¢æ¸¬æ˜¯å¦åœ¨ WSL ç’°å¢ƒä¸­
    is_wsl = "microsoft" in platform.uname().release.lower() or "WSL" in os.environ.get("WSL_DISTRO_NAME", "")
    
    if is_wsl:
        # WSL è·¯å¾‘æ ¼å¼
        base_path = "/mnt/e/NYCU/NYCU_IAII_ML2025/Ass2-Classification"
        input_dir = f"{base_path}/Dataset/preprocessed/train"
        output_dir = f"{base_path}/Dataset/augmented/train"
        backgrounds_dir = f"{base_path}/backgrounds"
    else:
        # Windows è·¯å¾‘æ ¼å¼
        input_dir = "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/preprocessed/train"
        output_dir = "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/augmented/train"
        backgrounds_dir = "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/backgrounds"
    
    return input_dir, output_dir, backgrounds_dir

# ===== è‡ªå®šç¾©å™ªè²å¢å¼·é¡åˆ¥ (ä¾†è‡ª data_aggV1.py) =====

class AddGaussianNoise(object):
    """æ·»åŠ é«˜æ–¯å™ªè²"""
    def __init__(self, mean=0., std=1.):
        self.std = std
        self.mean = mean

    def __call__(self, tensor):
        return tensor + torch.randn(tensor.size()) * self.std + self.mean

class AddSpeckleNoise(object):
    """æ·»åŠ æ•£æ–‘å™ªè²"""
    def __init__(self, noise_level=0.1):
        self.noise_level = noise_level

    def __call__(self, tensor):
        noise = torch.randn_like(tensor) * self.noise_level
        noisy_tensor = tensor * (1 + noise)
        return torch.clamp(noisy_tensor, 0, 1)

class AddPoissonNoise(object):
    """æ·»åŠ æ³Šæ¾å™ªè²"""
    def __init__(self, lam=1.0):
        self.lam = lam

    def __call__(self, tensor):
        noise = torch.poisson(self.lam * torch.ones(tensor.shape))
        noisy_tensor = tensor + noise / 255.0
        return torch.clamp(noisy_tensor, 0, 1)

class AddSaltPepperNoise(object):
    """æ·»åŠ æ¤’é¹½å™ªè² (èˆ‡ä½ çš„ data_aggV1.py å®Œå…¨ä¸€è‡´)"""
    def __init__(self, salt_prob=0.05, pepper_prob=0.05):
        self.salt_prob = salt_prob
        self.pepper_prob = pepper_prob

    def __call__(self, tensor):
        noise = torch.rand(tensor.size())
        tensor = tensor.clone()  # é˜²æ­¢ä¿®æ”¹åŸå§‹ tensor
        tensor[(noise < self.salt_prob)] = 1  # Salt noise: setting some pixels to 1
        tensor[(noise > 1 - self.pepper_prob)] = 0  # Pepper noise: setting some pixels to 0
        return tensor

# ===== è³‡æ–™å¢å¼·ç­–ç•¥å®šç¾© =====

def get_augmentation_transforms():
    """
    å®šç¾©è³‡æ–™å¢å¼·è®Šæ› (å®Œå…¨ä½¿ç”¨ä½ çš„ data_aggV1.py çš„è®Šæ›ç­–ç•¥)
    """
    transform = T.Compose([
        T.ToTensor(),  # Convert PIL image to tensor

        T.RandomApply([T.RandomHorizontalFlip()], p=0.1),
        T.RandomApply([T.RandomVerticalFlip()], p=0.1),
        T.RandomApply([T.RandomRotation(10)], p=0.1),

        T.RandomApply([T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)], p=0.1),
        T.RandomGrayscale(p=0.1),
        T.RandomInvert(p=0.1),
        T.RandomPosterize(bits=2, p=0.1),
        T.RandomApply([T.RandomSolarize(threshold=1.0)], p=0.05),
        T.RandomApply([T.RandomAdjustSharpness(sharpness_factor=2)], p=0.1),

        T.RandomApply([AddGaussianNoise(0., 0.05)], p=0.1),  # mean and std
        T.RandomApply([AddPoissonNoise(lam=0.1)], p=0.1),  # mean and std
        T.RandomApply([AddSpeckleNoise(noise_level=0.1)], p=0.1),
        T.RandomApply([AddSaltPepperNoise(salt_prob=0.05, pepper_prob=0.05)], p=0.1),

        T.RandomApply([T.RandomPerspective(distortion_scale=0.6, p=1.0)], p=0.1),
        T.RandomApply([T.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))], p=0.1),
        T.RandomApply([T.ElasticTransform(alpha=250.0)], p=0.1),

        T.RandomApply([T.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.))], p=0.1),

        T.RandomApply([AddGaussianNoise(0., 0.001)], p=1.0),  # mean and std
        T.ToPILImage()  # Convert tensor back to PIL image for saving
    ])
    
    return transform

def create_background_composite(foreground_img, background_img):
    """
    å‰µå»ºèƒŒæ™¯åˆæˆåœ–ç‰‡ (å®Œå…¨ä½¿ç”¨ä½ çš„ data_aggV2.py çš„é‚è¼¯)
    
    Args:
        foreground_img: PIL Imageï¼Œå‰æ™¯åœ–ç‰‡
        background_img: PIL Imageï¼ŒèƒŒæ™¯åœ–ç‰‡
    
    Returns:
        PIL Image: åˆæˆå¾Œçš„åœ–ç‰‡
    """
    # è½‰æ›ç‚º RGBA (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    img = foreground_img.convert("RGBA")

    # å‰µå»ºé®ç½© (å®Œå…¨è¤‡è£½ä½ çš„é‚è¼¯)
    mask = Image.new("L", img.size, 0)
    for x in range(img.width):
        for y in range(img.height):
            r, g, b, a = img.getpixel((x, y))
            if (r < 20 and g < 20 and b < 20) or (r > 235 and g > 235 and b > 235):
                mask.putpixel((x, y), 0)
            else:
                mask.putpixel((x, y), 255)

    # èƒŒæ™¯è™•ç† (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    background_image = background_img.convert("RGBA")

    # æ·»åŠ éš¨æ©Ÿé‚Šè· (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    padding_x = random.randint(10, 30)
    padding_y = random.randint(10, 30)
    new_size = (img.width + 2 * padding_x, img.height + 2 * padding_y)

    # èª¿æ•´èƒŒæ™¯å°ºå¯¸ (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    background_image = background_image.resize(new_size)

    # åˆæˆåœ–ç‰‡ (èˆ‡ä½ çš„ data_aggV2.py ä¸€è‡´)
    paste_position = (padding_x, padding_y)
    background_image.paste(img, paste_position, mask)

    # è¿”å› RGB æ ¼å¼
    return background_image.convert("RGB")

def load_background_images(backgrounds_dir):
    """è¼‰å…¥èƒŒæ™¯åœ–ç‰‡"""
    if not os.path.exists(backgrounds_dir):
        print(f"âš ï¸  èƒŒæ™¯è³‡æ–™å¤¾ä¸å­˜åœ¨: {backgrounds_dir}")
        return []
    
    background_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
        background_files.extend(list(Path(backgrounds_dir).glob(ext)))
    
    backgrounds = []
    for bg_file in background_files:
        try:
            bg_img = Image.open(bg_file).convert("RGB")
            backgrounds.append(bg_img)
        except Exception as e:
            print(f"ç„¡æ³•è¼‰å…¥èƒŒæ™¯åœ–ç‰‡ {bg_file}: {e}")
    
    print(f"âœ… è¼‰å…¥äº† {len(backgrounds)} å¼µèƒŒæ™¯åœ–ç‰‡")
    return backgrounds

def augment_dataset(input_dir, output_dir, backgrounds_dir=None, 
                   augment_per_image=3, use_background_aug=True, use_transform_aug=True):
    """
    å°æ•´å€‹è³‡æ–™é›†é€²è¡Œå¢å¼·
    
    Args:
        input_dir: è¼¸å…¥è³‡æ–™å¤¾ (åŒ…å«é¡åˆ¥å­è³‡æ–™å¤¾)
        output_dir: è¼¸å‡ºè³‡æ–™å¤¾
        backgrounds_dir: èƒŒæ™¯åœ–ç‰‡è³‡æ–™å¤¾ (å¯é¸)
        augment_per_image: æ¯å¼µåœ–ç‰‡ç”Ÿæˆçš„å¢å¼·ç‰ˆæœ¬æ•¸é‡
        use_background_aug: æ˜¯å¦ä½¿ç”¨èƒŒæ™¯åˆæˆå¢å¼·
        use_transform_aug: æ˜¯å¦ä½¿ç”¨è®Šæ›å¢å¼·
    """
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    # å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾
    output_path.mkdir(parents=True, exist_ok=True)
    
    # è¼‰å…¥èƒŒæ™¯åœ–ç‰‡
    backgrounds = []
    if use_background_aug and backgrounds_dir:
        backgrounds = load_background_images(backgrounds_dir)
    
    # æº–å‚™å¢å¼·è®Šæ›
    transform = get_augmentation_transforms() if use_transform_aug else None
    
    # è™•ç†æ¯å€‹é¡åˆ¥
    class_dirs = [d for d in input_path.iterdir() if d.is_dir()]
    
    print(f"ğŸ¯ é–‹å§‹å¢å¼· {len(class_dirs)} å€‹é¡åˆ¥çš„è³‡æ–™...")
    
    for class_dir in class_dirs:
        class_name = class_dir.name
        print(f"\nğŸ“ è™•ç†é¡åˆ¥: {class_name}")
        
        # å‰µå»ºè¼¸å‡ºé¡åˆ¥è³‡æ–™å¤¾
        output_class_dir = output_path / class_name
        output_class_dir.mkdir(exist_ok=True)
        
        # ç²å–è©²é¡åˆ¥çš„æ‰€æœ‰åœ–ç‰‡
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(list(class_dir.glob(ext)))
        
        print(f"  ğŸ“· æ‰¾åˆ° {len(image_files)} å¼µåŸå§‹åœ–ç‰‡")
        
        # å…ˆè¤‡è£½åŸå§‹åœ–ç‰‡
        for img_file in image_files:
            shutil.copy2(img_file, output_class_dir / img_file.name)
        
        # ç”Ÿæˆå¢å¼·ç‰ˆæœ¬
        augmented_count = 0
        
        for img_file in tqdm(image_files, desc=f"  å¢å¼· {class_name}"):
            try:
                # è¼‰å…¥åŸå§‹åœ–ç‰‡
                original_img = Image.open(img_file).convert("RGB")
                base_name = img_file.stem
                ext = img_file.suffix
                
                # ç”Ÿæˆå¤šå€‹å¢å¼·ç‰ˆæœ¬
                for aug_idx in range(augment_per_image):
                    current_img = original_img.copy()
                    aug_methods = []
                    
                    # æ–¹æ³• 1: è®Šæ›å¢å¼· (ä½¿ç”¨ä½ çš„ data_aggV1.py è®Šæ›)
                    if use_transform_aug and transform:
                        current_img = transform(current_img)
                        aug_methods.append("trans")
                    
                    # æ–¹æ³• 2: èƒŒæ™¯åˆæˆå¢å¼· (ä½¿ç”¨ä½ çš„ data_aggV2.py é‚è¼¯)
                    if use_background_aug and backgrounds and random.random() < 0.5:
                        bg_img = random.choice(backgrounds)
                        current_img = create_background_composite(current_img, bg_img)
                        aug_methods.append("bg")
                    
                    # å¦‚æœæœ‰æ‡‰ç”¨å¢å¼·ï¼Œå‰‡ä¿å­˜
                    if aug_methods:
                        methods_str = "_".join(aug_methods)
                        aug_filename = f"{base_name}_aug_{methods_str}_{aug_idx:02d}{ext}"
                        aug_path = output_class_dir / aug_filename
                        current_img.save(aug_path, quality=95)
                        augmented_count += 1
                
            except Exception as e:
                print(f"    âŒ è™•ç† {img_file} æ™‚å‡ºéŒ¯: {e}")
        
        print(f"  âœ… å®Œæˆï¼Œç”Ÿæˆäº† {augmented_count} å¼µå¢å¼·åœ–ç‰‡")
        
        # çµ±è¨ˆè©²é¡åˆ¥çš„ç¸½åœ–ç‰‡æ•¸
        total_images = len(list(output_class_dir.glob("*")))
        print(f"  ğŸ“Š è©²é¡åˆ¥ç¸½åœ–ç‰‡æ•¸: {total_images}")

def main():
    """ä¸»å‡½æ•¸"""
    # ç²å–ç’°å¢ƒé©é…çš„é è¨­è·¯å¾‘
    default_input, default_output, default_backgrounds = get_default_paths()
    
    parser = argparse.ArgumentParser(description="è¾›æ™®æ£®è§’è‰²è³‡æ–™å¢å¼·")
    parser.add_argument("--input_dir", type=str, 
                       default=default_input,
                       help="è¼¸å…¥è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--output_dir", type=str,
                       default=default_output,
                       help="è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--backgrounds_dir", type=str,
                       default=default_backgrounds,
                       help="èƒŒæ™¯åœ–ç‰‡è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--augment_per_image", type=int, default=3,
                       help="æ¯å¼µåœ–ç‰‡ç”Ÿæˆçš„å¢å¼·ç‰ˆæœ¬æ•¸é‡")
    parser.add_argument("--no_background", action="store_true",
                       help="ä¸ä½¿ç”¨èƒŒæ™¯åˆæˆå¢å¼·")
    parser.add_argument("--no_transform", action="store_true", 
                       help="ä¸ä½¿ç”¨è®Šæ›å¢å¼·")
    
    args = parser.parse_args()
    
    print("ğŸ¨ è¾›æ™®æ£®è§’è‰²è³‡æ–™å¢å¼·è…³æœ¬")
    print("=" * 50)
    print(f"ğŸ“‚ è¼¸å…¥è³‡æ–™å¤¾: {args.input_dir}")
    print(f"ğŸ“‚ è¼¸å‡ºè³‡æ–™å¤¾: {args.output_dir}")
    print(f"ğŸ–¼ï¸  èƒŒæ™¯è³‡æ–™å¤¾: {args.backgrounds_dir}")
    print(f"ğŸ”¢ æ¯å¼µåœ–ç‰‡å¢å¼·æ•¸é‡: {args.augment_per_image}")
    print(f"ğŸŒ… èƒŒæ™¯åˆæˆå¢å¼·: {'é—œé–‰' if args.no_background else 'é–‹å•Ÿ'}")
    print(f"ğŸ”„ è®Šæ›å¢å¼·: {'é—œé–‰' if args.no_transform else 'é–‹å•Ÿ'}")
    
    # æª¢æŸ¥è¼¸å…¥è³‡æ–™å¤¾
    if not os.path.exists(args.input_dir):
        print(f"âŒ è¼¸å…¥è³‡æ–™å¤¾ä¸å­˜åœ¨: {args.input_dir}")
        return
    
    # é–‹å§‹å¢å¼·
    augment_dataset(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        backgrounds_dir=args.backgrounds_dir if not args.no_background else None,
        augment_per_image=args.augment_per_image,
        use_background_aug=not args.no_background,
        use_transform_aug=not args.no_transform
    )
    
    print(f"\nâœ… è³‡æ–™å¢å¼·å®Œæˆï¼")
    print(f"ğŸ“Š å¢å¼·å¾Œçš„è³‡æ–™ä¿å­˜åœ¨: {args.output_dir}")

if __name__ == "__main__":
    main()