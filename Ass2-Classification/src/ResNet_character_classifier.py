#!/usr/bin/env python3
"""
ğŸƒ ResNet Simpson è§’è‰²åˆ†é¡å™¨ - ç©©å®šé«˜æ•ˆç‰ˆæœ¬

ResNet å„ªå‹¢ï¼š
- è¨“ç·´ç©©å®šï¼Œå®¹æ˜“èª¿åƒ
- é€Ÿåº¦æ¯” ViT å¿« 3-5 å€
- åœ¨å„ç¨®è³‡æ–™é›†ä¸Šè¡¨ç¾ç©©å®š
- æˆç†Ÿçš„æ¶æ§‹ï¼Œbug å°‘
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from torchvision import datasets, models
import os
import time
from tqdm import tqdm
import matplotlib.pyplot as plt

class ResNetCharacterClassifier:
    """
    ä½¿ç”¨ ResNet çš„å¿«é€Ÿè§’è‰²åˆ†é¡å™¨
    """
    
    def __init__(self, num_classes=50, model_type='resnet50', device=None):
        """
        åˆå§‹åŒ–åˆ†é¡å™¨
        
        Args:
            num_classes: é¡åˆ¥æ•¸é‡
            model_type: ResNet é¡å‹
                - resnet18: æœ€å¿« (11M åƒæ•¸)
                - resnet34: å¿«é€Ÿ (21M åƒæ•¸)  
                - resnet50: å¹³è¡¡ (25M åƒæ•¸) [æ¨è–¦]
                - resnet101: æº–ç¢º (44M åƒæ•¸)
            device: è¨ˆç®—è¨­å‚™
        """
        self.num_classes = num_classes
        self.model_type = model_type
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        print(f"ğŸ¯ åˆå§‹åŒ– {model_type} åˆ†é¡å™¨")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._create_model()
        self.class_to_idx = {}
        
    def _create_model(self):
        """å‰µå»º ResNet æ¨¡å‹"""
        # è¼‰å…¥é è¨“ç·´æ¨¡å‹
        if self.model_type == 'resnet18':
            model = models.resnet18(pretrained=True)
        elif self.model_type == 'resnet34':
            model = models.resnet34(pretrained=True)
        elif self.model_type == 'resnet50':
            model = models.resnet50(pretrained=True)
        elif self.model_type == 'resnet101':
            model = models.resnet101(pretrained=True)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹é¡å‹: {self.model_type}")
        
        # ä¿®æ”¹æœ€å¾Œä¸€å±¤
        model.fc = nn.Linear(model.fc.in_features, self.num_classes)
        
        # è¨ˆç®—åƒæ•¸
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"ğŸ“Š æ¨¡å‹çµ±è¨ˆ:")
        print(f"   ç¸½åƒæ•¸: {total_params/1e6:.1f}M")
        print(f"   å¯è¨“ç·´åƒæ•¸: {trainable_params/1e6:.1f}M")
        
        return model.to(self.device)
    
    def get_transforms(self, is_training=True):
        """ç²å–è³‡æ–™è®Šæ›"""
        if is_training:
            return transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(degrees=10),
                transforms.ColorJitter(brightness=0.2, contrast=0.2),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        else:
            return transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
    
    def prepare_data(self, data_paths):
        """æº–å‚™è³‡æ–™é›†"""
        print("\nğŸ“Š æº–å‚™è³‡æ–™...")
        
        # è¨“ç·´è³‡æ–™
        train_transform = self.get_transforms(is_training=True)
        train_dataset = datasets.ImageFolder(
            root=data_paths['train'],
            transform=train_transform
        )
        
        self.class_to_idx = train_dataset.class_to_idx
        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}
        
        print(f"âœ… è¨“ç·´é›†: {len(train_dataset)} å¼µåœ–ç‰‡")
        print(f"ğŸ“ é¡åˆ¥æ•¸: {len(self.class_to_idx)}")
        
        # é©—è­‰è³‡æ–™
        val_dataset = None
        if data_paths.get('val') and os.path.exists(data_paths['val']):
            val_transform = self.get_transforms(is_training=False)
            val_dataset = datasets.ImageFolder(
                root=data_paths['val'],
                transform=val_transform
            )
            print(f"âœ… é©—è­‰é›†: {len(val_dataset)} å¼µåœ–ç‰‡")
        
        return train_dataset, val_dataset
    
    def train(self, train_dataset, val_dataset=None, 
              batch_size=64, epochs=25, lr=1e-3):
        """
        å¿«é€Ÿè¨“ç·´æ¨¡å‹
        
        Args:
            train_dataset: è¨“ç·´è³‡æ–™é›†
            val_dataset: é©—è­‰è³‡æ–™é›†
            batch_size: batch size
            epochs: è¨“ç·´è¼ªæ•¸
            lr: å­¸ç¿’ç‡
        """
        print(f"\nğŸš€ é–‹å§‹è¨“ç·´ {self.model_type}...")
        
        # æº–å‚™è³‡æ–™è¼‰å…¥å™¨
        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=4,
            pin_memory=True if torch.cuda.is_available() else False
        )
        
        val_loader = None
        if val_dataset:
            val_loader = DataLoader(
                val_dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=2,
                pin_memory=True if torch.cuda.is_available() else False
            )
        
        # è¨­å®šå„ªåŒ–å™¨
        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-4)
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
        criterion = nn.CrossEntropyLoss()
        
        # è¨“ç·´æ­·å²
        history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': []
        }
        
        best_val_acc = 0.0
        
        print(f"ğŸ“Š è¨“ç·´è¨­å®š:")
        print(f"   Batch size: {batch_size}")
        print(f"   å­¸ç¿’ç‡: {lr}")
        print(f"   è¨“ç·´è¼ªæ•¸: {epochs}")
        
        # é–‹å§‹è¨“ç·´
        for epoch in range(epochs):
            start_time = time.time()
            
            # è¨“ç·´éšæ®µ
            self.model.train()
            train_loss = 0
            train_correct = 0
            train_total = 0
            
            pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")
            for images, labels in pbar:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                optimizer.zero_grad()
                outputs = self.model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                _, predicted = outputs.max(1)
                train_total += labels.size(0)
                train_correct += predicted.eq(labels).sum().item()
                
                # æ›´æ–°é€²åº¦æ¢
                acc = 100.0 * train_correct / train_total
                pbar.set_postfix({
                    'Loss': f'{train_loss/len(pbar):.4f}',
                    'Acc': f'{acc:.2f}%'
                })
            
            train_acc = 100.0 * train_correct / train_total
            
            # é©—è­‰éšæ®µ
            val_loss, val_acc = 0.0, 0.0
            if val_loader:
                self.model.eval()
                val_correct = 0
                val_total = 0
                val_loss_sum = 0
                
                with torch.no_grad():
                    for images, labels in val_loader:
                        images = images.to(self.device)
                        labels = labels.to(self.device)
                        
                        outputs = self.model(images)
                        loss = criterion(outputs, labels)
                        
                        val_loss_sum += loss.item()
                        _, predicted = outputs.max(1)
                        val_total += labels.size(0)
                        val_correct += predicted.eq(labels).sum().item()
                
                val_loss = val_loss_sum / len(val_loader)
                val_acc = 100.0 * val_correct / val_total
            
            # æ›´æ–°å­¸ç¿’ç‡
            scheduler.step()
            
            # è¨˜éŒ„æ­·å²
            history['train_loss'].append(train_loss / len(train_loader))
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)
            
            # è¨ˆç®—æ™‚é–“
            epoch_time = time.time() - start_time
            
            # é¡¯ç¤ºé€²åº¦
            print(f"Epoch [{epoch+1}/{epochs}] ({epoch_time:.1f}s)")
            print(f"  Train: Loss={train_loss/len(train_loader):.4f}, Acc={train_acc:.2f}%")
            if val_loader:
                print(f"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                self.save_model(f"best_{self.model_type}_acc{val_acc:.1f}.pth")
            
            print("-" * 50)
        
        print(f"\nâœ… è¨“ç·´å®Œæˆï¼")
        if val_loader:
            print(f"ğŸ† æœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_val_acc:.2f}%")
        
        return history
    
    def save_model(self, filename):
        """ä¿å­˜æ¨¡å‹"""
        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'model_type': self.model_type,
            'num_classes': self.num_classes,
            'class_to_idx': self.class_to_idx,
            'idx_to_class': self.idx_to_class
        }
        
        torch.save(checkpoint, filename)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filename}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸƒ ResNet Simpson è§’è‰²åˆ†é¡å™¨")
    print("=" * 50)
    
    # æª¢æŸ¥ GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {device}")
    
    # è‡ªå‹•æª¢æ¸¬è³‡æ–™è·¯å¾‘
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    possible_paths = [
        {
            'train': os.path.join(base_dir, 'Dataset', 'processed', 'train'),
            'val': os.path.join(base_dir, 'Dataset', 'processed', 'val')
        },
        {
            'train': os.path.join(base_dir, 'Dataset', 'train'),
            'val': os.path.join(base_dir, 'Dataset', 'val')
        }
    ]
    
    data_paths = None
    for paths in possible_paths:
        if os.path.exists(paths['train']):
            data_paths = paths
            print(f"âœ… æ‰¾åˆ°è³‡æ–™è·¯å¾‘: {paths['train']}")
            break
    
    if data_paths is None:
        print("âŒ æ‰¾ä¸åˆ°è¨“ç·´è³‡æ–™ï¼")
        return
    
    # é¸æ“‡æ¨¡å‹
    print("\nğŸ¯ é¸æ“‡ ResNet æ¨¡å‹:")
    print("1. resnet18 - æœ€å¿« (11M åƒæ•¸)")
    print("2. resnet50 - å¹³è¡¡ (25M åƒæ•¸) [æ¨è–¦]")
    print("3. resnet101 - æº–ç¢º (44M åƒæ•¸)")
    
    choice = input("è«‹é¸æ“‡ (1/2/3ï¼Œé è¨­2): ").strip()
    model_mapping = {
        '1': 'resnet18',
        '2': 'resnet50', 
        '3': 'resnet101'
    }
    model_type = model_mapping.get(choice, 'resnet50')
    
    # åˆå§‹åŒ–åˆ†é¡å™¨
    classifier = ResNetCharacterClassifier(
        num_classes=50,
        model_type=model_type,
        device=device
    )
    
    # æº–å‚™è³‡æ–™
    train_dataset, val_dataset = classifier.prepare_data(data_paths)
    
    # è¨“ç·´åƒæ•¸
    batch_size = int(input("Batch size (é è¨­ 64): ") or "64")
    epochs = int(input("è¨“ç·´è¼ªæ•¸ (é è¨­ 25): ") or "25")
    lr = float(input("å­¸ç¿’ç‡ (é è¨­ 1e-3): ") or "1e-3")
    
    # é–‹å§‹è¨“ç·´
    history = classifier.train(
        train_dataset=train_dataset,
        val_dataset=val_dataset,
        batch_size=batch_size,
        epochs=epochs,
        lr=lr
    )
    
    print("\nğŸ‰ è¨“ç·´å®Œæˆï¼")

if __name__ == "__main__":
    main()