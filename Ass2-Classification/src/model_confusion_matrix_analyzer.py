#!/usr/bin/env python3
"""
ğŸ¯ EfficientNet æ¨¡å‹åˆ†æå·¥å…· - Confusion Matrix èˆ‡è©³ç´°è©•ä¼°

ä½¿ç”¨å·²è¨“ç·´å¥½çš„æ¨¡å‹æª”æ¡ˆé€²è¡Œï¼š
- Confusion Matrix ç¹ªè£½
- åˆ†é¡å ±å‘Šç”Ÿæˆ
- éŒ¯èª¤æ¨£æœ¬åˆ†æ
- Per-class æº–ç¢ºç‡åˆ†æ
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision import datasets
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.metrics import precision_recall_fscore_support
import timm
import os
import glob
from pathlib import Path
import pandas as pd
from PIL import Image
import json

class ModelAnalyzer:
    """
    æ¨¡å‹åˆ†æå™¨ - è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹ä¸¦é€²è¡Œå„ç¨®è©•ä¼°
    """
    
    def __init__(self, model_path, device=None):
        """
        åˆå§‹åŒ–æ¨¡å‹åˆ†æå™¨
        
        Args:
            model_path: è¨“ç·´å¥½çš„æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth)
            device: è¨ˆç®—è¨­å‚™
        """
        self.model_path = model_path
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.class_to_idx = {}
        self.idx_to_class = {}
        self.model_name = ""
        self.num_classes = 0
        
        print(f"ğŸ” æ¨¡å‹åˆ†æå™¨åˆå§‹åŒ–")
        print(f"ğŸ“ æ¨¡å‹æª”æ¡ˆ: {model_path}")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # è¼‰å…¥æ¨¡å‹
        self._load_model()
        
    def _load_model(self):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {self.model_path}")
        
        print(f"ğŸ“‚ è¼‰å…¥æ¨¡å‹...")
        checkpoint = torch.load(self.model_path, map_location=self.device)
        
        # æå–æ¨¡å‹è³‡è¨Š
        self.model_name = checkpoint.get('model_name', 'unknown')
        self.num_classes = checkpoint.get('num_classes', 50)
        self.class_to_idx = checkpoint.get('class_to_idx', {})
        self.idx_to_class = checkpoint.get('idx_to_class', {})
        
        if not self.idx_to_class and self.class_to_idx:
            self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}
        
        # å‰µå»ºæ¨¡å‹æ¶æ§‹
        try:
            self.model = timm.create_model(
                self.model_name,
                pretrained=False,  # ä¸è¼‰å…¥é è¨“ç·´æ¬Šé‡
                num_classes=self.num_classes
            )
        except Exception as e:
            print(f"âš ï¸ ä½¿ç”¨ timm å‰µå»ºæ¨¡å‹å¤±æ•—: {e}")
            print("ğŸ”„ å˜—è©¦ä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ...")
            # é€™è£¡å¯ä»¥æ·»åŠ å‚™ç”¨çš„æ¨¡å‹å‰µå»ºé‚è¼¯
            raise e
        
        # è¼‰å…¥è¨“ç·´å¥½çš„æ¬Šé‡
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
        val_acc = checkpoint.get('val_acc', 'N/A')
        epoch = checkpoint.get('epoch', 'N/A')
        
        print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
        print(f"   æ¨¡å‹: {self.model_name}")
        print(f"   é¡åˆ¥æ•¸: {self.num_classes}")
        print(f"   é©—è­‰æº–ç¢ºç‡: {val_acc}")
        print(f"   è¨“ç·´è¼ªæ•¸: {epoch}")
        
    def get_transforms(self):
        """ç²å–æ¸¬è©¦ç”¨çš„è³‡æ–™è®Šæ› (èˆ‡è¨“ç·´æ™‚çš„é©—è­‰è®Šæ›ç›¸åŒ)"""
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def load_test_data(self, data_path, batch_size=32):
        """
        è¼‰å…¥æ¸¬è©¦è³‡æ–™
        
        Args:
            data_path: æ¸¬è©¦è³‡æ–™è·¯å¾‘
            batch_size: batch size
        """
        print(f"\nğŸ“Š è¼‰å…¥æ¸¬è©¦è³‡æ–™: {data_path}")
        
        if not os.path.exists(data_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è³‡æ–™è·¯å¾‘: {data_path}")
        
        # å‰µå»ºè³‡æ–™é›†
        transform = self.get_transforms()
        dataset = datasets.ImageFolder(root=data_path, transform=transform)
        
        # ç¢ºä¿é¡åˆ¥æ˜ å°„ä¸€è‡´
        if dataset.class_to_idx != self.class_to_idx:
            print("âš ï¸ è­¦å‘Š: æ¸¬è©¦è³‡æ–™çš„é¡åˆ¥æ˜ å°„èˆ‡æ¨¡å‹ä¸ä¸€è‡´")
            print(f"   æ¨¡å‹é¡åˆ¥æ•¸: {len(self.class_to_idx)}")
            print(f"   æ¸¬è©¦è³‡æ–™é¡åˆ¥æ•¸: {len(dataset.class_to_idx)}")
            
            # ä½¿ç”¨æ¨¡å‹çš„é¡åˆ¥æ˜ å°„
            dataset.class_to_idx = self.class_to_idx
        
        # å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=False,  # ä¸æ‰“äº‚é †åºï¼Œä¾¿æ–¼åˆ†æ
            num_workers=4,
            pin_memory=True if torch.cuda.is_available() else False
        )
        
        print(f"âœ… æ¸¬è©¦è³‡æ–™è¼‰å…¥å®Œæˆ")
        print(f"   ç¸½æ¨£æœ¬æ•¸: {len(dataset)}")
        print(f"   é¡åˆ¥æ•¸: {len(dataset.classes)}")
        print(f"   Batchæ•¸: {len(dataloader)}")
        
        return dataloader, dataset
    
    def predict(self, dataloader):
        """
        å°æ¸¬è©¦è³‡æ–™é€²è¡Œé æ¸¬
        
        Args:
            dataloader: æ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨
            
        Returns:
            y_true: çœŸå¯¦æ¨™ç±¤
            y_pred: é æ¸¬æ¨™ç±¤
            y_probs: é æ¸¬æ©Ÿç‡
        """
        print(f"\nğŸ”® é–‹å§‹é æ¸¬...")
        
        self.model.eval()
        y_true = []
        y_pred = []
        y_probs = []
        
        with torch.no_grad():
            for batch_idx, (images, labels) in enumerate(dataloader):
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                # é æ¸¬
                outputs = self.model(images)
                probabilities = torch.softmax(outputs, dim=1)
                predicted = outputs.argmax(dim=1)
                
                # æ”¶é›†çµæœ
                y_true.extend(labels.cpu().numpy())
                y_pred.extend(predicted.cpu().numpy())
                y_probs.extend(probabilities.cpu().numpy())
                
                if (batch_idx + 1) % 10 == 0:
                    print(f"   å·²è™•ç†: {(batch_idx + 1) * dataloader.batch_size} æ¨£æœ¬")
        
        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        y_probs = np.array(y_probs)
        
        accuracy = accuracy_score(y_true, y_pred)
        print(f"âœ… é æ¸¬å®Œæˆï¼")
        print(f"   ç¸½æ¨£æœ¬æ•¸: {len(y_true)}")
        print(f"   æ•´é«”æº–ç¢ºç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        
        return y_true, y_pred, y_probs
    
    def plot_confusion_matrix(self, y_true, y_pred, save_path=None, figsize=(15, 12)):
        """
        ç¹ªè£½ Confusion Matrix
        
        Args:
            y_true: çœŸå¯¦æ¨™ç±¤
            y_pred: é æ¸¬æ¨™ç±¤
            save_path: ä¿å­˜è·¯å¾‘
            figsize: åœ–ç‰‡å°ºå¯¸
        """
        print(f"\nğŸ“Š ç¹ªè£½ Confusion Matrix...")
        
        # è¨ˆç®— confusion matrix
        cm = confusion_matrix(y_true, y_pred)
        
        # å‰µå»ºé¡åˆ¥åç¨±åˆ—è¡¨
        class_names = [self.idx_to_class.get(i, f'Class_{i}') for i in range(self.num_classes)]
        
        # å‰µå»ºåœ–ç‰‡
        plt.figure(figsize=figsize)
        
        # ç¹ªè£½ç†±åŠ›åœ–
        sns.heatmap(
            cm, 
            annot=True, 
            fmt='d', 
            cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names,
            cbar_kws={'label': 'Sample Count'}
        )
        
        plt.title(f'Confusion Matrix\n{self.model_name} - Accuracy: {accuracy_score(y_true, y_pred):.4f}', 
                 fontsize=16, pad=20)
        plt.xlabel('Predicted Label', fontsize=12)
        plt.ylabel('True Label', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜åœ–ç‰‡
        if save_path is None:
            save_path = f"{self.model_name}_confusion_matrix.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ Confusion Matrix å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        return cm
    
    def plot_normalized_confusion_matrix(self, y_true, y_pred, save_path=None, figsize=(15, 12)):
        """
        ç¹ªè£½æ¨™æº–åŒ–çš„ Confusion Matrix (ç™¾åˆ†æ¯”)
        
        Args:
            y_true: çœŸå¯¦æ¨™ç±¤
            y_pred: é æ¸¬æ¨™ç±¤
            save_path: ä¿å­˜è·¯å¾‘
            figsize: åœ–ç‰‡å°ºå¯¸
        """
        print(f"\nğŸ“Š ç¹ªè£½æ¨™æº–åŒ– Confusion Matrix...")
        
        # è¨ˆç®—æ¨™æº–åŒ–çš„ confusion matrix
        cm = confusion_matrix(y_true, y_pred)
        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        # å‰µå»ºé¡åˆ¥åç¨±åˆ—è¡¨
        class_names = [self.idx_to_class.get(i, f'Class_{i}') for i in range(self.num_classes)]
        
        # å‰µå»ºåœ–ç‰‡
        plt.figure(figsize=figsize)
        
        # ç¹ªè£½ç†±åŠ›åœ–
        sns.heatmap(
            cm_normalized, 
            annot=True, 
            fmt='.2f', 
            cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names,
            cbar_kws={'label': 'Percentage'},
            vmin=0, vmax=1
        )
        
        plt.title(f'Normalized Confusion Matrix (%)\n{self.model_name} - Accuracy: {accuracy_score(y_true, y_pred):.4f}', 
                 fontsize=16, pad=20)
        plt.xlabel('Predicted Label', fontsize=12)
        plt.ylabel('True Label', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜åœ–ç‰‡
        if save_path is None:
            save_path = f"{self.model_name}_confusion_matrix_normalized.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ æ¨™æº–åŒ– Confusion Matrix å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        return cm_normalized
    
    def generate_classification_report(self, y_true, y_pred, save_path=None):
        """
        ç”Ÿæˆè©³ç´°çš„åˆ†é¡å ±å‘Š
        
        Args:
            y_true: çœŸå¯¦æ¨™ç±¤
            y_pred: é æ¸¬æ¨™ç±¤
            save_path: ä¿å­˜è·¯å¾‘
        """
        print(f"\nğŸ“‹ ç”Ÿæˆåˆ†é¡å ±å‘Š...")
        
        # å‰µå»ºé¡åˆ¥åç¨±åˆ—è¡¨
        class_names = [self.idx_to_class.get(i, f'Class_{i}') for i in range(self.num_classes)]
        
        # ç”Ÿæˆåˆ†é¡å ±å‘Š
        report = classification_report(
            y_true, y_pred, 
            target_names=class_names,
            output_dict=True
        )
        
        # è½‰æ›ç‚º DataFrame ä¾¿æ–¼é¡¯ç¤ºå’Œä¿å­˜
        df = pd.DataFrame(report).transpose()
        
        # é¡¯ç¤ºå ±å‘Š
        print("ğŸ“Š åˆ†é¡å ±å‘Š:")
        print("=" * 60)
        print(df.round(4))
        
        # ä¿å­˜ç‚º CSV
        if save_path is None:
            save_path = f"{self.model_name}_classification_report.csv"
        
        df.to_csv(save_path)
        print(f"ğŸ’¾ åˆ†é¡å ±å‘Šå·²ä¿å­˜: {save_path}")
        
        return df
    
    def analyze_per_class_accuracy(self, y_true, y_pred, save_path=None):
        """
        åˆ†ææ¯å€‹é¡åˆ¥çš„æº–ç¢ºç‡
        
        Args:
            y_true: çœŸå¯¦æ¨™ç±¤
            y_pred: é æ¸¬æ¨™ç±¤
            save_path: ä¿å­˜è·¯å¾‘
        """
        print(f"\nğŸ¯ åˆ†ææ¯é¡åˆ¥æº–ç¢ºç‡...")
        
        # è¨ˆç®—æ¯å€‹é¡åˆ¥çš„æº–ç¢ºç‡
        cm = confusion_matrix(y_true, y_pred)
        per_class_acc = cm.diagonal() / cm.sum(axis=1)
        
        # å‰µå»ºçµæœ DataFrame
        class_names = [self.idx_to_class.get(i, f'Class_{i}') for i in range(self.num_classes)]
        
        results = []
        for i, (class_name, accuracy) in enumerate(zip(class_names, per_class_acc)):
            total_samples = cm.sum(axis=1)[i]
            correct_predictions = cm.diagonal()[i]
            
            results.append({
                'Class': class_name,
                'Accuracy': accuracy,
                'Correct': correct_predictions,
                'Total': total_samples,
                'Error_Count': total_samples - correct_predictions
            })
        
        df = pd.DataFrame(results)
        df = df.sort_values('Accuracy', ascending=False)
        
        # é¡¯ç¤ºçµæœ
        print("ğŸ† å„é¡åˆ¥æº–ç¢ºç‡æ’å:")
        print("=" * 60)
        for _, row in df.head(10).iterrows():
            print(f"{row['Class']:20} | æº–ç¢ºç‡: {row['Accuracy']:.4f} ({row['Accuracy']*100:6.2f}%) | "
                  f"æ­£ç¢º/ç¸½æ•¸: {row['Correct']}/{row['Total']}")
        
        print("\nâŒ æº–ç¢ºç‡æœ€ä½çš„é¡åˆ¥:")
        print("-" * 60)
        for _, row in df.tail(5).iterrows():
            print(f"{row['Class']:20} | æº–ç¢ºç‡: {row['Accuracy']:.4f} ({row['Accuracy']*100:6.2f}%) | "
                  f"éŒ¯èª¤æ•¸: {row['Error_Count']}")
        
        # ç¹ªè£½æº–ç¢ºç‡åˆ†å¸ƒåœ–
        plt.figure(figsize=(15, 8))
        bars = plt.bar(range(len(df)), df['Accuracy'], 
                      color=['green' if acc >= 0.9 else 'orange' if acc >= 0.7 else 'red' 
                            for acc in df['Accuracy']])
        
        plt.title(f'Per-Class Accuracy\n{self.model_name}', fontsize=16)
        plt.xlabel('Classes (sorted by accuracy)', fontsize=12)
        plt.ylabel('Accuracy', fontsize=12)
        plt.xticks(range(len(df)), df['Class'], rotation=45, ha='right')
        plt.ylim(0, 1)
        plt.grid(axis='y', alpha=0.3)
        
        # æ·»åŠ æº–ç¢ºç‡æ–‡å­—
        for i, (bar, acc) in enumerate(zip(bars, df['Accuracy'])):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{acc:.3f}', ha='center', va='bottom', fontsize=8)
        
        plt.tight_layout()
        
        # ä¿å­˜åœ–ç‰‡å’Œæ•¸æ“š
        if save_path is None:
            save_path = f"{self.model_name}_per_class_accuracy"
        
        plt.savefig(f"{save_path}.png", dpi=300, bbox_inches='tight')
        df.to_csv(f"{save_path}.csv", index=False)
        
        print(f"ğŸ’¾ æ¯é¡åˆ¥æº–ç¢ºç‡å·²ä¿å­˜: {save_path}.png, {save_path}.csv")
        
        plt.show()
        
        return df
    
    def find_misclassified_samples(self, y_true, y_pred, y_probs, dataset, num_samples=5):
        """
        æ‰¾å‡ºåˆ†é¡éŒ¯èª¤çš„æ¨£æœ¬
        
        Args:
            y_true: çœŸå¯¦æ¨™ç±¤
            y_pred: é æ¸¬æ¨™ç±¤
            y_probs: é æ¸¬æ©Ÿç‡
            dataset: è³‡æ–™é›†
            num_samples: æ¯å€‹é¡åˆ¥é¡¯ç¤ºçš„éŒ¯èª¤æ¨£æœ¬æ•¸
        """
        print(f"\nğŸ” åˆ†æåˆ†é¡éŒ¯èª¤çš„æ¨£æœ¬...")
        
        # æ‰¾å‡ºéŒ¯èª¤åˆ†é¡çš„æ¨£æœ¬
        misclassified_indices = np.where(y_true != y_pred)[0]
        
        print(f"ğŸ“Š éŒ¯èª¤åˆ†é¡çµ±è¨ˆ:")
        print(f"   ç¸½æ¨£æœ¬æ•¸: {len(y_true)}")
        print(f"   éŒ¯èª¤æ¨£æœ¬æ•¸: {len(misclassified_indices)}")
        print(f"   éŒ¯èª¤ç‡: {len(misclassified_indices)/len(y_true)*100:.2f}%")
        
        # åˆ†ææ¯å€‹é¡åˆ¥çš„éŒ¯èª¤
        class_names = [self.idx_to_class.get(i, f'Class_{i}') for i in range(self.num_classes)]
        
        for true_class_idx in range(self.num_classes):
            class_name = class_names[true_class_idx]
            
            # æ‰¾å‡ºé€™å€‹é¡åˆ¥çš„éŒ¯èª¤æ¨£æœ¬
            class_misclassified = misclassified_indices[
                y_true[misclassified_indices] == true_class_idx
            ]
            
            if len(class_misclassified) > 0:
                print(f"\nâŒ {class_name} çš„éŒ¯èª¤åˆ†é¡:")
                
                # æŒ‰ç…§é æ¸¬ä¿¡å¿ƒåº¦æ’åº (ä¿¡å¿ƒåº¦è¶Šé«˜çš„éŒ¯èª¤è¶Šå€¼å¾—é—œæ³¨)
                confidences = np.max(y_probs[class_misclassified], axis=1)
                sorted_indices = class_misclassified[np.argsort(confidences)[::-1]]
                
                for i, sample_idx in enumerate(sorted_indices[:num_samples]):
                    true_label = y_true[sample_idx]
                    pred_label = y_pred[sample_idx]
                    confidence = np.max(y_probs[sample_idx])
                    
                    true_class_name = class_names[true_label]
                    pred_class_name = class_names[pred_label]
                    
                    print(f"   æ¨£æœ¬ {sample_idx}: {true_class_name} â†’ {pred_class_name} "
                          f"(ä¿¡å¿ƒåº¦: {confidence:.3f})")
        
        return misclassified_indices

def get_available_models():
    """å°‹æ‰¾å¯ç”¨çš„æ¨¡å‹æª”æ¡ˆ"""
    print("ğŸ” å°‹æ‰¾å¯ç”¨çš„æ¨¡å‹æª”æ¡ˆ...")
    
    # æœå°‹æ¨¡å¼
    patterns = [
        "*.pth",
        "efficientnet*.pth", 
        "convnext*.pth",
        "*_epoch_*.pth",
        "best_*.pth"
    ]
    
    model_files = []
    for pattern in patterns:
        model_files.extend(glob.glob(pattern))
    
    # å»é™¤é‡è¤‡ä¸¦æ’åº
    model_files = list(set(model_files))
    model_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    
    return model_files

def get_available_data_paths():
    """ç²å–å¯ç”¨çš„æ¸¬è©¦è³‡æ–™è·¯å¾‘"""
    print("ğŸ“ å°‹æ‰¾å¯ç”¨çš„æ¸¬è©¦è³‡æ–™...")
    
    # å¯èƒ½çš„æ¸¬è©¦è³‡æ–™è·¯å¾‘
    possible_paths = [
        "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/preprocessed/val",
        "/mnt/e/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/preprocessed/val",
        "Dataset/preprocessed/val",
        "../Dataset/preprocessed/val",
        "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/preprocessed/test",
        "/mnt/e/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/preprocessed/test"
    ]
    
    available_paths = []
    for path in possible_paths:
        if os.path.exists(path):
            available_paths.append(path)
    
    return available_paths

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ EfficientNet æ¨¡å‹åˆ†æå·¥å…·")
    print("=" * 60)
    print("ğŸ“Š åŠŸèƒ½: Confusion Matrix, åˆ†é¡å ±å‘Š, éŒ¯èª¤åˆ†æ")
    print("=" * 60)
    
    # 1. é¸æ“‡æ¨¡å‹æª”æ¡ˆ
    # model_files = get_available_models()
    model_files = ["convnext_tiny_epoch_013_acc_99.91.pth"]

    if not model_files:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•æ¨¡å‹æª”æ¡ˆï¼")
        print("ğŸ’¡ è«‹ç¢ºèªç•¶å‰ç›®éŒ„ä¸‹æœ‰ .pth æª”æ¡ˆ")
        return
    
    print(f"\nğŸ“‚ æ‰¾åˆ° {len(model_files)} å€‹æ¨¡å‹æª”æ¡ˆ:")
    for i, file in enumerate(model_files, 1):
        # ç²å–æª”æ¡ˆè³‡è¨Š
        file_size = os.path.getsize(file) / (1024 * 1024)  # MB
        mod_time = os.path.getmtime(file)
        time_str = pd.Timestamp.fromtimestamp(mod_time).strftime('%m/%d %H:%M')
        
        print(f"  {i}. {file} ({file_size:.1f}MB, {time_str})")
    
    try:
        choice = int(input(f"\nè«‹é¸æ“‡æ¨¡å‹æª”æ¡ˆ (1-{len(model_files)}): ")) - 1
        model_path = model_files[choice]
        print(f"âœ… é¸æ“‡æ¨¡å‹: {model_path}")
    except (ValueError, IndexError):
        print("âŒ é¸æ“‡ç„¡æ•ˆï¼Œä½¿ç”¨æœ€æ–°çš„æ¨¡å‹æª”æ¡ˆ")
        model_path = model_files[0]
    
    # 2. é¸æ“‡æ¸¬è©¦è³‡æ–™
    data_paths = get_available_data_paths()
    
    if not data_paths:
        print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦è³‡æ–™è·¯å¾‘ï¼")
        print("ğŸ’¡ è«‹ç¢ºèªä»¥ä¸‹è·¯å¾‘å­˜åœ¨:")
        print("   - Dataset/preprocessed/val")
        print("   - Dataset/preprocessed/test")
        return
    
    print(f"\nğŸ“ æ‰¾åˆ° {len(data_paths)} å€‹è³‡æ–™è·¯å¾‘:")
    for i, path in enumerate(data_paths, 1):
        print(f"  {i}. {path}")
    
    try:
        choice = int(input(f"\nè«‹é¸æ“‡æ¸¬è©¦è³‡æ–™è·¯å¾‘ (1-{len(data_paths)}): ")) - 1
        data_path = data_paths[choice]
        print(f"âœ… é¸æ“‡è³‡æ–™: {data_path}")
    except (ValueError, IndexError):
        print("âŒ é¸æ“‡ç„¡æ•ˆï¼Œä½¿ç”¨ç¬¬ä¸€å€‹è³‡æ–™è·¯å¾‘")
        data_path = data_paths[0]
    
    # 3. åˆå§‹åŒ–åˆ†æå™¨
    try:
        analyzer = ModelAnalyzer(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return
    
    # 4. è¼‰å…¥æ¸¬è©¦è³‡æ–™
    try:
        dataloader, dataset = analyzer.load_test_data(data_path)
    except Exception as e:
        print(f"âŒ è³‡æ–™è¼‰å…¥å¤±æ•—: {e}")
        return
    
    # 5. é€²è¡Œé æ¸¬
    try:
        y_true, y_pred, y_probs = analyzer.predict(dataloader)
    except Exception as e:
        print(f"âŒ é æ¸¬å¤±æ•—: {e}")
        return
    
    # 6. ç”Ÿæˆåˆ†æå ±å‘Š
    print(f"\nğŸ¯ é–‹å§‹ç”Ÿæˆåˆ†æå ±å‘Š...")
    
    # Confusion Matrix
    cm = analyzer.plot_confusion_matrix(y_true, y_pred)
    
    # æ¨™æº–åŒ– Confusion Matrix  
    cm_norm = analyzer.plot_normalized_confusion_matrix(y_true, y_pred)
    
    # åˆ†é¡å ±å‘Š
    report_df = analyzer.generate_classification_report(y_true, y_pred)
    
    # æ¯é¡åˆ¥æº–ç¢ºç‡åˆ†æ
    per_class_df = analyzer.analyze_per_class_accuracy(y_true, y_pred)
    
    # éŒ¯èª¤æ¨£æœ¬åˆ†æ
    misclassified_indices = analyzer.find_misclassified_samples(
        y_true, y_pred, y_probs, dataset
    )
    
    print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰çµæœå·²ä¿å­˜åˆ°ç•¶å‰ç›®éŒ„")
    print(f"ğŸ“Š ç¸½é«”æº–ç¢ºç‡: {accuracy_score(y_true, y_pred):.4f}")

if __name__ == "__main__":
    main()