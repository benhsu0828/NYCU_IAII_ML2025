#!/usr/bin/env python3
"""
ğŸ§ª CoCa æ¸¬è©¦è…³æœ¬ - é©—è­‰ open-clip å®‰è£å’Œ CoCa æ¨¡å‹è¼‰å…¥

æ¸¬è©¦å…§å®¹ï¼š
1. æª¢æŸ¥ open-clip-torch å®‰è£
2. æ¸¬è©¦ CoCa æ¨¡å‹è¼‰å…¥
3. æ¸¬è©¦ Mac MPS æ”¯æ´
4. é©—è­‰åŸºæœ¬æ¨ç†åŠŸèƒ½
"""

import torch
import sys
import os

def test_basic_imports():
    """æ¸¬è©¦åŸºæœ¬å¥—ä»¶åŒ¯å…¥"""
    print("ğŸ§ª æ¸¬è©¦åŸºæœ¬å¥—ä»¶...")
    
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
    except ImportError as e:
        print(f"âŒ PyTorch åŒ¯å…¥å¤±æ•—: {e}")
        return False
        
    try:
        import torchvision
        print(f"âœ… TorchVision: {torchvision.__version__}")
    except ImportError as e:
        print(f"âŒ TorchVision åŒ¯å…¥å¤±æ•—: {e}")
        return False
        
    try:
        import open_clip
        print(f"âœ… OpenCLIP: {open_clip.__version__}")
    except ImportError as e:
        print(f"âŒ OpenCLIP åŒ¯å…¥å¤±æ•—: {e}")
        print("   è«‹å®‰è£: pip install open-clip-torch")
        return False
        
    return True

def test_device_support():
    """æ¸¬è©¦è¨­å‚™æ”¯æ´"""
    print("\nğŸ–¥ï¸ æ¸¬è©¦è¨­å‚™æ”¯æ´...")
    
    # CPU æ”¯æ´
    print(f"âœ… CPU å¯ç”¨")
    
    # MPS æ”¯æ´ (Mac)
    if torch.backends.mps.is_available():
        print(f"âœ… MPS (Metal) å¯ç”¨")
        try:
            # æ¸¬è©¦ MPS åŸºæœ¬æ“ä½œ
            x = torch.randn(2, 3).to('mps')
            y = x * 2
            print(f"   MPS æ¸¬è©¦é‹ç®—: {y.shape}")
        except Exception as e:
            print(f"   âš ï¸ MPS æ¸¬è©¦å¤±æ•—: {e}")
    else:
        print(f"â„¹ï¸ MPS ä¸å¯ç”¨ï¼ˆé Apple Silicon Macï¼‰")
    
    # CUDA æ”¯æ´ (é€šå¸¸ Mac ä¸æœƒæœ‰)
    if torch.cuda.is_available():
        print(f"âœ… CUDA å¯ç”¨: {torch.cuda.get_device_name()}")
    else:
        print(f"â„¹ï¸ CUDA ä¸å¯ç”¨")

def test_coca_models():
    """æ¸¬è©¦ CoCa æ¨¡å‹è¼‰å…¥"""
    print("\nğŸ¤– æ¸¬è©¦ CoCa æ¨¡å‹...")
    
    try:
        import open_clip
        
        # åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹
        available_models = open_clip.list_models()
        coca_models = [m for m in available_models if 'coca' in m.lower()]
        
        print(f"ğŸ“‹ æ‰¾åˆ° {len(coca_models)} å€‹ CoCa æ¨¡å‹:")
        for model in coca_models[:5]:  # åªé¡¯ç¤ºå‰5å€‹
            print(f"   - {model}")
            
        if not coca_models:
            print("âš ï¸ æ²’æœ‰æ‰¾åˆ° CoCa æ¨¡å‹")
            return False
        
        # æ¸¬è©¦è¼‰å…¥ä¸€å€‹ CoCa æ¨¡å‹
        test_model = coca_models[0]
        print(f"\nğŸ”„ æ¸¬è©¦è¼‰å…¥æ¨¡å‹: {test_model}")
        
        try:
            model, _, preprocess = open_clip.create_model_and_transforms(
                test_model,
                pretrained='laion2b_s13b_b90k'
            )
            
            # æ¸¬è©¦æ¨¡å‹åŸºæœ¬è³‡è¨Š
            total_params = sum(p.numel() for p in model.parameters())
            print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            print(f"   åƒæ•¸é‡: {total_params/1e6:.1f}M")
            print(f"   é è™•ç†: {type(preprocess)}")
            
            # æ¸¬è©¦ç·¨ç¢¼åŠŸèƒ½
            dummy_image = torch.randn(1, 3, 224, 224)
            
            with torch.no_grad():
                features = model.encode_image(dummy_image)
                print(f"   åœ–ç‰‡ç‰¹å¾µç¶­åº¦: {features.shape}")
                
                # å¦‚æœæœ‰æ–‡å­—ç·¨ç¢¼åŠŸèƒ½ä¹Ÿæ¸¬è©¦ä¸€ä¸‹
                try:
                    dummy_text = open_clip.tokenize(["a photo of simpson character"])
                    text_features = model.encode_text(dummy_text)
                    print(f"   æ–‡å­—ç‰¹å¾µç¶­åº¦: {text_features.shape}")
                except:
                    print(f"   (æ²’æœ‰æ–‡å­—ç·¨ç¢¼åŠŸèƒ½)")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            return False
            
    except ImportError as e:
        print(f"âŒ OpenCLIP ä¸å¯ç”¨: {e}")
        return False

def test_image_processing():
    """æ¸¬è©¦åœ–ç‰‡è™•ç†åŠŸèƒ½"""
    print("\nğŸ–¼ï¸ æ¸¬è©¦åœ–ç‰‡è™•ç†...")
    
    try:
        from PIL import Image
        import torchvision.transforms as transforms
        import numpy as np
        
        # å‰µå»ºæ¸¬è©¦åœ–ç‰‡
        test_image = Image.new('RGB', (224, 224), color='red')
        print("âœ… PIL åœ–ç‰‡å‰µå»ºæˆåŠŸ")
        
        # æ¸¬è©¦è®Šæ›
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.48145466, 0.4578275, 0.40821073],
                std=[0.26862954, 0.26130258, 0.27577711]
            )
        ])
        
        tensor = transform(test_image)
        print(f"âœ… åœ–ç‰‡è®Šæ›æˆåŠŸ: {tensor.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åœ–ç‰‡è™•ç†æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_file_operations():
    """æ¸¬è©¦æª”æ¡ˆæ“ä½œ"""
    print("\nğŸ“ æ¸¬è©¦æª”æ¡ˆæ“ä½œ...")
    
    try:
        import glob
        import pandas as pd
        
        # æ¸¬è©¦ç›®éŒ„
        test_dirs = [
            "Dataset/test",
            "src",
            "."
        ]
        
        for test_dir in test_dirs:
            if os.path.exists(test_dir):
                files = glob.glob(os.path.join(test_dir, "*"))
                print(f"âœ… {test_dir}: {len(files)} å€‹æª”æ¡ˆ")
                break
        else:
            print("âš ï¸ æ¸¬è©¦ç›®éŒ„éƒ½ä¸å­˜åœ¨")
        
        # æ¸¬è©¦ pandas
        df = pd.DataFrame({'id': [1, 2, 3], 'character': ['homer', 'marge', 'bart']})
        print(f"âœ… Pandas DataFrame: {df.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æª”æ¡ˆæ“ä½œæ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§ª CoCa ç³»çµ±æ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦çµæœè¨˜éŒ„
    tests = [
        ("åŸºæœ¬å¥—ä»¶åŒ¯å…¥", test_basic_imports),
        ("è¨­å‚™æ”¯æ´", test_device_support),
        ("CoCa æ¨¡å‹", test_coca_models),
        ("åœ–ç‰‡è™•ç†", test_image_processing),
        ("æª”æ¡ˆæ“ä½œ", test_file_operations),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name} æ¸¬è©¦ç•°å¸¸: {e}")
            results[test_name] = False
    
    # ç¸½çµ
    print(f"\n{'='*50}")
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ:")
    
    passed = 0
    total = len(tests)
    
    for test_name, result in results.items():
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ ç¸½è¨ˆ: {passed}/{total} é€šé")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼CoCa ç³»çµ±æº–å‚™å°±ç·’")
    elif passed >= total * 0.7:
        print("âš ï¸ å¤§éƒ¨åˆ†æ¸¬è©¦é€šéï¼Œç³»çµ±åŸºæœ¬å¯ç”¨")
    else:
        print("âŒ å¤šé …æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç’°å¢ƒè¨­å®š")
        
    # çµ¦å‡ºå»ºè­°
    print(f"\nğŸ’¡ å»ºè­°:")
    if not results.get("åŸºæœ¬å¥—ä»¶åŒ¯å…¥", True):
        print("   1. å®‰è£å¿…è¦å¥—ä»¶: pip install torch torchvision open-clip-torch")
    if not results.get("CoCa æ¨¡å‹", True):
        print("   2. æª¢æŸ¥ open-clip-torch ç‰ˆæœ¬: pip install --upgrade open-clip-torch")
    if not results.get("åœ–ç‰‡è™•ç†", True):
        print("   3. å®‰è£åœ–ç‰‡è™•ç†å¥—ä»¶: pip install Pillow pandas tqdm")
    
    print(f"\nğŸš€ å¦‚æœæ¸¬è©¦é€šéï¼Œå¯ä»¥é–‹å§‹ä½¿ç”¨ CoCa åˆ†é¡å™¨äº†ï¼")

if __name__ == "__main__":
    main()
