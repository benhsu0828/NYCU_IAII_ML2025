#!/usr/bin/env python3
"""
ğŸ”® Mac EfficientNet æ¨ç†å·¥å…· - æ¸¬è©¦ç‰ˆæœ¬

é€™æ˜¯ä¸€å€‹æ¸¬è©¦ç‰ˆæœ¬ï¼Œæœƒå‰µå»ºæ¨¡æ“¬çš„æ¨ç†çµæœã€‚
åœ¨æœ‰å¯¦éš›æ¨¡å‹æª”æ¡ˆæ™‚ï¼Œè«‹ä½¿ç”¨å®Œæ•´ç‰ˆæœ¬ã€‚
"""

import os
import glob
import pandas as pd
import random
from pathlib import Path
from tqdm import tqdm
import json

# æ¨¡æ“¬çš„è¾›æ™®æ£®å®¶åº­è§’è‰²é¡åˆ¥ï¼ˆå¾ character_class_mapping.json ç²å–ï¼‰
SIMPSON_CHARACTERS = [
    "abraham_grampa_simpson",
    "agnes_skinner", 
    "apu_nahasapeemapetilon",
    "barney_gumble",
    "bart_simpson",
    "brandine_spuckler",
    "carl_carlson",
    "charles_montgomery_burns",
    "chief_wiggum",
    "cletus_spuckler",
    "comic_book_guy",
    "disco_stu",
    "dolph_starbeam",
    "duff_man",
    "edna_krabappel",
    "fat_tony",
    "gary_chalmers",
    "gil",
    "groundskeeper_willie",
    "homer_simpson",
    "jimbo_jones",
    "kearney_zzyzwicz",
    "kent_brockman",
    "krusty_the_clown",
    "lenny_leonard",
    "lionel_hutz",
    "lisa_simpson",
    "lunchlady_doris",
    "maggie_simpson",
    "marge_simpson",
    "martin_prince",
    "mayor_quimby",
    "milhouse_van_houten",
    "miss_hoover",
    "moe_szyslak",
    "ned_flanders",
    "nelson_muntz",
    "otto_mann",
    "patty_bouvier",
    "principal_skinner",
    "professor_john_frink",
    "rainier_wolfcastle",
    "ralph_wiggum",
    "selma_bouvier",
    "sideshow_bob",
    "sideshow_mel",
    "snake_jailbird",
    "timothy_lovejoy",
    "troy_mclure",
    "waylon_smithers"
]

def predict_test_dataset_demo(test_dir="Dataset/test", output_file="predictions.csv"):
    """
    æ¼”ç¤ºç‰ˆæœ¬çš„æ¸¬è©¦è³‡æ–™é›†é æ¸¬ï¼ˆä½¿ç”¨éš¨æ©Ÿé æ¸¬ï¼‰
    
    Args:
        test_dir: æ¸¬è©¦åœ–ç‰‡ç›®éŒ„
        output_file: è¼¸å‡º CSV æª”æ¡ˆåç¨±
        
    Returns:
        pd.DataFrame: é æ¸¬çµæœ
    """
    print(f"ğŸ­ Mac EfficientNet æ¨ç†å·¥å…· - æ¼”ç¤ºæ¨¡å¼")
    print(f"ğŸ“ è™•ç†æ¸¬è©¦è³‡æ–™é›†: {test_dir}")
    
    # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif', '*.webp']
    
    # æ”¶é›†æ‰€æœ‰åœ–ç‰‡è·¯å¾‘
    image_paths = []
    for ext in image_extensions:
        pattern = os.path.join(test_dir, ext)
        image_paths.extend(glob.glob(pattern))
    
    # æŒ‰æª”åæ•¸å­—æ’åº
    def sort_key(path):
        filename = os.path.basename(path)
        try:
            number = int(filename.split('.')[0])
            return number
        except:
            return 0
    
    image_paths.sort(key=sort_key)
    
    if not image_paths:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡ï¼")
        return None
    
    print(f"ğŸ” æ‰¾åˆ° {len(image_paths)} å¼µåœ–ç‰‡")
    
    # è¨­å®šéš¨æ©Ÿç¨®å­ä»¥ä¾¿é‡ç¾çµæœ
    random.seed(42)
    
    # æº–å‚™çµæœåˆ—è¡¨
    results = []
    
    # æ¨¡æ“¬é æ¸¬ï¼ˆä½¿ç”¨é€²åº¦æ¢ï¼‰
    print("ğŸ² é–‹å§‹æ¨¡æ“¬é æ¸¬...")
    for image_path in tqdm(image_paths, desc="é æ¸¬é€²åº¦"):
        filename = os.path.basename(image_path)
        
        # æ¨¡æ“¬é æ¸¬ï¼ˆéš¨æ©Ÿé¸æ“‡è§’è‰²ï¼‰
        predicted_class = random.choice(SIMPSON_CHARACTERS)
        
        results.append({
            'filename': filename,
            'prediction': predicted_class
        })
    
    # å‰µå»º DataFrame
    df = pd.DataFrame(results)
    
    # ä¿å­˜ CSV
    df.to_csv(output_file, index=False, encoding='utf-8')
    print(f"ğŸ’¾ é æ¸¬çµæœå·²ä¿å­˜è‡³: {output_file}")
    
    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
    print(f"\nğŸ“Š é æ¸¬çµ±è¨ˆ:")
    print(f"   ç¸½åœ–ç‰‡æ•¸: {len(df)}")
    print(f"   é æ¸¬é¡åˆ¥åˆ†å¸ƒ (å‰10å):")
    for class_name, count in df['prediction'].value_counts().head(10).items():
        print(f"     {class_name}: {count}")
    
    # é¡¯ç¤ºå‰å¹¾å€‹çµæœ
    print(f"\nğŸ“‹ å‰ 10 å€‹é æ¸¬çµæœ:")
    print(df.head(10).to_string(index=False))
    
    return df

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ Mac EfficientNet æ¨ç†å·¥å…· - æ¼”ç¤ºæ¨¡å¼")
    print("=" * 50)
    print("âš ï¸  æ³¨æ„: é€™æ˜¯æ¼”ç¤ºç‰ˆæœ¬ï¼Œä½¿ç”¨éš¨æ©Ÿé æ¸¬çµæœ")
    print("ğŸ“ å¦‚éœ€ä½¿ç”¨å¯¦éš›æ¨¡å‹ï¼Œè«‹ç¢ºä¿æœ‰ .pth æ¨¡å‹æª”æ¡ˆ")
    print("")
    
    # è¨­å®šæ¸¬è©¦ç›®éŒ„
    test_dir = input("æ¸¬è©¦åœ–ç‰‡ç›®éŒ„ (é è¨­: Dataset/test): ").strip()
    if not test_dir:
        test_dir = "Dataset/test"
    
    # æª¢æŸ¥æ¸¬è©¦ç›®éŒ„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_dir):
        print(f"âŒ æ¸¬è©¦ç›®éŒ„ä¸å­˜åœ¨: {test_dir}")
        return 1
    
    # è¨­å®šè¼¸å‡ºæª”æ¡ˆ
    output_file = input("è¼¸å‡ºæª”æ¡ˆåç¨± (é è¨­: predictions_demo.csv): ").strip()
    if not output_file:
        output_file = "predictions_demo.csv"
    
    # åŸ·è¡Œæ¼”ç¤ºæ¨ç†
    try:
        print(f"\nğŸš€ é–‹å§‹æ¼”ç¤ºæ¨ç†...")
        df = predict_test_dataset_demo(test_dir, output_file)
        
        if df is not None:
            print(f"\nğŸ‰ æ¼”ç¤ºæ¨ç†å®Œæˆï¼")
            print(f"ğŸ“„ çµæœå·²ä¿å­˜è‡³: {output_file}")
            
            # æç¤ºå¦‚ä½•ä½¿ç”¨å¯¦éš›æ¨¡å‹
            print(f"\nğŸ’¡ ä½¿ç”¨å¯¦éš›æ¨¡å‹çš„æ­¥é©Ÿ:")
            print(f"   1. ç¢ºä¿æœ‰è¨“ç·´å¥½çš„ .pth æ¨¡å‹æª”æ¡ˆ")
            print(f"   2. å®‰è£ä¾è³´: pip install -r requirements.txt")
            print(f"   3. ä½¿ç”¨å®Œæ•´ç‰ˆ: python src/mac_inference.py --model your_model.pth")
            
        else:
            print("âŒ æ¼”ç¤ºæ¨ç†å¤±æ•—ï¼")
            return 1
            
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
