#!/usr/bin/env python3
"""
ğŸ”® EfficientNet æ¨¡å‹æ¨ç†å·¥å…· - Mac ç‰ˆæœ¬

åŠŸèƒ½ï¼š
- å¾ Dataset/test ç›®éŒ„è®€å–æ‰€æœ‰æ¸¬è©¦åœ–ç‰‡
- ä½¿ç”¨è¨“ç·´å¥½çš„ EfficientNet æ¨¡å‹é€²è¡Œé æ¸¬
- è¼¸å‡º CSV æ ¼å¼çµæœï¼šæª”å, é æ¸¬çµæœ
- é‡å° Mac ç³»çµ±å„ªåŒ–ï¼Œæ”¯æ´ MPSï¼ˆMetal Performance Shadersï¼‰åŠ é€Ÿ
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import timm
import os
import glob
import pandas as pd
import numpy as np
from PIL import Image
from pathlib import Path
import argparse
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class MacEfficientNetInference:
    """
    Mac å„ªåŒ–ç‰ˆ EfficientNet æ¨¡å‹æ¨ç†å™¨
    """
    
    def __init__(self, model_path, device=None):
        """
        åˆå§‹åŒ–æ¨ç†å™¨
        
        Args:
            model_path: æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth)
            device: è¨ˆç®—è¨­å‚™
        """
        # Mac è¨­å‚™å„ªå…ˆç´šï¼šMPS > CPU
        if device is None:
            if torch.backends.mps.is_available():
                self.device = torch.device("mps")
            else:
                self.device = torch.device("cpu")
        else:
            self.device = device
            
        self.model = None
        self.class_to_idx = {}
        self.idx_to_class = {}
        self.model_name = None
        
        print(f"ğŸ”® Mac EfficientNet æ¨ç†å™¨")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # è¼‰å…¥æ¨¡å‹
        self.load_model(model_path)
        
        # æº–å‚™è®Šæ›
        self.transform = self._get_inference_transform()
        
    def load_model(self, model_path):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}")
        
        print(f"ğŸ“‚ è¼‰å…¥æ¨¡å‹: {model_path}")
        
        # è¼‰å…¥ checkpointï¼Œå¼·åˆ¶ä½¿ç”¨ CPU ä»¥é¿å…è¨­å‚™ä¸åŒ¹é…
        checkpoint = torch.load(model_path, map_location='cpu')
        
        # ç²å–æ¨¡å‹è³‡è¨Š
        self.model_name = checkpoint['model_name']
        num_classes = checkpoint['num_classes']
        self.class_to_idx = checkpoint['class_to_idx']
        self.idx_to_class = checkpoint['idx_to_class']
        
        print(f"ğŸ¯ æ¨¡å‹: {self.model_name}")
        print(f"ğŸ“ é¡åˆ¥æ•¸: {num_classes}")
        print(f"ğŸ·ï¸ é¡åˆ¥: {list(self.class_to_idx.keys())}")
        
        # é‡å»ºæ¨¡å‹æ¶æ§‹
        self.model = timm.create_model(
            self.model_name,
            pretrained=False,  # ä¸éœ€è¦é è¨“ç·´æ¬Šé‡
            num_classes=num_classes
        )
        
        # è¼‰å…¥æ¬Šé‡
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()  # è¨­ç‚ºæ¨ç†æ¨¡å¼
        
        print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼")
    
    def _get_inference_transform(self):
        """ç²å–æ¨ç†ç”¨çš„åœ–ç‰‡è®Šæ›"""
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def predict_single(self, image_path):
        """
        é æ¸¬å–®å¼µåœ–ç‰‡
        
        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            
        Returns:
            str: é æ¸¬çš„é¡åˆ¥åç¨±
        """
        try:
            # è¼‰å…¥ä¸¦é è™•ç†åœ–ç‰‡
            image = Image.open(image_path).convert('RGB')
            
            # è®Šæ›åœ–ç‰‡
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                outputs = self.model(input_tensor)
                _, predicted = torch.max(outputs.data, 1)
                predicted_idx = predicted.item()
                predicted_class = self.idx_to_class[predicted_idx]
            
            return predicted_class
        
        except Exception as e:
            print(f"âŒ é æ¸¬å¤±æ•— {image_path}: {e}")
            return "unknown"
    
    def predict_test_dataset(self, test_dir="Dataset/test", output_file="predictions.csv"):
        """
        å°æ¸¬è©¦è³‡æ–™é›†é€²è¡Œæ‰¹é‡é æ¸¬ä¸¦è¼¸å‡º CSV
        
        Args:
            test_dir: æ¸¬è©¦åœ–ç‰‡ç›®éŒ„
            output_file: è¼¸å‡º CSV æª”æ¡ˆåç¨±
            
        Returns:
            pd.DataFrame: é æ¸¬çµæœ
        """
        print(f"\nğŸ“ é–‹å§‹è™•ç†æ¸¬è©¦è³‡æ–™é›†: {test_dir}")
        
        # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif', '*.webp']
        
        # æ”¶é›†æ‰€æœ‰åœ–ç‰‡è·¯å¾‘
        image_paths = []
        for ext in image_extensions:
            pattern = os.path.join(test_dir, ext)
            image_paths.extend(glob.glob(pattern))
        
        # æŒ‰æª”åæ•¸å­—æ’åº
        def sort_key(path):
            filename = os.path.basename(path)
            # æå–æ•¸å­—éƒ¨åˆ†é€²è¡Œæ’åº
            try:
                number = int(filename.split('.')[0])
                return number
            except:
                return 0
        
        image_paths.sort(key=sort_key)
        
        if not image_paths:
            print("âŒ æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡ï¼")
            return None
        
        print(f"ğŸ” æ‰¾åˆ° {len(image_paths)} å¼µåœ–ç‰‡")
        
        # æº–å‚™çµæœåˆ—è¡¨
        results = []
        
        # æ‰¹é‡é æ¸¬ï¼ˆä½¿ç”¨é€²åº¦æ¢ï¼‰
        print("ğŸš€ é–‹å§‹æ‰¹é‡é æ¸¬...")
        for image_path in tqdm(image_paths, desc="é æ¸¬é€²åº¦"):
            filename = os.path.basename(image_path)
            # ç§»é™¤å‰¯æª”å (.jpg, .png ç­‰)
            id_name = os.path.splitext(filename)[0]
            predicted_class = self.predict_single(image_path)
            
            results.append({
                'id': id_name,
                'character': predicted_class
            })
        
        # å‰µå»º DataFrame
        df = pd.DataFrame(results)
        
        # ä¿å­˜ CSV
        df.to_csv(output_file, index=False, encoding='utf-8')
        print(f"ğŸ’¾ é æ¸¬çµæœå·²ä¿å­˜è‡³: {output_file}")
        
        # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        print(f"\nğŸ“Š é æ¸¬çµ±è¨ˆ:")
        print(f"   ç¸½åœ–ç‰‡æ•¸: {len(df)}")
        print(f"   é æ¸¬é¡åˆ¥åˆ†å¸ƒ:")
        for class_name, count in df['character'].value_counts().items():
            print(f"     {class_name}: {count}")
        
        return df
    
    def get_model_info(self):
        """ç²å–æ¨¡å‹è³‡è¨Š"""
        total_params = sum(p.numel() for p in self.model.parameters())
        
        info = {
            'model_name': self.model_name,
            'num_classes': len(self.idx_to_class),
            'total_parameters': f"{total_params/1e6:.1f}M",
            'device': str(self.device),
            'class_names': list(self.class_to_idx.keys())
        }
        
        return info

def main():
    """ä¸»å‡½æ•¸ - å‘½ä»¤åˆ—ä»‹é¢"""
    parser = argparse.ArgumentParser(description="Mac EfficientNet æ¨¡å‹æ¨ç†å·¥å…·")
    parser.add_argument('--model', '-m', required=True, help='æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth)')
    parser.add_argument('--test-dir', '-t', default='Dataset/test', help='æ¸¬è©¦åœ–ç‰‡ç›®éŒ„')
    parser.add_argument('--output', '-o', default='predictions.csv', help='è¼¸å‡º CSV æª”æ¡ˆåç¨±')
    parser.add_argument('--device', choices=['auto', 'mps', 'cpu'], default='auto', help='è¨ˆç®—è¨­å‚™')
    
    args = parser.parse_args()
    
    # è¨­å®šè¨­å‚™
    if args.device == 'auto':
        device = None
    elif args.device == 'mps' and torch.backends.mps.is_available():
        device = torch.device('mps')
    else:
        device = torch.device('cpu')
    
    # åˆå§‹åŒ–æ¨ç†å™¨
    try:
        inferencer = MacEfficientNetInference(args.model, device=device)
        
        # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
        info = inferencer.get_model_info()
        print(f"\nğŸ“Š æ¨¡å‹è³‡è¨Š:")
        print(f"   æ¨¡å‹: {info['model_name']}")
        print(f"   é¡åˆ¥æ•¸: {info['num_classes']}")
        print(f"   åƒæ•¸é‡: {info['total_parameters']}")
        print(f"   è¨­å‚™: {info['device']}")
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
        return 1
    
    # åŸ·è¡Œæ‰¹é‡æ¨ç†
    try:
        # ç¢ºä¿æ¸¬è©¦ç›®éŒ„å­˜åœ¨
        if not os.path.exists(args.test_dir):
            print(f"âŒ æ¸¬è©¦ç›®éŒ„ä¸å­˜åœ¨: {args.test_dir}")
            return 1
        
        # é–‹å§‹é æ¸¬
        df = inferencer.predict_test_dataset(args.test_dir, args.output)
        
        if df is not None:
            print(f"\nâœ… æ¨ç†å®Œæˆï¼")
            print(f"ğŸ“„ çµæœæª”æ¡ˆ: {args.output}")
            print(f"ğŸ”¢ ç¸½é æ¸¬æ•¸: {len(df)}")
        else:
            print("âŒ æ¨ç†å¤±æ•—ï¼")
            return 1
            
    except Exception as e:
        print(f"âŒ æ¨ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    # å¦‚æœæ²’æœ‰å‘½ä»¤åˆ—åƒæ•¸ï¼Œä½¿ç”¨äº’å‹•æ¨¡å¼
    import sys
    
    if len(sys.argv) == 1:
        print("ğŸ”® Mac EfficientNet æ¨ç†å·¥å…· - äº’å‹•æ¨¡å¼")
        print("=" * 50)
        
        # å°‹æ‰¾å¯ç”¨çš„æ¨¡å‹
        possible_paths = [
            "*.pth",
            "../*.pth", 
            "models/*.pth",
            "../models/*.pth"
        ]
        
        model_files = []
        for pattern in possible_paths:
            model_files.extend(glob.glob(pattern))
        
        if not model_files:
            print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ (.pth)")
            model_path = input("è«‹è¼¸å…¥æ¨¡å‹æª”æ¡ˆè·¯å¾‘: ").strip()
        else:
            print("ğŸ” æ‰¾åˆ°ä»¥ä¸‹æ¨¡å‹æª”æ¡ˆ:")
            for i, model_file in enumerate(model_files):
                print(f"{i+1}. {model_file}")
            
            choice = input(f"è«‹é¸æ“‡æ¨¡å‹ (1-{len(model_files)}): ").strip()
            try:
                model_path = model_files[int(choice)-1]
            except (ValueError, IndexError):
                model_path = model_files[0]
                print(f"ä½¿ç”¨é è¨­æ¨¡å‹: {model_path}")
        
        # è¨­å®šæ¸¬è©¦ç›®éŒ„
        test_dir = input("æ¸¬è©¦åœ–ç‰‡ç›®éŒ„ (é è¨­: Dataset/test): ").strip()
        if not test_dir:
            test_dir = "Dataset/test"
        
        # è¨­å®šè¼¸å‡ºæª”æ¡ˆ
        output_file = input("è¼¸å‡ºæª”æ¡ˆåç¨± (é è¨­: predictions.csv): ").strip()
        if not output_file:
            output_file = "predictions.csv"
        
        # åˆå§‹åŒ–æ¨ç†å™¨
        try:
            print("\nğŸš€ åˆå§‹åŒ–æ¨ç†å™¨...")
            inferencer = MacEfficientNetInference(model_path)
            
            # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
            info = inferencer.get_model_info()
            print(f"\nğŸ“Š æ¨¡å‹è³‡è¨Š:")
            print(f"   æ¨¡å‹: {info['model_name']}")
            print(f"   é¡åˆ¥æ•¸: {info['num_classes']}")
            print(f"   åƒæ•¸é‡: {info['total_parameters']}")
            print(f"   è¨­å‚™: {info['device']}")
            print(f"   é¡åˆ¥: {', '.join(info['class_names'])}")
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            exit(1)
        
        # åŸ·è¡Œæ¨ç†
        try:
            print(f"\nğŸ¯ é–‹å§‹é æ¸¬...")
            df = inferencer.predict_test_dataset(test_dir, output_file)
            
            if df is not None:
                print(f"\nğŸ‰ æ¨ç†å®Œæˆï¼")
                print(f"ğŸ“„ çµæœå·²ä¿å­˜è‡³: {output_file}")
                
                # é¡¯ç¤ºå‰å¹¾å€‹çµæœ
                print(f"\nğŸ“‹ å‰ 10 å€‹é æ¸¬çµæœ:")
                print(df.head(10).to_string(index=False))
                
            else:
                print("âŒ æ¨ç†å¤±æ•—ï¼")
                
        except Exception as e:
            print(f"âŒ æ¨ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    else:
        # å‘½ä»¤åˆ—æ¨¡å¼
        exit(main())
