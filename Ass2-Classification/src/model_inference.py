#!/usr/bin/env python3
"""
MemoryViT æ¨¡å‹è¼‰å…¥å’Œæ¨è«–å·¥å…·
è¼‰å…¥å·²è¨“ç·´çš„æ¨¡å‹é€²è¡Œå–®å¼µåœ–ç‰‡é æ¸¬æˆ–æ‰¹é‡æ¨è«–
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
from PIL import Image
import os
import json
import numpy as np
from vit_pytorch.learnable_memory_vit import ViT, Adapter

class MemoryViTPredictor:
    def __init__(self, model_path, device='cuda'):
        """
        åˆå§‹åŒ–é æ¸¬å™¨
        
        Args:
            model_path: æ¨¡å‹æª”æ¡ˆè·¯å¾‘
            device: é‹ç®—è£ç½®
        """
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.model_path = model_path
        
        # è¼‰å…¥æ¨¡å‹
        self.load_model()
        
    def load_model(self):
        """è¼‰å…¥é è¨“ç·´æ¨¡å‹"""
        print(f"ğŸ”„ è¼‰å…¥æ¨¡å‹: {self.model_path}")
        
        try:
            checkpoint = torch.load(self.model_path, map_location=self.device)
            
            # ç²å–æ¨¡å‹é…ç½®
            if 'training_config' in checkpoint:
                config = checkpoint['training_config']
                self.image_size = config.get('image_size', 224)
                self.num_classes = config.get('num_classes', 50)
            else:
                self.image_size = 224
                self.num_classes = 50
                
            # ç²å–é¡åˆ¥æ˜ å°„
            if 'class_mapping' in checkpoint:
                self.class_to_idx = checkpoint['class_mapping']['class_to_idx']
                self.idx_to_class = checkpoint['class_mapping']['idx_to_class']
                # å°‡å­—ç¬¦ä¸²éµè½‰æ›ç‚ºæ•´æ•¸éµ
                self.idx_to_class = {int(k): v for k, v in self.idx_to_class.items()}
            else:
                raise ValueError("æ¨¡å‹æª”æ¡ˆä¸­æ²’æœ‰é¡åˆ¥æ˜ å°„ä¿¡æ¯")
            
            # è¨­å®šåœ–åƒè®Šæ›
            self.transform = transforms.Compose([
                transforms.Resize((self.image_size, self.image_size)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
            
            # é‡å»ºæ¨¡å‹æ¶æ§‹
            self.base_vit = ViT(
                image_size=self.image_size,
                patch_size=16,
                num_classes=1000,
                dim=768,
                depth=12,
                heads=12,
                mlp_dim=3072,
                dropout=0.1,
                emb_dropout=0.1
            ).to(self.device)
            
            self.character_adapter = Adapter(
                vit=self.base_vit,
                num_classes=self.num_classes,
                num_memories_per_layer=20
            ).to(self.device)
            
            # è¼‰å…¥æ¬Šé‡
            self.character_adapter.load_state_dict(checkpoint['model_state_dict'])
            self.character_adapter.eval()
            
            # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
            if 'val_acc' in checkpoint:
                print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼é©—è­‰æº–ç¢ºç‡: {checkpoint['val_acc']:.2f}%")
            
            if 'training_config' in checkpoint:
                config = checkpoint['training_config']
                print(f"ğŸ“Š æ¨¡å‹é…ç½®:")
                print(f"   åœ–åƒå°ºå¯¸: {config.get('image_size', 224)}x{config.get('image_size', 224)}")
                print(f"   é¡åˆ¥æ•¸é‡: {self.num_classes}")
                print(f"   æ‰¹æ¬¡å¤§å°: {config.get('batch_size', 'N/A')}")
                print(f"   æ··åˆç²¾åº¦: {'æ˜¯' if config.get('use_mixed_precision', False) else 'å¦'}")
            
            print(f"ğŸ­ å¯è­˜åˆ¥çš„è§’è‰²: {len(self.class_to_idx)} å€‹")
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            raise
    
    def predict_single_image(self, image_path, top_k=5):
        """
        é æ¸¬å–®å¼µåœ–ç‰‡
        
        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            top_k: è¿”å›å‰ k å€‹é æ¸¬çµæœ
            
        Returns:
            list: [(class_name, probability), ...]
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"åœ–ç‰‡ä¸å­˜åœ¨: {image_path}")
        
        # è¼‰å…¥ä¸¦é è™•ç†åœ–ç‰‡
        try:
            image = Image.open(image_path).convert('RGB')
            image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        except Exception as e:
            raise ValueError(f"ç„¡æ³•è¼‰å…¥åœ–ç‰‡ {image_path}: {e}")
        
        # æ¨è«–
        with torch.no_grad():
            outputs = self.character_adapter(image_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            top_probs, top_indices = torch.topk(probabilities, min(top_k, self.num_classes))
        
        # æ•´ç†çµæœ
        results = []
        for i in range(top_probs.size(1)):
            class_idx = top_indices[0][i].item()
            class_name = self.idx_to_class[class_idx]
            prob = top_probs[0][i].item()
            results.append((class_name, prob))
        
        return results
    
    def predict_batch(self, image_paths, batch_size=32):
        """
        æ‰¹é‡é æ¸¬å¤šå¼µåœ–ç‰‡
        
        Args:
            image_paths: åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            list: [predictions, ...] æ¯å€‹é æ¸¬æ˜¯ (class_name, probability) çš„åˆ—è¡¨
        """
        all_results = []
        
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i:i+batch_size]
            batch_images = []
            valid_indices = []
            
            # è¼‰å…¥ä¸¦é è™•ç†æ‰¹æ¬¡åœ–ç‰‡
            for j, path in enumerate(batch_paths):
                try:
                    if os.path.exists(path):
                        image = Image.open(path).convert('RGB')
                        image_tensor = self.transform(image)
                        batch_images.append(image_tensor)
                        valid_indices.append(i + j)
                    else:
                        print(f"âš ï¸ è·³éä¸å­˜åœ¨çš„åœ–ç‰‡: {path}")
                except Exception as e:
                    print(f"âš ï¸ è·³éç„¡æ³•è¼‰å…¥çš„åœ–ç‰‡ {path}: {e}")
            
            if batch_images:
                # å †ç–Šæˆæ‰¹æ¬¡
                batch_tensor = torch.stack(batch_images).to(self.device)
                
                # æ¨è«–
                with torch.no_grad():
                    outputs = self.character_adapter(batch_tensor)
                    probabilities = torch.softmax(outputs, dim=1)
                    top_probs, top_indices = torch.topk(probabilities, 5)
                
                # æ•´ç†æ‰¹æ¬¡çµæœ
                for k in range(len(batch_images)):
                    batch_results = []
                    for m in range(5):
                        class_idx = top_indices[k][m].item()
                        class_name = self.idx_to_class[class_idx]
                        prob = top_probs[k][m].item()
                        batch_results.append((class_name, prob))
                    all_results.append(batch_results)
            
        return all_results
    
    def get_class_list(self):
        """ç²å–æ‰€æœ‰é¡åˆ¥åç¨±"""
        return list(self.class_to_idx.keys())
    
    def get_model_info(self):
        """ç²å–æ¨¡å‹è©³ç´°è³‡è¨Š"""
        try:
            checkpoint = torch.load(self.model_path, map_location='cpu')
            info = {
                'model_path': self.model_path,
                'num_classes': self.num_classes,
                'image_size': self.image_size,
                'validation_accuracy': checkpoint.get('val_acc', 'N/A'),
                'training_accuracy': checkpoint.get('train_acc', 'N/A'),
                'epoch': checkpoint.get('epoch', 'N/A'),
                'classes': list(self.class_to_idx.keys())
            }
            
            if 'training_config' in checkpoint:
                info.update(checkpoint['training_config'])
            
            return info
        except Exception as e:
            return {'error': str(e)}

def demo_prediction():
    """æ¼”ç¤ºé æ¸¬åŠŸèƒ½"""
    print("ğŸ­ MemoryViT é æ¸¬æ¼”ç¤º")
    print("=" * 50)
    
    # å°‹æ‰¾æ¨¡å‹æª”æ¡ˆ
    model_files = [
        'best_memory_vit_character_classifier.pth',
        'memoryvit_model_acc*.pth'
    ]
    
    model_path = None
    for pattern in model_files:
        if '*' in pattern:
            import glob
            matches = glob.glob(pattern)
            if matches:
                model_path = matches[0]
                break
        elif os.path.exists(pattern):
            model_path = pattern
            break
    
    if not model_path:
        print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ")
        print("è«‹ç¢ºèªä»¥ä¸‹æª”æ¡ˆä¹‹ä¸€å­˜åœ¨:")
        for f in model_files:
            print(f"  - {f}")
        return
    
    try:
        # è¼‰å…¥é æ¸¬å™¨
        predictor = MemoryViTPredictor(model_path)
        
        # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
        info = predictor.get_model_info()
        print(f"\nğŸ“Š æ¨¡å‹è³‡è¨Š:")
        for key, value in info.items():
            if key != 'classes':
                print(f"   {key}: {value}")
        
        # ç²å–æ¸¬è©¦åœ–ç‰‡
        test_image = input("\nè«‹è¼¸å…¥æ¸¬è©¦åœ–ç‰‡è·¯å¾‘ (æˆ–æŒ‰ Enter è·³é): ").strip()
        
        if test_image and os.path.exists(test_image):
            print(f"\nğŸ” é æ¸¬åœ–ç‰‡: {test_image}")
            results = predictor.predict_single_image(test_image, top_k=5)
            
            print("\nğŸ¯ é æ¸¬çµæœ:")
            for i, (class_name, prob) in enumerate(results, 1):
                print(f"   {i}. {class_name}: {prob*100:.2f}%")
        else:
            print("âš ï¸ è·³éåœ–ç‰‡é æ¸¬")
        
        # é¡¯ç¤ºæ‰€æœ‰å¯è­˜åˆ¥çš„è§’è‰²
        classes = predictor.get_class_list()
        print(f"\nğŸ­ å¯è­˜åˆ¥çš„è§’è‰² ({len(classes)} å€‹):")
        for i, class_name in enumerate(sorted(classes), 1):
            print(f"   {i:2d}. {class_name}")
            
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    demo_prediction()