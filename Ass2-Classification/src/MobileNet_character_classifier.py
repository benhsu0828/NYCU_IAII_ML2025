#!/usr/bin/env python3
"""
ğŸ“± MobileNet Simpson è§’è‰²åˆ†é¡å™¨ - è¶…è¼•é‡ç‰ˆæœ¬

MobileNet å„ªå‹¢ï¼š
- æœ€è¼•é‡ï¼Œé©åˆå¿«é€Ÿå¯¦é©—
- é€Ÿåº¦æ¥µå¿«ï¼Œæ¯” ViT å¿« 10+ å€
- è¨˜æ†¶é«”éœ€æ±‚æœ€ä½
- é©åˆè³‡æºå—é™ç’°å¢ƒ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from torchvision import datasets, models
import os
import time
from tqdm import tqdm

class MobileNetCharacterClassifier:
    """
    ä½¿ç”¨ MobileNet çš„è¶…è¼•é‡è§’è‰²åˆ†é¡å™¨
    """
    
    def __init__(self, num_classes=50, model_type='mobilenet_v2', device=None):
        """
        åˆå§‹åŒ–åˆ†é¡å™¨
        
        Args:
            num_classes: é¡åˆ¥æ•¸é‡
            model_type: MobileNet é¡å‹
                - mobilenet_v2: ç¶“å…¸ç‰ˆæœ¬ (3.5M åƒæ•¸)
                - mobilenet_v3_small: è¶…è¼•é‡ (2.5M åƒæ•¸)
                - mobilenet_v3_large: å¹³è¡¡ç‰ˆ (5.5M åƒæ•¸)
            device: è¨ˆç®—è¨­å‚™
        """
        self.num_classes = num_classes
        self.model_type = model_type
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        print(f"ğŸ¯ åˆå§‹åŒ– {model_type} åˆ†é¡å™¨")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._create_model()
        self.class_to_idx = {}
        
    def _create_model(self):
        """å‰µå»º MobileNet æ¨¡å‹"""
        # è¼‰å…¥é è¨“ç·´æ¨¡å‹
        if self.model_type == 'mobilenet_v2':
            model = models.mobilenet_v2(pretrained=True)
            model.classifier[1] = nn.Linear(model.classifier[1].in_features, self.num_classes)
        elif self.model_type == 'mobilenet_v3_small':
            model = models.mobilenet_v3_small(pretrained=True)
            model.classifier[3] = nn.Linear(model.classifier[3].in_features, self.num_classes)
        elif self.model_type == 'mobilenet_v3_large':
            model = models.mobilenet_v3_large(pretrained=True)
            model.classifier[3] = nn.Linear(model.classifier[3].in_features, self.num_classes)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹é¡å‹: {self.model_type}")
        
        # è¨ˆç®—åƒæ•¸
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"ğŸ“Š æ¨¡å‹çµ±è¨ˆ:")
        print(f"   ç¸½åƒæ•¸: {total_params/1e6:.1f}M")
        print(f"   å¯è¨“ç·´åƒæ•¸: {trainable_params/1e6:.1f}M")
        print(f"ğŸš€ é æœŸé€Ÿåº¦: ViT çš„ 10+ å€")
        
        return model.to(self.device)
    
    def get_transforms(self, is_training=True):
        """ç²å–è³‡æ–™è®Šæ›"""
        if is_training:
            return transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(degrees=15),
                transforms.ColorJitter(brightness=0.3, contrast=0.3),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        else:
            return transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
    
    def prepare_data(self, data_paths):
        """æº–å‚™è³‡æ–™é›†"""
        print("\nğŸ“Š æº–å‚™è³‡æ–™...")
        
        # è¨“ç·´è³‡æ–™
        train_transform = self.get_transforms(is_training=True)
        train_dataset = datasets.ImageFolder(
            root=data_paths['train'],
            transform=train_transform
        )
        
        self.class_to_idx = train_dataset.class_to_idx
        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}
        
        print(f"âœ… è¨“ç·´é›†: {len(train_dataset)} å¼µåœ–ç‰‡")
        print(f"ğŸ“ é¡åˆ¥æ•¸: {len(self.class_to_idx)}")
        
        # é©—è­‰è³‡æ–™
        val_dataset = None
        if data_paths.get('val') and os.path.exists(data_paths['val']):
            val_transform = self.get_transforms(is_training=False)
            val_dataset = datasets.ImageFolder(
                root=data_paths['val'],
                transform=val_transform
            )
            print(f"âœ… é©—è­‰é›†: {len(val_dataset)} å¼µåœ–ç‰‡")
        
        return train_dataset, val_dataset
    
    def train_fast(self, train_dataset, val_dataset=None, 
                   batch_size=128, epochs=20, lr=2e-3):
        """
        è¶…å¿«é€Ÿè¨“ç·´æ¨¡å‹
        
        Args:
            train_dataset: è¨“ç·´è³‡æ–™é›†
            val_dataset: é©—è­‰è³‡æ–™é›†
            batch_size: batch size (è¼ƒå¤§ï¼Œå› ç‚ºæ¨¡å‹è¼•é‡)
            epochs: è¨“ç·´è¼ªæ•¸
            lr: å­¸ç¿’ç‡ (è¼ƒé«˜ï¼Œå› ç‚ºæ¨¡å‹æ”¶æ–‚å¿«)
        """
        print(f"\nğŸš€ é–‹å§‹è¶…å¿«é€Ÿè¨“ç·´ {self.model_type}...")
        
        # æº–å‚™è³‡æ–™è¼‰å…¥å™¨
        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=6,  # æ›´å¤š workerï¼Œå› ç‚ºæ¨¡å‹è¨ˆç®—å¿«
            pin_memory=True if torch.cuda.is_available() else False
        )
        
        val_loader = None
        if val_dataset:
            val_loader = DataLoader(
                val_dataset,
                batch_size=batch_size * 2,  # é©—è­‰æ™‚å¯ä»¥ç”¨æ›´å¤§ batch
                shuffle=False,
                num_workers=4,
                pin_memory=True if torch.cuda.is_available() else False
            )
        
        # è¨­å®šå„ªåŒ–å™¨ (é©åˆè¼•é‡æ¨¡å‹çš„è¨­å®š)
        optimizer = optim.SGD(
            self.model.parameters(), 
            lr=lr, 
            momentum=0.9, 
            weight_decay=4e-5
        )
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
        criterion = nn.CrossEntropyLoss()
        
        best_val_acc = 0.0
        
        print(f"ğŸ“Š è¶…å¿«é€Ÿè¨“ç·´è¨­å®š:")
        print(f"   Batch size: {batch_size}")
        print(f"   å­¸ç¿’ç‡: {lr}")
        print(f"   è¨“ç·´è¼ªæ•¸: {epochs}")
        print(f"   å„ªåŒ–å™¨: SGD + Cosine Annealing")
        
        # é–‹å§‹è¨“ç·´
        total_start_time = time.time()
        
        for epoch in range(epochs):
            start_time = time.time()
            
            # è¨“ç·´éšæ®µ
            self.model.train()
            train_loss = 0
            train_correct = 0
            train_total = 0
            
            pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")
            for images, labels in pbar:
                images = images.to(self.device, non_blocking=True)
                labels = labels.to(self.device, non_blocking=True)
                
                optimizer.zero_grad()
                outputs = self.model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                _, predicted = outputs.max(1)
                train_total += labels.size(0)
                train_correct += predicted.eq(labels).sum().item()
                
                # æ›´æ–°é€²åº¦æ¢
                acc = 100.0 * train_correct / train_total
                pbar.set_postfix({
                    'Loss': f'{train_loss/len(pbar):.4f}',
                    'Acc': f'{acc:.2f}%'
                })
            
            train_acc = 100.0 * train_correct / train_total
            
            # é©—è­‰éšæ®µ
            val_acc = 0.0
            if val_loader:
                self.model.eval()
                val_correct = 0
                val_total = 0
                
                with torch.no_grad():
                    for images, labels in val_loader:
                        images = images.to(self.device, non_blocking=True)
                        labels = labels.to(self.device, non_blocking=True)
                        
                        outputs = self.model(images)
                        _, predicted = outputs.max(1)
                        val_total += labels.size(0)
                        val_correct += predicted.eq(labels).sum().item()
                
                val_acc = 100.0 * val_correct / val_total
            
            # æ›´æ–°å­¸ç¿’ç‡
            scheduler.step()
            
            # è¨ˆç®—æ™‚é–“
            epoch_time = time.time() - start_time
            
            # é¡¯ç¤ºé€²åº¦
            print(f"Epoch [{epoch+1}/{epochs}] ({epoch_time:.1f}s)")
            print(f"  Train Acc: {train_acc:.2f}%")
            if val_loader:
                print(f"  Val Acc:   {val_acc:.2f}%")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                self.save_model(f"best_{self.model_type}_acc{val_acc:.1f}.pth")
            
            print("-" * 40)
        
        total_time = time.time() - total_start_time
        
        print(f"\nğŸ‰ è¶…å¿«é€Ÿè¨“ç·´å®Œæˆï¼")
        print(f"â±ï¸ ç¸½è¨“ç·´æ™‚é–“: {total_time/60:.1f} åˆ†é˜")
        if val_loader:
            print(f"ğŸ† æœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_val_acc:.2f}%")
        
        return best_val_acc
    
    def save_model(self, filename):
        """ä¿å­˜æ¨¡å‹"""
        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'model_type': self.model_type,
            'num_classes': self.num_classes,
            'class_to_idx': self.class_to_idx,
            'idx_to_class': self.idx_to_class
        }
        
        torch.save(checkpoint, filename)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filename}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ“± MobileNet Simpson è§’è‰²åˆ†é¡å™¨ - è¶…å¿«é€Ÿç‰ˆ")
    print("=" * 60)
    
    # æª¢æŸ¥ GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {device}")
    
    # è‡ªå‹•æª¢æ¸¬è³‡æ–™è·¯å¾‘
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    possible_paths = [
        {
            'train': os.path.join(base_dir, 'Dataset', 'processed', 'train'),
            'val': os.path.join(base_dir, 'Dataset', 'processed', 'val')
        },
        {
            'train': os.path.join(base_dir, 'Dataset', 'train'),
            'val': os.path.join(base_dir, 'Dataset', 'val')
        }
    ]
    
    data_paths = None
    for paths in possible_paths:
        if os.path.exists(paths['train']):
            data_paths = paths
            print(f"âœ… æ‰¾åˆ°è³‡æ–™è·¯å¾‘: {paths['train']}")
            break
    
    if data_paths is None:
        print("âŒ æ‰¾ä¸åˆ°è¨“ç·´è³‡æ–™ï¼")
        return
    
    # é¸æ“‡æ¨¡å‹
    print("\nğŸ¯ é¸æ“‡ MobileNet æ¨¡å‹:")
    print("1. mobilenet_v3_small - è¶…å¿« (2.5M åƒæ•¸)")
    print("2. mobilenet_v2 - å¹³è¡¡ (3.5M åƒæ•¸) [æ¨è–¦]")
    print("3. mobilenet_v3_large - è¼ƒæº–ç¢º (5.5M åƒæ•¸)")
    
    choice = input("è«‹é¸æ“‡ (1/2/3ï¼Œé è¨­2): ").strip()
    model_mapping = {
        '1': 'mobilenet_v3_small',
        '2': 'mobilenet_v2',
        '3': 'mobilenet_v3_large'
    }
    model_type = model_mapping.get(choice, 'mobilenet_v2')
    
    # åˆå§‹åŒ–åˆ†é¡å™¨
    classifier = MobileNetCharacterClassifier(
        num_classes=50,
        model_type=model_type,
        device=device
    )
    
    # æº–å‚™è³‡æ–™
    train_dataset, val_dataset = classifier.prepare_data(data_paths)
    
    # å¿«é€Ÿè¨“ç·´è¨­å®š
    print("\nâš¡ å¿«é€Ÿè¨“ç·´è¨­å®š (é‡å° MobileNet å„ªåŒ–):")
    batch_size = 128  # å¤§ batch size
    epochs = 20       # è¼ƒå°‘è¼ªæ•¸ï¼Œå› ç‚ºæ”¶æ–‚å¿«
    lr = 2e-3        # è¼ƒé«˜å­¸ç¿’ç‡
    
    print(f"   Batch size: {batch_size}")
    print(f"   è¨“ç·´è¼ªæ•¸: {epochs}")
    print(f"   å­¸ç¿’ç‡: {lr}")
    
    # é–‹å§‹è¨“ç·´
    best_acc = classifier.train_fast(
        train_dataset=train_dataset,
        val_dataset=val_dataset,
        batch_size=batch_size,
        epochs=epochs,
        lr=lr
    )
    
    print(f"\nğŸŠ å¿«é€Ÿè¨“ç·´å®Œæˆï¼æœ€ä½³æº–ç¢ºç‡: {best_acc:.2f}%")
    print("ğŸ’¡ å¦‚æœæº–ç¢ºç‡æ»¿æ„ï¼Œå¯ä»¥ç”¨æ­¤æ¨¡å‹å¿«é€Ÿéƒ¨ç½²")
    print("ğŸ’¡ å¦‚æœéœ€è¦æ›´é«˜æº–ç¢ºç‡ï¼Œè€ƒæ…®ä½¿ç”¨ EfficientNet æˆ– ResNet")

if __name__ == "__main__":
    main()