#!/usr/bin/env python3
"""
ğŸ¯ æ¨¡å‹ç¬¬ä¸€å±¤æ¬Šé‡èˆ‡ç‰¹å¾µåœ–å¯è¦–åŒ–å·¥å…·

åŠŸèƒ½ï¼š
- å¯è¦–åŒ–æ¨¡å‹ç¬¬ä¸€å±¤çš„æ¬Šé‡ (filters/kernels)
- åˆ†æå–®å¼µåœ–ç‰‡ç¶“éç¬¬ä¸€å±¤å¾Œçš„ç‰¹å¾µåœ–
- è¨ˆç®—ä¸¦é¡¯ç¤ºæ³¨æ„åŠ›ç†±åŠ›åœ–
- æ¯”è¼ƒä¸åŒé€šé“çš„éŸ¿æ‡‰å¼·åº¦
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import cv2
import os
import glob
import timm
from pathlib import Path
import pandas as pd
from matplotlib.patches import Rectangle
import warnings
warnings.filterwarnings('ignore')

class FirstLayerVisualizer:
    """
    ç¬¬ä¸€å±¤æ¬Šé‡èˆ‡ç‰¹å¾µåœ–å¯è¦–åŒ–å™¨
    """
    
    def __init__(self, model_path, device=None):
        """
        åˆå§‹åŒ–å¯è¦–åŒ–å™¨
        
        Args:
            model_path: è¨“ç·´å¥½çš„æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth)
            device: è¨ˆç®—è¨­å‚™
        """
        self.model_path = model_path
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.first_layer = None
        self.model_name = ""
        self.num_classes = 0
        
        print(f"ğŸ” ç¬¬ä¸€å±¤å¯è¦–åŒ–å™¨åˆå§‹åŒ–")
        print(f"ğŸ“ æ¨¡å‹æª”æ¡ˆ: {model_path}")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # è¼‰å…¥æ¨¡å‹
        self._load_model()
        
    def _load_model(self):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹ä¸¦æå–ç¬¬ä¸€å±¤"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {self.model_path}")
        
        print(f"ğŸ“‚ è¼‰å…¥æ¨¡å‹...")
        checkpoint = torch.load(self.model_path, map_location=self.device)
        
        # æå–æ¨¡å‹è³‡è¨Š
        self.model_name = checkpoint.get('model_name', 'unknown')
        self.num_classes = checkpoint.get('num_classes', 50)
        
        # å‰µå»ºæ¨¡å‹æ¶æ§‹
        try:
            self.model = timm.create_model(
                self.model_name,
                pretrained=False,
                num_classes=self.num_classes
            )
        except Exception as e:
            print(f"âš ï¸ ä½¿ç”¨ timm å‰µå»ºæ¨¡å‹å¤±æ•—: {e}")
            raise e
        
        # è¼‰å…¥è¨“ç·´å¥½çš„æ¬Šé‡
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # æå–ç¬¬ä¸€å±¤
        self._extract_first_layer()
        
        print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
        print(f"   æ¨¡å‹: {self.model_name}")
        print(f"   ç¬¬ä¸€å±¤: {type(self.first_layer).__name__}")
        if hasattr(self.first_layer, 'weight'):
            weight_shape = self.first_layer.weight.shape
            print(f"   æ¬Šé‡å½¢ç‹€: {weight_shape}")
            print(f"   filtersæ•¸é‡: {weight_shape[0]}")
            print(f"   kernelå¤§å°: {weight_shape[2]}x{weight_shape[3]}")
        
    def _extract_first_layer(self):
        """æå–æ¨¡å‹çš„ç¬¬ä¸€å±¤å·ç©å±¤"""
        # å°‹æ‰¾ç¬¬ä¸€å€‹å·ç©å±¤
        for name, module in self.model.named_modules():
            if isinstance(module, nn.Conv2d):
                self.first_layer = module
                self.first_layer_name = name
                print(f"ğŸ¯ æ‰¾åˆ°ç¬¬ä¸€å±¤å·ç©: {name}")
                break
        
        if self.first_layer is None:
            raise ValueError("æ‰¾ä¸åˆ°å·ç©å±¤ï¼")
    
    def get_transforms(self):
        """ç²å–åœ–ç‰‡é è™•ç†è®Šæ›"""
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def load_image(self, image_path):
        """
        è¼‰å…¥ä¸¦é è™•ç†åœ–ç‰‡
        
        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            
        Returns:
            original_image: åŸå§‹åœ–ç‰‡ (PIL)
            processed_image: é è™•ç†å¾Œçš„åœ–ç‰‡ (tensor)
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°åœ–ç‰‡: {image_path}")
        
        # è¼‰å…¥åŸå§‹åœ–ç‰‡
        original_image = Image.open(image_path).convert('RGB')
        
        # é è™•ç†
        transform = self.get_transforms()
        processed_image = transform(original_image).unsqueeze(0)  # æ·»åŠ  batch ç¶­åº¦
        
        print(f"ğŸ“· åœ–ç‰‡è¼‰å…¥æˆåŠŸ: {image_path}")
        print(f"   åŸå§‹å°ºå¯¸: {original_image.size}")
        print(f"   è™•ç†å¾Œå°ºå¯¸: {processed_image.shape}")
        
        return original_image, processed_image
    
    def visualize_first_layer_weights(self, save_path=None, figsize=(20, 15)):
        """
        å¯è¦–åŒ–ç¬¬ä¸€å±¤çš„æ¬Šé‡ (filters/kernels)
        
        Args:
            save_path: ä¿å­˜è·¯å¾‘
            figsize: åœ–ç‰‡å°ºå¯¸
        """
        print(f"\nğŸ¨ å¯è¦–åŒ–ç¬¬ä¸€å±¤æ¬Šé‡...")
        
        if self.first_layer is None or not hasattr(self.first_layer, 'weight'):
            raise ValueError("ç¬¬ä¸€å±¤æ²’æœ‰æ¬Šé‡å¯ä»¥å¯è¦–åŒ–")
        
        # å–å¾—æ¬Šé‡
        weights = self.first_layer.weight.data.cpu().numpy()  # shape: (out_channels, in_channels, H, W)
        out_channels, in_channels, kernel_h, kernel_w = weights.shape
        
        print(f"   æ¬Šé‡å½¢ç‹€: {weights.shape}")
        print(f"   å°‡é¡¯ç¤ºå‰64å€‹filter...")
        
        # é™åˆ¶é¡¯ç¤ºçš„filteræ•¸é‡
        max_filters = min(64, out_channels)
        cols = 8
        rows = (max_filters + cols - 1) // cols
        
        fig, axes = plt.subplots(rows, cols, figsize=figsize)
        axes = axes.flatten() if rows > 1 else [axes] if rows == 1 else []
        
        for i in range(max_filters):
            ax = axes[i]
            
            # å°æ–¼RGBè¼¸å…¥ï¼Œå–ç¬¬ä¸€å€‹è¼¸å…¥é€šé“æˆ–åˆä½µæ‰€æœ‰é€šé“
            if in_channels == 3:  # RGBåœ–ç‰‡
                # å°‡RGBä¸‰å€‹é€šé“çš„æ¬Šé‡åˆä½µç‚ºç°åº¦åœ–
                filter_weight = np.mean(weights[i], axis=0)
            else:
                filter_weight = weights[i, 0]  # å–ç¬¬ä¸€å€‹é€šé“
            
            # æ¨™æº–åŒ–åˆ° [0, 1]
            filter_weight = (filter_weight - filter_weight.min()) / (filter_weight.max() - filter_weight.min() + 1e-8)
            
            # é¡¯ç¤ºæ¬Šé‡
            im = ax.imshow(filter_weight, cmap='viridis', interpolation='nearest')
            ax.set_title(f'Filter {i+1}', fontsize=8)
            ax.axis('off')
            
            # æ·»åŠ é¡è‰²æ¢
            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        
        # éš±è—å¤šé¤˜çš„å­åœ–
        for i in range(max_filters, len(axes)):
            axes[i].axis('off')
        
        plt.suptitle(f'First Layer Weights ({self.model_name})\nShowing {max_filters}/{out_channels} filters', 
                     fontsize=16, y=0.98)
        plt.tight_layout()
        
        # ä¿å­˜åœ–ç‰‡
        if save_path is None:
            save_path = f"{self.model_name}_first_layer_weights.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ç¬¬ä¸€å±¤æ¬Šé‡å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        return weights
    
    def get_feature_maps(self, image_tensor):
        """
        ç²å–åœ–ç‰‡ç¶“éç¬¬ä¸€å±¤å¾Œçš„ç‰¹å¾µåœ–
        
        Args:
            image_tensor: é è™•ç†å¾Œçš„åœ–ç‰‡tensor
            
        Returns:
            feature_maps: ç‰¹å¾µåœ– (numpy array)
        """
        print(f"\nğŸ” è¨ˆç®—ç‰¹å¾µåœ–...")
        
        self.model.eval()
        with torch.no_grad():
            image_tensor = image_tensor.to(self.device)
            
            # å‰å‘å‚³æ’­åˆ°ç¬¬ä¸€å±¤
            feature_maps = self.first_layer(image_tensor)
            
        feature_maps = feature_maps.cpu().numpy()[0]  # ç§»é™¤batchç¶­åº¦
        
        print(f"   ç‰¹å¾µåœ–å½¢ç‹€: {feature_maps.shape}")
        print(f"   é€šé“æ•¸: {feature_maps.shape[0]}")
        
        return feature_maps
    
    def visualize_feature_maps(self, image_tensor, save_path=None, figsize=(20, 15), max_channels=64):
        """
        å¯è¦–åŒ–ç‰¹å¾µåœ–
        
        Args:
            image_tensor: é è™•ç†å¾Œçš„åœ–ç‰‡tensor
            save_path: ä¿å­˜è·¯å¾‘
            figsize: åœ–ç‰‡å°ºå¯¸
            max_channels: æœ€å¤§é¡¯ç¤ºé€šé“æ•¸
        """
        print(f"\nğŸ¨ å¯è¦–åŒ–ç‰¹å¾µåœ–...")
        
        # ç²å–ç‰¹å¾µåœ–
        feature_maps = self.get_feature_maps(image_tensor)
        num_channels = feature_maps.shape[0]
        
        # é™åˆ¶é¡¯ç¤ºçš„é€šé“æ•¸
        max_channels = min(max_channels, num_channels)
        cols = 8
        rows = (max_channels + cols - 1) // cols
        
        fig, axes = plt.subplots(rows, cols, figsize=figsize)
        axes = axes.flatten() if rows > 1 else [axes] if rows == 1 else []
        
        for i in range(max_channels):
            ax = axes[i]
            
            # å–å¾—ç‰¹å¾µåœ–
            feature_map = feature_maps[i]
            
            # é¡¯ç¤ºç‰¹å¾µåœ–
            im = ax.imshow(feature_map, cmap='hot', interpolation='bilinear')
            ax.set_title(f'Channel {i+1}', fontsize=8)
            ax.axis('off')
            
            # æ·»åŠ é¡è‰²æ¢
            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        
        # éš±è—å¤šé¤˜çš„å­åœ–
        for i in range(max_channels, len(axes)):
            axes[i].axis('off')
        
        plt.suptitle(f'Feature Maps After First Layer ({self.model_name})\nShowing {max_channels}/{num_channels} channels', 
                     fontsize=16, y=0.98)
        plt.tight_layout()
        
        # ä¿å­˜åœ–ç‰‡
        if save_path is None:
            save_path = f"{self.model_name}_feature_maps.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ç‰¹å¾µåœ–å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        return feature_maps
    
    def create_attention_heatmap(self, image_tensor, original_image, save_path=None, figsize=(15, 5)):
        """
        å‰µå»ºæ³¨æ„åŠ›ç†±åŠ›åœ– - é¡¯ç¤ºæ¨¡å‹å°åœ–ç‰‡ä¸åŒå€åŸŸçš„æ³¨æ„ç¨‹åº¦
        
        Args:
            image_tensor: é è™•ç†å¾Œçš„åœ–ç‰‡tensor
            original_image: åŸå§‹åœ–ç‰‡ (PIL)
            save_path: ä¿å­˜è·¯å¾‘
            figsize: åœ–ç‰‡å°ºå¯¸
        """
        print(f"\nğŸ”¥ å‰µå»ºæ³¨æ„åŠ›ç†±åŠ›åœ–...")
        
        # ç²å–ç‰¹å¾µåœ–
        feature_maps = self.get_feature_maps(image_tensor)
        
        # è¨ˆç®—æ‰€æœ‰é€šé“çš„å¹³å‡éŸ¿æ‡‰å¼·åº¦
        avg_feature_map = np.mean(feature_maps, axis=0)
        
        # è¨ˆç®—æœ€å¤§éŸ¿æ‡‰é€šé“
        max_response_channel = np.argmax(np.sum(feature_maps.reshape(feature_maps.shape[0], -1), axis=1))
        max_feature_map = feature_maps[max_response_channel]
        
        # å°‡ç‰¹å¾µåœ–ç¸®æ”¾åˆ°åŸå§‹åœ–ç‰‡å°ºå¯¸
        original_size = original_image.size  # (width, height)
        avg_heatmap = cv2.resize(avg_feature_map, original_size, interpolation=cv2.INTER_LINEAR)
        max_heatmap = cv2.resize(max_feature_map, original_size, interpolation=cv2.INTER_LINEAR)
        
        # æ¨™æº–åŒ–ç†±åŠ›åœ–
        avg_heatmap = (avg_heatmap - avg_heatmap.min()) / (avg_heatmap.max() - avg_heatmap.min() + 1e-8)
        max_heatmap = (max_heatmap - max_heatmap.min()) / (max_heatmap.max() - max_heatmap.min() + 1e-8)
        
        # å‰µå»ºåœ–ç‰‡
        fig, axes = plt.subplots(1, 3, figsize=figsize)
        
        # åŸå§‹åœ–ç‰‡
        axes[0].imshow(original_image)
        axes[0].set_title('Original Image', fontsize=12)
        axes[0].axis('off')
        
        # å¹³å‡æ³¨æ„åŠ›ç†±åŠ›åœ–
        axes[1].imshow(original_image, alpha=0.6)
        im1 = axes[1].imshow(avg_heatmap, cmap='jet', alpha=0.4, interpolation='bilinear')
        axes[1].set_title('Average Attention Heatmap\n(All Channels)', fontsize=12)
        axes[1].axis('off')
        plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)
        
        # æœ€å¤§éŸ¿æ‡‰é€šé“ç†±åŠ›åœ–
        axes[2].imshow(original_image, alpha=0.6)
        im2 = axes[2].imshow(max_heatmap, cmap='jet', alpha=0.4, interpolation='bilinear')
        axes[2].set_title(f'Max Response Channel\n(Channel {max_response_channel+1})', fontsize=12)
        axes[2].axis('off')
        plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)
        
        plt.suptitle(f'Attention Heatmaps ({self.model_name})', fontsize=16, y=1.02)
        plt.tight_layout()
        
        # ä¿å­˜åœ–ç‰‡
        if save_path is None:
            save_path = f"{self.model_name}_attention_heatmap.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ æ³¨æ„åŠ›ç†±åŠ›åœ–å·²ä¿å­˜: {save_path}")
        print(f"   æœ€å¤§éŸ¿æ‡‰é€šé“: {max_response_channel+1}")
        print(f"   æœ€å¤§éŸ¿æ‡‰å€¼: {feature_maps[max_response_channel].max():.4f}")
        
        plt.show()
        
        return avg_heatmap, max_heatmap, max_response_channel
    
    def analyze_channel_responses(self, image_tensor, save_path=None, figsize=(15, 10)):
        """
        åˆ†æå„é€šé“çš„éŸ¿æ‡‰å¼·åº¦
        
        Args:
            image_tensor: é è™•ç†å¾Œçš„åœ–ç‰‡tensor
            save_path: ä¿å­˜è·¯å¾‘
            figsize: åœ–ç‰‡å°ºå¯¸
        """
        print(f"\nğŸ“Š åˆ†æé€šé“éŸ¿æ‡‰å¼·åº¦...")
        
        # ç²å–ç‰¹å¾µåœ–
        feature_maps = self.get_feature_maps(image_tensor)
        num_channels = feature_maps.shape[0]
        
        # è¨ˆç®—æ¯å€‹é€šé“çš„çµ±è¨ˆè³‡è¨Š
        channel_stats = []
        for i in range(num_channels):
            fm = feature_maps[i]
            stats = {
                'channel': i + 1,
                'mean': np.mean(fm),
                'max': np.max(fm),
                'std': np.std(fm),
                'sum': np.sum(fm),
                'positive_ratio': np.sum(fm > 0) / fm.size
            }
            channel_stats.append(stats)
        
        df = pd.DataFrame(channel_stats)
        
        # å‰µå»ºåœ–è¡¨
        fig, axes = plt.subplots(2, 2, figsize=figsize)
        
        # 1. æœ€å¤§éŸ¿æ‡‰å€¼æ’åº
        df_sorted_max = df.sort_values('max', ascending=False)
        axes[0, 0].bar(range(len(df_sorted_max)), df_sorted_max['max'])
        axes[0, 0].set_title('Maximum Response by Channel')
        axes[0, 0].set_xlabel('Channel (sorted by max response)')
        axes[0, 0].set_ylabel('Max Response')
        axes[0, 0].grid(alpha=0.3)
        
        # 2. å¹³å‡éŸ¿æ‡‰å€¼æ’åº
        df_sorted_mean = df.sort_values('mean', ascending=False)
        axes[0, 1].bar(range(len(df_sorted_mean)), df_sorted_mean['mean'])
        axes[0, 1].set_title('Mean Response by Channel')
        axes[0, 1].set_xlabel('Channel (sorted by mean response)')
        axes[0, 1].set_ylabel('Mean Response')
        axes[0, 1].grid(alpha=0.3)
        
        # 3. éŸ¿æ‡‰ç¸½å’Œæ’åº
        df_sorted_sum = df.sort_values('sum', ascending=False)
        axes[1, 0].bar(range(len(df_sorted_sum)), df_sorted_sum['sum'])
        axes[1, 0].set_title('Total Response by Channel')
        axes[1, 0].set_xlabel('Channel (sorted by total response)')
        axes[1, 0].set_ylabel('Total Response')
        axes[1, 0].grid(alpha=0.3)
        
        # 4. æ­£å€¼æ¯”ä¾‹
        df_sorted_pos = df.sort_values('positive_ratio', ascending=False)
        axes[1, 1].bar(range(len(df_sorted_pos)), df_sorted_pos['positive_ratio'])
        axes[1, 1].set_title('Positive Response Ratio by Channel')
        axes[1, 1].set_xlabel('Channel (sorted by positive ratio)')
        axes[1, 1].set_ylabel('Positive Ratio')
        axes[1, 1].grid(alpha=0.3)
        
        plt.suptitle(f'Channel Response Analysis ({self.model_name})', fontsize=16, y=1.02)
        plt.tight_layout()
        
        # ä¿å­˜åœ–ç‰‡å’Œæ•¸æ“š
        if save_path is None:
            save_path = f"{self.model_name}_channel_analysis"
        
        plt.savefig(f"{save_path}.png", dpi=300, bbox_inches='tight')
        df.to_csv(f"{save_path}.csv", index=False)
        
        print(f"ğŸ’¾ é€šé“åˆ†æå·²ä¿å­˜: {save_path}.png, {save_path}.csv")
        
        # é¡¯ç¤ºçµ±è¨ˆæ‘˜è¦
        print(f"\nğŸ“Š é€šé“éŸ¿æ‡‰çµ±è¨ˆæ‘˜è¦:")
        print(f"   ç¸½é€šé“æ•¸: {num_channels}")
        print(f"   æœ€é«˜éŸ¿æ‡‰: {df['max'].max():.4f} (é€šé“ {df.loc[df['max'].idxmax(), 'channel']})")
        print(f"   æœ€ä½éŸ¿æ‡‰: {df['max'].min():.4f} (é€šé“ {df.loc[df['max'].idxmin(), 'channel']})")
        print(f"   å¹³å‡éŸ¿æ‡‰: {df['mean'].mean():.4f}")
        print(f"   éŸ¿æ‡‰æ¨™æº–å·®: {df['mean'].std():.4f}")
        
        plt.show()
        
        return df

def get_available_models():
    """å°‹æ‰¾å¯ç”¨çš„æ¨¡å‹æª”æ¡ˆ"""
    print("ğŸ” å°‹æ‰¾å¯ç”¨çš„æ¨¡å‹æª”æ¡ˆ...")
    
    patterns = ["*.pth", "efficientnet*.pth", "convnext*.pth"]
    model_files = []
    for pattern in patterns:
        model_files.extend(glob.glob(pattern))
    
    model_files = list(set(model_files))
    model_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    
    return model_files

def get_sample_images():
    """ç²å–ç¯„ä¾‹åœ–ç‰‡"""
    print("ğŸ–¼ï¸ å°‹æ‰¾ç¯„ä¾‹åœ–ç‰‡...")
    
    # å¯èƒ½çš„åœ–ç‰‡è·¯å¾‘
    possible_paths = [
        "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/preprocessed/val/**/*.jpg",
        "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/preprocessed/val/**/*.png",
        "/mnt/e/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset/preprocessed/val/**/*.jpg",
        "Dataset/preprocessed/val/**/*.jpg",
        "../Dataset/preprocessed/val/**/*.jpg",
        "*.jpg", "*.png", "*.jpeg"
    ]
    
    image_files = []
    for pattern in possible_paths:
        image_files.extend(glob.glob(pattern, recursive=True))
    
    # å»é™¤é‡è¤‡ä¸¦é™åˆ¶æ•¸é‡
    image_files = list(set(image_files))
    image_files = image_files[:20]  # æœ€å¤šé¡¯ç¤º20å¼µ
    
    return image_files

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¨ ç¬¬ä¸€å±¤æ¬Šé‡èˆ‡ç‰¹å¾µåœ–å¯è¦–åŒ–å·¥å…·")
    print("=" * 60)
    print("ğŸ“Š åŠŸèƒ½: æ¬Šé‡å¯è¦–åŒ–, ç‰¹å¾µåœ–åˆ†æ, æ³¨æ„åŠ›ç†±åŠ›åœ–")
    print("=" * 60)
    
    # 1. é¸æ“‡æ¨¡å‹æª”æ¡ˆ
    model_files = get_available_models()
    
    if not model_files:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•æ¨¡å‹æª”æ¡ˆï¼")
        return
    
    print(f"\nğŸ“‚ æ‰¾åˆ° {len(model_files)} å€‹æ¨¡å‹æª”æ¡ˆ:")
    for i, file in enumerate(model_files, 1):
        file_size = os.path.getsize(file) / (1024 * 1024)
        time_str = pd.Timestamp.fromtimestamp(os.path.getmtime(file)).strftime('%m/%d %H:%M')
        print(f"  {i}. {file} ({file_size:.1f}MB, {time_str})")
    
    try:
        choice = int(input(f"\nè«‹é¸æ“‡æ¨¡å‹æª”æ¡ˆ (1-{len(model_files)}): ")) - 1
        model_path = model_files[choice]
    except (ValueError, IndexError):
        print("âŒ é¸æ“‡ç„¡æ•ˆï¼Œä½¿ç”¨æœ€æ–°çš„æ¨¡å‹æª”æ¡ˆ")
        model_path = model_files[0]
    
    # 2. åˆå§‹åŒ–å¯è¦–åŒ–å™¨
    try:
        visualizer = FirstLayerVisualizer(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return
    
    # 3. å¯è¦–åŒ–ç¬¬ä¸€å±¤æ¬Šé‡
    print(f"\nğŸ¨ æ­¥é©Ÿ1: å¯è¦–åŒ–ç¬¬ä¸€å±¤æ¬Šé‡")
    try:
        weights = visualizer.visualize_first_layer_weights()
    except Exception as e:
        print(f"âŒ æ¬Šé‡å¯è¦–åŒ–å¤±æ•—: {e}")
        return
    
    # 4. é¸æ“‡æ¸¬è©¦åœ–ç‰‡
    image_files = get_sample_images()
    
    if not image_files:
        print("âŒ æ‰¾ä¸åˆ°ç¯„ä¾‹åœ–ç‰‡ï¼")
        return
    
    print(f"\nğŸ–¼ï¸ æ‰¾åˆ° {len(image_files)} å¼µåœ–ç‰‡:")
    for i, file in enumerate(image_files[:10], 1):  # åªé¡¯ç¤ºå‰10å¼µ
        print(f"  {i}. {os.path.basename(file)}")
    
    try:
        choice = int(input(f"\nè«‹é¸æ“‡åœ–ç‰‡ (1-{min(10, len(image_files))}): ")) - 1
        image_path = image_files[choice]
    except (ValueError, IndexError):
        print("âŒ é¸æ“‡ç„¡æ•ˆï¼Œä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡")
        image_path = image_files[0]
    
    # 5. è¼‰å…¥åœ–ç‰‡
    try:
        original_image, processed_image = visualizer.load_image(image_path)
    except Exception as e:
        print(f"âŒ åœ–ç‰‡è¼‰å…¥å¤±æ•—: {e}")
        return
    
    # 6. å¯è¦–åŒ–ç‰¹å¾µåœ–
    print(f"\nğŸ¨ æ­¥é©Ÿ2: å¯è¦–åŒ–ç‰¹å¾µåœ–")
    try:
        feature_maps = visualizer.visualize_feature_maps(processed_image)
    except Exception as e:
        print(f"âŒ ç‰¹å¾µåœ–å¯è¦–åŒ–å¤±æ•—: {e}")
        return
    
    # 7. å‰µå»ºæ³¨æ„åŠ›ç†±åŠ›åœ–
    print(f"\nğŸ¨ æ­¥é©Ÿ3: å‰µå»ºæ³¨æ„åŠ›ç†±åŠ›åœ–")
    try:
        avg_heatmap, max_heatmap, max_channel = visualizer.create_attention_heatmap(
            processed_image, original_image
        )
    except Exception as e:
        print(f"âŒ æ³¨æ„åŠ›ç†±åŠ›åœ–å‰µå»ºå¤±æ•—: {e}")
        return
    
    # 8. åˆ†æé€šé“éŸ¿æ‡‰
    print(f"\nğŸ¨ æ­¥é©Ÿ4: åˆ†æé€šé“éŸ¿æ‡‰")
    try:
        channel_df = visualizer.analyze_channel_responses(processed_image)
    except Exception as e:
        print(f"âŒ é€šé“åˆ†æå¤±æ•—: {e}")
        return
    
    print(f"\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼")
    print(f"ğŸ“ çµæœå·²ä¿å­˜åˆ°ç•¶å‰ç›®éŒ„")
    print(f"ğŸ–¼ï¸ åˆ†æåœ–ç‰‡: {os.path.basename(image_path)}")

if __name__ == "__main__":
    main()