#!/usr/bin/env python3
"""
ğŸ”® EfficientNet æ¨¡å‹æ¨ç†å·¥å…· - Simpson è§’è‰²é æ¸¬

åŠŸèƒ½ï¼š
- è¼‰å…¥è¨“ç·´å¥½çš„ EfficientNet æ¨¡å‹
- å°å–®å¼µåœ–ç‰‡æˆ–æ‰¹é‡åœ–ç‰‡é€²è¡Œé æ¸¬
- æ”¯æ´ä¿¡å¿ƒåˆ†æ•¸å’Œå‰ N é æ¸¬
- é«˜æ•ˆæ¨ç†ï¼Œé©åˆéƒ¨ç½²ä½¿ç”¨
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import timm
import os
import glob
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import json
from pathlib import Path
import argparse

class EfficientNetInference:
    """
    EfficientNet æ¨¡å‹æ¨ç†å™¨
    """
    
    def __init__(self, model_path, device=None):
        """
        åˆå§‹åŒ–æ¨ç†å™¨
        
        Args:
            model_path: æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth)
            device: è¨ˆç®—è¨­å‚™
        """
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.class_to_idx = {}
        self.idx_to_class = {}
        self.model_name = None
        
        print(f"ğŸ”® EfficientNet æ¨ç†å™¨")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # è¼‰å…¥æ¨¡å‹
        self.load_model(model_path)
        
        # æº–å‚™è®Šæ›
        self.transform = self._get_inference_transform()
        
    def load_model(self, model_path):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}")
        
        print(f"ğŸ“‚ è¼‰å…¥æ¨¡å‹: {model_path}")
        
        # è¼‰å…¥ checkpoint
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # ç²å–æ¨¡å‹è³‡è¨Š
        self.model_name = checkpoint['model_name']
        num_classes = checkpoint['num_classes']
        self.class_to_idx = checkpoint['class_to_idx']
        self.idx_to_class = checkpoint['idx_to_class']
        
        print(f"ğŸ¯ æ¨¡å‹: {self.model_name}")
        print(f"ğŸ“ é¡åˆ¥æ•¸: {num_classes}")
        
        # é‡å»ºæ¨¡å‹æ¶æ§‹
        self.model = timm.create_model(
            self.model_name,
            pretrained=False,  # ä¸éœ€è¦é è¨“ç·´æ¬Šé‡
            num_classes=num_classes
        )
        
        # è¼‰å…¥æ¬Šé‡
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()  # è¨­ç‚ºæ¨ç†æ¨¡å¼
        
        print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼")
    
    def _get_inference_transform(self):
        """ç²å–æ¨ç†ç”¨çš„åœ–ç‰‡è®Šæ›"""
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def predict_single(self, image_path, top_k=5):
        """
        é æ¸¬å–®å¼µåœ–ç‰‡
        
        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            top_k: è¿”å›å‰ k å€‹é æ¸¬çµæœ
            
        Returns:
            dict: é æ¸¬çµæœ
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°åœ–ç‰‡: {image_path}")
        
        # è¼‰å…¥ä¸¦é è™•ç†åœ–ç‰‡
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            raise ValueError(f"ç„¡æ³•è¼‰å…¥åœ–ç‰‡ {image_path}: {e}")
        
        # è®Šæ›åœ–ç‰‡
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # æ¨ç†
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
        
        # ç²å–å‰ k å€‹çµæœ
        top_probs, top_indices = torch.topk(probabilities, k=min(top_k, len(self.idx_to_class)))
        
        # æ•´ç†çµæœ
        results = {
            'image_path': image_path,
            'predictions': []
        }
        
        for i in range(len(top_indices[0])):
            class_idx = top_indices[0][i].item()
            prob = top_probs[0][i].item()
            class_name = self.idx_to_class[class_idx]
            
            results['predictions'].append({
                'class_name': class_name,
                'confidence': prob,
                'class_idx': class_idx
            })
        
        return results
    
    def predict_batch(self, image_folder, output_file=None, top_k=3):
        """
        æ‰¹é‡é æ¸¬è³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡
        
        Args:
            image_folder: åœ–ç‰‡è³‡æ–™å¤¾è·¯å¾‘
            output_file: è¼¸å‡ºçµæœæª”æ¡ˆ (JSON)
            top_k: æ¯å¼µåœ–ç‰‡è¿”å›å‰ k å€‹çµæœ
            
        Returns:
            list: æ‰€æœ‰é æ¸¬çµæœ
        """
        print(f"\nğŸ“ æ‰¹é‡æ¨ç†: {image_folder}")
        
        # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif', '*.webp']
        
        # æ”¶é›†æ‰€æœ‰åœ–ç‰‡
        image_paths = []
        for ext in image_extensions:
            image_paths.extend(glob.glob(os.path.join(image_folder, '**', ext), recursive=True))
        
        if not image_paths:
            print("âŒ æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡ï¼")
            return []
        
        print(f"ğŸ” æ‰¾åˆ° {len(image_paths)} å¼µåœ–ç‰‡")
        
        # æ‰¹é‡é æ¸¬
        all_results = []
        
        for i, image_path in enumerate(image_paths):
            try:
                result = self.predict_single(image_path, top_k=top_k)
                all_results.append(result)
                
                # é¡¯ç¤ºé€²åº¦
                if (i + 1) % 100 == 0 or (i + 1) == len(image_paths):
                    print(f"âš¡ é€²åº¦: {i+1}/{len(image_paths)} ({(i+1)/len(image_paths)*100:.1f}%)")
                
            except Exception as e:
                print(f"âŒ é æ¸¬å¤±æ•— {image_path}: {e}")
                continue
        
        # ä¿å­˜çµæœ
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(all_results, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ çµæœå·²ä¿å­˜: {output_file}")
        
        print(f"âœ… æ‰¹é‡æ¨ç†å®Œæˆï¼æˆåŠŸé æ¸¬ {len(all_results)} å¼µåœ–ç‰‡")
        return all_results
    
    def predict_and_show(self, image_path, save_plot=True):
        """
        é æ¸¬åœ–ç‰‡ä¸¦è¦–è¦ºåŒ–çµæœ
        
        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            save_plot: æ˜¯å¦ä¿å­˜çµæœåœ–ç‰‡
        """
        # é æ¸¬
        result = self.predict_single(image_path, top_k=5)
        
        # è¼‰å…¥åŸåœ–
        image = Image.open(image_path).convert('RGB')
        
        # ç¹ªè£½çµæœ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # é¡¯ç¤ºåŸåœ–
        ax1.imshow(image)
        ax1.set_title(f'åŸåœ–: {os.path.basename(image_path)}')
        ax1.axis('off')
        
        # é¡¯ç¤ºé æ¸¬çµæœ
        predictions = result['predictions']
        class_names = [pred['class_name'] for pred in predictions]
        confidences = [pred['confidence'] for pred in predictions]
        
        bars = ax2.barh(range(len(class_names)), confidences)
        ax2.set_yticks(range(len(class_names)))
        ax2.set_yticklabels(class_names)
        ax2.set_xlabel('ä¿¡å¿ƒåˆ†æ•¸')
        ax2.set_title('é æ¸¬çµæœ (å‰5å)')
        ax2.set_xlim(0, 1)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, (bar, conf) in enumerate(zip(bars, confidences)):
            ax2.text(conf + 0.01, i, f'{conf:.3f}', 
                    va='center', fontsize=10)
        
        # æ¨™è¨˜æœ€ä½³é æ¸¬
        if confidences:
            bars[0].set_color('gold')
            ax2.text(0.5, len(class_names), 
                    f'æœ€ä½³é æ¸¬: {class_names[0]} ({confidences[0]:.3f})',
                    ha='center', fontweight='bold', fontsize=12)
        
        plt.tight_layout()
        
        if save_plot:
            output_name = f"prediction_{os.path.splitext(os.path.basename(image_path))[0]}.png"
            plt.savefig(output_name, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š çµæœåœ–å·²ä¿å­˜: {output_name}")
        
        plt.show()
        
        # æ‰“å°çµæœ
        print(f"\nğŸ¯ é æ¸¬çµæœ:")
        for i, pred in enumerate(predictions):
            icon = "ğŸ†" if i == 0 else f"{i+1}."
            print(f"{icon} {pred['class_name']}: {pred['confidence']:.3f}")
        
        return result
    
    def get_model_info(self):
        """ç²å–æ¨¡å‹è³‡è¨Š"""
        total_params = sum(p.numel() for p in self.model.parameters())
        
        info = {
            'model_name': self.model_name,
            'num_classes': len(self.idx_to_class),
            'total_parameters': f"{total_params/1e6:.1f}M",
            'device': str(self.device),
            'class_names': list(self.class_to_idx.keys())
        }
        
        return info
    
    def print_model_info(self):
        """æ‰“å°æ¨¡å‹è³‡è¨Š"""
        info = self.get_model_info()
        
        print(f"\nğŸ“Š æ¨¡å‹è³‡è¨Š:")
        print(f"   æ¨¡å‹: {info['model_name']}")
        print(f"   é¡åˆ¥æ•¸: {info['num_classes']}")
        print(f"   åƒæ•¸é‡: {info['total_parameters']}")
        print(f"   è¨­å‚™: {info['device']}")
        print(f"   é¡åˆ¥åˆ—è¡¨: {info['class_names'][:10]}..." if len(info['class_names']) > 10 else f"   é¡åˆ¥åˆ—è¡¨: {info['class_names']}")

def main():
    """ä¸»å‡½æ•¸ - å‘½ä»¤åˆ—ä»‹é¢"""
    parser = argparse.ArgumentParser(description="EfficientNet æ¨¡å‹æ¨ç†å·¥å…·")
    parser.add_argument('--model', '-m', required=True, help='æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth)')
    parser.add_argument('--image', '-i', help='å–®å¼µåœ–ç‰‡è·¯å¾‘')
    parser.add_argument('--folder', '-f', help='åœ–ç‰‡è³‡æ–™å¤¾è·¯å¾‘')
    parser.add_argument('--output', '-o', help='è¼¸å‡ºçµæœæª”æ¡ˆ (JSON)')
    parser.add_argument('--top-k', '-k', type=int, default=5, help='å‰ k å€‹é æ¸¬çµæœ')
    parser.add_argument('--show', action='store_true', help='é¡¯ç¤ºé æ¸¬çµæœåœ–')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ¨ç†å™¨
    try:
        inferencer = EfficientNetInference(args.model)
        inferencer.print_model_info()
    except Exception as e:
        print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
        return
    
    # åŸ·è¡Œæ¨ç†
    if args.image:
        # å–®å¼µåœ–ç‰‡æ¨ç†
        try:
            if args.show:
                result = inferencer.predict_and_show(args.image)
            else:
                result = inferencer.predict_single(args.image, top_k=args.top_k)
                print(f"\nğŸ¯ é æ¸¬çµæœ:")
                for i, pred in enumerate(result['predictions']):
                    print(f"{i+1}. {pred['class_name']}: {pred['confidence']:.3f}")
        except Exception as e:
            print(f"âŒ é æ¸¬å¤±æ•—: {e}")
    
    elif args.folder:
        # æ‰¹é‡æ¨ç†
        try:
            results = inferencer.predict_batch(
                args.folder, 
                output_file=args.output, 
                top_k=args.top_k
            )
        except Exception as e:
            print(f"âŒ æ‰¹é‡æ¨ç†å¤±æ•—: {e}")
    
    else:
        print("âŒ è«‹æŒ‡å®š --image æˆ– --folder åƒæ•¸")
        print("ğŸ’¡ ä½¿ç”¨ç¯„ä¾‹:")
        print("   python EfficientNet_inference.py -m best_model.pth -i test_image.jpg --show")
        print("   python EfficientNet_inference.py -m best_model.pth -f test_folder/ -o results.json")

if __name__ == "__main__":
    # å¦‚æœæ²’æœ‰å‘½ä»¤åˆ—åƒæ•¸ï¼Œä½¿ç”¨äº’å‹•æ¨¡å¼
    import sys
    
    if len(sys.argv) == 1:
        print("ğŸ”® EfficientNet æ¨ç†å·¥å…· - äº’å‹•æ¨¡å¼")
        print("=" * 50)
        
        # å°‹æ‰¾å¯ç”¨çš„æ¨¡å‹
        model_files = glob.glob("*.pth") + glob.glob("best_*.pth")
        
        if not model_files:
            print("âŒ ç•¶å‰ç›®éŒ„æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ (.pth)")
            model_path = input("è«‹è¼¸å…¥æ¨¡å‹æª”æ¡ˆè·¯å¾‘: ").strip()
        else:
            print("ğŸ” æ‰¾åˆ°ä»¥ä¸‹æ¨¡å‹æª”æ¡ˆ:")
            for i, model_file in enumerate(model_files):
                print(f"{i+1}. {model_file}")
            
            choice = input(f"è«‹é¸æ“‡æ¨¡å‹ (1-{len(model_files)}): ").strip()
            try:
                model_path = model_files[int(choice)-1]
            except (ValueError, IndexError):
                model_path = model_files[0]
        
        # åˆå§‹åŒ–æ¨ç†å™¨
        try:
            inferencer = EfficientNetInference(model_path)
            inferencer.print_model_info()
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            exit(1)
        
        # é¸æ“‡æ¨ç†æ¨¡å¼
        print(f"\nğŸ¯ é¸æ“‡æ¨ç†æ¨¡å¼:")
        print("1. å–®å¼µåœ–ç‰‡é æ¸¬")
        print("2. æ‰¹é‡åœ–ç‰‡é æ¸¬")
        
        mode = input("è«‹é¸æ“‡ (1/2): ").strip()
        
        if mode == "1":
            image_path = input("è«‹è¼¸å…¥åœ–ç‰‡è·¯å¾‘: ").strip()
            show = input("é¡¯ç¤ºçµæœåœ–ï¼Ÿ(y/n): ").strip().lower() == 'y'
            
            try:
                if show:
                    inferencer.predict_and_show(image_path)
                else:
                    result = inferencer.predict_single(image_path)
                    print(f"\nğŸ¯ é æ¸¬çµæœ:")
                    for i, pred in enumerate(result['predictions']):
                        print(f"{i+1}. {pred['class_name']}: {pred['confidence']:.3f}")
            except Exception as e:
                print(f"âŒ é æ¸¬å¤±æ•—: {e}")
        
        elif mode == "2":
            folder_path = input("è«‹è¼¸å…¥åœ–ç‰‡è³‡æ–™å¤¾è·¯å¾‘: ").strip()
            output_file = input("è¼¸å‡ºæª”æ¡ˆåç¨± (é è¨­ results.json): ").strip() or "results.json"
            
            try:
                inferencer.predict_batch(folder_path, output_file=output_file)
            except Exception as e:
                print(f"âŒ æ‰¹é‡æ¨ç†å¤±æ•—: {e}")
    else:
        main()