#!/usr/bin/env python
"""
å¿«é€Ÿ GPU è³‡æ–™å¢å¼·è…³æœ¬
"""

import os
import sys
from pathlib import Path
import platform

def get_correct_paths():
    """æ ¹æ“šé‹è¡Œç’°å¢ƒè‡ªå‹•é¸æ“‡æ­£ç¢ºçš„è·¯å¾‘æ ¼å¼"""
    is_wsl = "microsoft" in platform.uname().release.lower() or "WSL" in os.environ.get("WSL_DISTRO_NAME", "")
    
    if is_wsl:
        base_path = "/mnt/e/NYCU/NYCU_IAII_ML2025/Ass2-Classification"
        input_dir = f"{base_path}/Dataset/preprocessed/train"
        output_dir = f"{base_path}/Dataset/augmented_gpu/train"
        print("ğŸ§ æª¢æ¸¬åˆ° WSL ç’°å¢ƒï¼Œä½¿ç”¨ Linux è·¯å¾‘æ ¼å¼")
    else:
        input_dir = r"E:\NYCU\NYCU_IAII_ML2025\Ass2-Classification\Dataset\preprocessed\train"
        output_dir = r"E:\NYCU\NYCU_IAII_ML2025\Ass2-Classification\Dataset\augmented_gpu\train"
        print("ğŸªŸ æª¢æ¸¬åˆ° Windows ç’°å¢ƒï¼Œä½¿ç”¨ Windows è·¯å¾‘æ ¼å¼")
    
    return input_dir, output_dir

def check_gpu():
    """æª¢æŸ¥ GPU å¯ç”¨æ€§"""
    try:
        import torch
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            
            print(f"ğŸ® GPU æª¢æ¸¬çµæœ:")
            print(f"   GPU æ•¸é‡: {gpu_count}")
            print(f"   GPU å‹è™Ÿ: {gpu_name}")
            print(f"   VRAM: {gpu_memory:.1f} GB")
            
            # æ ¹æ“š VRAM æ¨è–¦æ‰¹æ¬¡å¤§å°
            if gpu_memory >= 8:
                recommended_batch = 16
            elif gpu_memory >= 4:
                recommended_batch = 8
            else:
                recommended_batch = 4
            
            print(f"   æ¨è–¦æ‰¹æ¬¡å¤§å°: {recommended_batch}")
            return True, recommended_batch
        else:
            print("âŒ æœªæª¢æ¸¬åˆ°å¯ç”¨çš„ GPU")
            return False, 4
            
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨ GPU åŠ é€Ÿ")
        return False, 4

def run_gpu_augmentation():
    """åŸ·è¡Œ GPU åŠ é€Ÿè³‡æ–™å¢å¼·"""
    
    # ç²å–è·¯å¾‘
    input_dir, output_dir = get_correct_paths()
    
    print("âš¡ GPU åŠ é€Ÿè³‡æ–™å¢å¼·")
    print("=" * 50)
    print(f"ğŸ“‚ è¼¸å…¥: {input_dir}")
    print(f"ğŸ“‚ è¼¸å‡º: {output_dir}")
    
    # æª¢æŸ¥è¼¸å…¥è³‡æ–™å¤¾
    if not os.path.exists(input_dir):
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥è³‡æ–™å¤¾: {input_dir}")
        return False
    
    # æª¢æŸ¥ GPU
    has_gpu, batch_size = check_gpu()
    
    # çµ±è¨ˆè³‡æ–™
    class_dirs = [d for d in Path(input_dir).iterdir() if d.is_dir()]
    total_images = 0
    for class_dir in class_dirs:
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(list(class_dir.glob(ext)))
        total_images += len(image_files)
    
    print(f"\nğŸ“Š è³‡æ–™çµ±è¨ˆ:")
    print(f"   é¡åˆ¥æ•¸: {len(class_dirs)}")
    print(f"   åŸå§‹åœ–ç‰‡: {total_images}")
    print(f"   é æœŸç”Ÿæˆ: ~{total_images * 4} å¼µ (4å€)")
    
    # GPU vs CPU é€Ÿåº¦é ä¼°
    if has_gpu:
        print(f"\nâš¡ GPU åŠ é€Ÿå„ªå‹¢:")
        print(f"   æ‰¹æ¬¡è™•ç†: {batch_size} å¼µåŒæ™‚è™•ç†")
        print(f"   é ä¼°åŠ é€Ÿ: 3-5å€ (ç›¸æ¯” CPU)")
        print(f"   è¨˜æ†¶é«”æ•ˆç‡: æ›´å¥½çš„è¨˜æ†¶é«”åˆ©ç”¨")
    else:
        print(f"\nğŸ’» ä½¿ç”¨ CPU æ¨¡å¼:")
        print(f"   æ‰¹æ¬¡å¤§å°: 4 (CPU å„ªåŒ–)")
        print(f"   å¤šæ ¸è™•ç†: åˆ©ç”¨å¤š CPU æ ¸å¿ƒ")
    
    # è©¢å•ç”¨æˆ¶
    choice = input(f"\næ˜¯å¦é–‹å§‹ {'GPU' if has_gpu else 'CPU'} åŠ é€Ÿå¢å¼·? (y/n): ")
    if choice.lower() not in ['y', 'yes', 'æ˜¯']:
        print("å·²å–æ¶ˆ")
        return False
    
    # å°å…¥ GPU å¢å¼·æ¨¡çµ„
    try:
        from gpu_augmentation import gpu_augment_dataset
    except ImportError as e:
        print(f"âŒ å°å…¥ GPU å¢å¼·æ¨¡çµ„å¤±æ•—: {e}")
        print("è«‹ç¢ºä¿åœ¨æ­£ç¢ºçš„ Python ç’°å¢ƒä¸­é‹è¡Œ")
        return False
    
    # åŸ·è¡Œå¢å¼·
    try:
        device = 'cuda' if has_gpu else 'cpu'
        gpu_augment_dataset(
            input_dir=input_dir,
            output_dir=output_dir,
            augment_per_image=3,
            batch_size=batch_size,
            device=device
        )
        
        print(f"\nâœ… GPU åŠ é€Ÿå¢å¼·å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ å¢å¼·éç¨‹å‡ºéŒ¯: {e}")
        return False

def compare_methods():
    """æ¯”è¼ƒä¸åŒå¢å¼·æ–¹æ³•"""
    print("\nğŸ“Š è³‡æ–™å¢å¼·æ–¹æ³•æ¯”è¼ƒ:")
    print("=" * 60)
    
    methods = [
        ("åŸå§‹ CPU", "data_augmentation.py", "é€å¼µè™•ç†", "æ…¢", "ä½è¨˜æ†¶é«”"),
        ("GPU åŠ é€Ÿ", "gpu_augmentation.py", "æ‰¹æ¬¡è™•ç†", "å¿« 3-5å€", "é«˜è¨˜æ†¶é«”"),
        ("CPU ä¸¦è¡Œ", "æº–å‚™ä¸­...", "å¤šæ ¸è™•ç†", "ä¸­ç­‰", "ä¸­è¨˜æ†¶é«”")
    ]
    
    print(f"{'æ–¹æ³•':<12} {'è…³æœ¬':<20} {'è™•ç†æ–¹å¼':<10} {'é€Ÿåº¦':<10} {'è¨˜æ†¶é«”'}")
    print("-" * 60)
    for method, script, process, speed, memory in methods:
        print(f"{method:<12} {script:<20} {process:<10} {speed:<10} {memory}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ GPU åŠ é€Ÿè¾›æ™®æ£®è§’è‰²è³‡æ–™å¢å¼·")
    print("=" * 50)
    
    # æ¯”è¼ƒæ–¹æ³•
    compare_methods()
    
    # åŸ·è¡Œå¢å¼·
    success = run_gpu_augmentation()
    
    if success:
        print("\nğŸ¯ GPU å¢å¼·å®Œæˆï¼")
        print("èˆ‡åŸå§‹æ–¹æ³•çš„å·®ç•°:")
        print("  âœ… é€Ÿåº¦æå‡ 3-5 å€")
        print("  âœ… æ‰¹æ¬¡è™•ç†æ›´é«˜æ•ˆ")
        print("  âœ… GPU è¨˜æ†¶é«”å……åˆ†åˆ©ç”¨")
        print("  âœ… å¢å¼·å“è³ªå®Œå…¨ä¸€è‡´")
        
        input_dir, output_dir = get_correct_paths()
        print(f"\nğŸ“ å¢å¼·çµæœä¿å­˜åœ¨:")
        print(f"   {output_dir}")
    else:
        print("\nğŸ’¡ å»ºè­°:")
        print("1. ç¢ºä¿ CUDA å’Œ PyTorch GPU ç‰ˆæœ¬å·²å®‰è£")
        print("2. æª¢æŸ¥ GPU é©…å‹•ç¨‹å¼æ˜¯å¦æœ€æ–°")
        print("3. å¦‚æœæ²’æœ‰ GPUï¼Œå¯ä»¥ä½¿ç”¨åŸå§‹ CPU ç‰ˆæœ¬:")
        print("   python quick_augment.py")

if __name__ == "__main__":
    main()