#!/usr/bin/env python3
"""
ğŸš€ EfficientNet Simpson è§’è‰²åˆ†é¡å™¨ - é«˜é€Ÿç‰ˆæœ¬

EfficientNet å„ªå‹¢ï¼š
- é€Ÿåº¦æ¯” ViT å¿« 5-10 å€
- è¨˜æ†¶é«”éœ€æ±‚ä½
- åœ¨ä¸­å°å‹è³‡æ–™é›†ä¸Šè¡¨ç¾å„ªç§€
- é©åˆå¿«é€Ÿå¯¦é©—å’Œéƒ¨ç½²
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
from torchvision import datasets
import torchvision.models as models
import timm
import os
import glob
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm
import time
import json
import platform

class EfficientNetCharacterClassifier:
    """
    ä½¿ç”¨ EfficientNet çš„é«˜é€Ÿè§’è‰²åˆ†é¡å™¨
    """
    
    def __init__(self, num_classes=50, model_name='efficientnet_b3', device=None):
        """
        åˆå§‹åŒ–åˆ†é¡å™¨
        
        Args:
            num_classes: é¡åˆ¥æ•¸é‡
            model_name: EfficientNet æ¨¡å‹åç¨±
                - efficientnet_b0: æœ€å¿«ï¼Œæº–ç¢ºç‡ä¸­ç­‰
                - efficientnet_b3: å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºç‡ (æ¨è–¦)
                - efficientnet_b5: è¼ƒæ…¢ä½†æº–ç¢ºç‡é«˜
            device: è¨ˆç®—è¨­å‚™
        """
        self.num_classes = num_classes
        self.model_name = model_name
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        print(f"ğŸ¯ åˆå§‹åŒ– {model_name} åˆ†é¡å™¨")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._create_model()
        self.class_to_idx = {}
        
    def _create_model(self):
        """å‰µå»º EfficientNet æ¨¡å‹"""
        try:
            # ä½¿ç”¨ timm è¼‰å…¥é è¨“ç·´æ¨¡å‹
            model = timm.create_model(
                self.model_name,
                pretrained=True,
                num_classes=self.num_classes,
                drop_rate=0.2,
                drop_path_rate=0.2
            )
            
            # è¨ˆç®—æ¨¡å‹åƒæ•¸
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            
            print(f"ğŸ“Š æ¨¡å‹çµ±è¨ˆ:")
            print(f"   ç¸½åƒæ•¸: {total_params/1e6:.1f}M")
            print(f"   å¯è¨“ç·´åƒæ•¸: {trainable_params/1e6:.1f}M")
            
            return model.to(self.device)
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹å‰µå»ºå¤±æ•—: {e}")
            raise
    
    def get_transforms(self, is_training=True):
        """
        ç²å–è³‡æ–™è®Šæ›
        
        Args:
            is_training: æ˜¯å¦ç‚ºè¨“ç·´æ¨¡å¼
        """
        if is_training:
            # è¨“ç·´æ™‚çš„è³‡æ–™å¢å¼·
            return transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(degrees=15),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        else:
            # é©—è­‰/æ¸¬è©¦æ™‚çš„è®Šæ›
            return transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
    
    def prepare_data(self, data_paths):
        """
        æº–å‚™è³‡æ–™é›† - ä½¿ç”¨å’Œ MemoryViT ç›¸åŒçš„é…ç½®
        
        Args:
            data_paths: åŒ…å« train, val è·¯å¾‘çš„å­—å…¸
        """
        print("\nğŸ“Š æº–å‚™è³‡æ–™...")
        
        # ç¢ºèªè³‡æ–™è·¯å¾‘
        train_path = data_paths['train']
        val_path = data_paths['val']
        
        print(f"ğŸ“ è¼‰å…¥è¨“ç·´è³‡æ–™: {train_path}")
        print(f"ğŸ“ è¼‰å…¥é©—è­‰è³‡æ–™: {val_path}")
        
        # è¨“ç·´è³‡æ–™
        train_transform = self.get_transforms(is_training=True)
        train_dataset = datasets.ImageFolder(
            root=train_path,
            transform=train_transform
        )
        
        # é©—è­‰è³‡æ–™
        val_transform = self.get_transforms(is_training=False)
        val_dataset = datasets.ImageFolder(
            root=val_path,
            transform=val_transform
        )
        
        # å»ºç«‹çµ±ä¸€çš„é¡åˆ¥æ˜ å°„ï¼ˆä½¿ç”¨è¨“ç·´é›†çš„æ˜ å°„ï¼‰
        self.class_to_idx = train_dataset.class_to_idx
        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}
        
        # æª¢æŸ¥é¡åˆ¥ä¸€è‡´æ€§
        if val_dataset.class_to_idx != self.class_to_idx:
            print("âš ï¸ è­¦å‘Šï¼šè¨“ç·´é›†å’Œé©—è­‰é›†çš„é¡åˆ¥æ˜ å°„ä¸å®Œå…¨ä¸€è‡´")
            print(f"   è¨“ç·´é›†é¡åˆ¥æ•¸: {len(self.class_to_idx)}")
            print(f"   é©—è­‰é›†é¡åˆ¥æ•¸: {len(val_dataset.class_to_idx)}")
            
            # ä½¿ç”¨è¨“ç·´é›†çš„é¡åˆ¥æ˜ å°„é‡æ–°æ•´ç†é©—è­‰é›†
            val_dataset.class_to_idx = self.class_to_idx
        
        print(f"âœ… è¨“ç·´é›†: {len(train_dataset)} å¼µåœ–ç‰‡")
        print(f"âœ… é©—è­‰é›†: {len(val_dataset)} å¼µåœ–ç‰‡")
        print(f"ğŸ“ é¡åˆ¥æ•¸: {len(self.class_to_idx)}")
        
        # æ›´æ–°æ¨¡å‹çš„é¡åˆ¥æ•¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if len(self.class_to_idx) != self.num_classes:
            print(f"âš ï¸ æ›´æ–°é¡åˆ¥æ•¸ï¼š{self.num_classes} â†’ {len(self.class_to_idx)}")
            self.num_classes = len(self.class_to_idx)
            # é‡æ–°å‰µå»ºæ¨¡å‹ä»¥åŒ¹é…æ–°çš„é¡åˆ¥æ•¸
            self.model = self._create_model()
        
        # é¡¯ç¤ºé¡åˆ¥è³‡è¨Š
        print(f"ğŸ“‹ å‰10å€‹é¡åˆ¥: {list(self.class_to_idx.keys())[:10]}")
        
        # æ¸¬è©¦è³‡æ–™é›†ï¼ˆå¾é©—è­‰é›†åˆ†å‡ºä¸€éƒ¨åˆ†ï¼Œæˆ–è€…æ²’æœ‰æ¸¬è©¦é›†ï¼‰
        test_dataset = None
        
        return train_dataset, val_dataset, test_dataset
    
    def find_optimal_batch_size(self, train_dataset, start_size=16, max_size=128):
        """
        å¿«é€Ÿæ‰¾åˆ°æœ€ä½³ batch size
        
        Args:
            train_dataset: è¨“ç·´è³‡æ–™é›†
            start_size: èµ·å§‹ batch size
            max_size: æœ€å¤§ batch size
        """
        print(f"\nâš™ï¸ å°‹æ‰¾æœ€ä½³ batch size (ç¯„åœ: {start_size}-{max_size})")
        
        # æ¸¬è©¦ä¸åŒ batch size
        batch_sizes = [32, 64, 128]
        if torch.cuda.is_available():
            batch_sizes = [16, 32, 64, 128]
        
        best_batch_size = 16
        best_speed = 0
        
        for batch_size in batch_sizes:
            try:
                # æ¸¬è©¦é€™å€‹ batch size
                test_loader = DataLoader(
                    train_dataset, 
                    batch_size=batch_size, 
                    shuffle=True, 
                    num_workers=2,
                    pin_memory=True if torch.cuda.is_available() else False
                )
                
                # æ¸¬è©¦é€Ÿåº¦
                self.model.train()
                start_time = time.time()
                
                for i, (images, labels) in enumerate(test_loader):
                    if i >= 5:  # åªæ¸¬è©¦ 5 å€‹ batch
                        break
                    
                    images = images.to(self.device)
                    labels = labels.to(self.device)
                    
                    with torch.no_grad():
                        outputs = self.model(images)
                
                elapsed = time.time() - start_time
                speed = 5 * batch_size / elapsed  # æ¯ç§’è™•ç†åœ–ç‰‡æ•¸
                
                print(f"   Batch {batch_size}: {speed:.1f} åœ–ç‰‡/ç§’")
                
                if speed > best_speed:
                    best_speed = speed
                    best_batch_size = batch_size
                    
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"   Batch {batch_size}: âŒ GPU è¨˜æ†¶é«”ä¸è¶³")
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    break
                else:
                    raise e
        
        print(f"âœ… é¸æ“‡ batch size: {best_batch_size} (é€Ÿåº¦: {best_speed:.1f} åœ–ç‰‡/ç§’)")
        return best_batch_size
    
    def train(self, train_dataset, val_dataset=None, 
              batch_size=None, epochs=30, lr=3e-5, 
              auto_batch_size=True, patience=10):
        """
        è¨“ç·´æ¨¡å‹
        
        Args:
            train_dataset: è¨“ç·´è³‡æ–™é›†
            val_dataset: é©—è­‰è³‡æ–™é›†
            batch_size: batch size (None è¡¨ç¤ºè‡ªå‹•æª¢æ¸¬)
            epochs: è¨“ç·´è¼ªæ•¸
            lr: å­¸ç¿’ç‡
            auto_batch_size: æ˜¯å¦è‡ªå‹•æª¢æ¸¬ batch size
            patience: æ—©åœè€å¿ƒå€¼
        """
        print(f"\nğŸš€ é–‹å§‹è¨“ç·´ {self.model_name}...")
        
        # è‡ªå‹•æª¢æ¸¬ batch size
        if auto_batch_size or batch_size is None:
            batch_size = self.find_optimal_batch_size(train_dataset)
        
        # æº–å‚™è³‡æ–™è¼‰å…¥å™¨
        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=4,
            pin_memory=True if torch.cuda.is_available() else False,
            drop_last=True
        )
        
        val_loader = None
        if val_dataset:
            val_loader = DataLoader(
                val_dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=2,
                pin_memory=True if torch.cuda.is_available() else False
            )
        
        # è¨­å®šå„ªåŒ–å™¨å’Œæ’ç¨‹å™¨
        optimizer = optim.AdamW(
            self.model.parameters(),
            lr=lr,
            weight_decay=0.01,
            betas=(0.9, 0.999)
        )
        
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=epochs, eta_min=lr/100
        )
        
        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
        
        # è¨“ç·´æ­·å²
        history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': [],
            'lr': []
        }
        
        best_val_acc = 0.0
        patience_counter = 0
        
        print(f"ğŸ“Š è¨“ç·´è¨­å®š:")
        print(f"   Batch size: {batch_size}")
        print(f"   å­¸ç¿’ç‡: {lr}")
        print(f"   è¨“ç·´è¼ªæ•¸: {epochs}")
        print(f"   æ—©åœè€å¿ƒ: {patience}")
        
        # é–‹å§‹è¨“ç·´
        for epoch in range(epochs):
            start_time = time.time()
            
            # è¨“ç·´éšæ®µ
            train_loss, train_acc = self._train_epoch(train_loader, optimizer, criterion)
            
            # é©—è­‰éšæ®µ
            val_loss, val_acc = 0.0, 0.0
            if val_loader:
                val_loss, val_acc = self._validate_epoch(val_loader, criterion)
            
            # æ›´æ–°å­¸ç¿’ç‡
            scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']
            
            # è¨˜éŒ„æ­·å²
            history['train_loss'].append(train_loss)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)
            history['lr'].append(current_lr)
            
            # è¨ˆç®—æ™‚é–“
            epoch_time = time.time() - start_time
            
            # é¡¯ç¤ºé€²åº¦
            print(f"Epoch [{epoch+1}/{epochs}] ({epoch_time:.1f}s)")
            print(f"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%")
            if val_loader:
                print(f"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%")
            print(f"  LR: {current_lr:.2e}")
            
            # æ—©åœæª¢æŸ¥
            if val_loader:
                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                    patience_counter = 0
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    self.save_model(f"best_{self.model_name}_acc{val_acc:.1f}.pth")
                else:
                    patience_counter += 1
                    
                if patience_counter >= patience:
                    print(f"\nâ¹ï¸ æ—©åœè§¸ç™¼ï¼æœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_val_acc:.2f}%")
                    break
            
            print("-" * 60)
        
        print(f"\nâœ… è¨“ç·´å®Œæˆï¼")
        if val_loader:
            print(f"ğŸ† æœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_val_acc:.2f}%")
        
        return history
    
    def _train_epoch(self, train_loader, optimizer, criterion):
        """è¨“ç·´ä¸€å€‹ epoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        pbar = tqdm(train_loader, desc="Training")
        for images, labels in pbar:
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            optimizer.zero_grad()
            outputs = self.model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
            # æ›´æ–°é€²åº¦æ¢
            acc = 100.0 * correct / total
            pbar.set_postfix({
                'Loss': f'{total_loss/len(pbar):.4f}',
                'Acc': f'{acc:.2f}%'
            })
        
        return total_loss / len(train_loader), 100.0 * correct / total
    
    def _validate_epoch(self, val_loader, criterion):
        """é©—è­‰ä¸€å€‹ epoch"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for images, labels in tqdm(val_loader, desc="Validation"):
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                outputs = self.model(images)
                loss = criterion(outputs, labels)
                
                total_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()
        
        return total_loss / len(val_loader), 100.0 * correct / total
    
    def save_model(self, filename):
        """ä¿å­˜æ¨¡å‹"""
        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'model_name': self.model_name,
            'num_classes': self.num_classes,
            'class_to_idx': self.class_to_idx,
            'idx_to_class': self.idx_to_class
        }
        
        torch.save(checkpoint, filename)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filename}")
    
    def load_model(self, filename):
        """è¼‰å…¥æ¨¡å‹"""
        checkpoint = torch.load(filename, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.class_to_idx = checkpoint['class_to_idx']
        self.idx_to_class = checkpoint['idx_to_class']
        
        print(f"ğŸ“‚ æ¨¡å‹å·²è¼‰å…¥: {filename}")
    
    def plot_training_history(self, history):
        """ç¹ªè£½è¨“ç·´æ­·å²"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # Loss
        axes[0,0].plot(history['train_loss'], label='Train Loss')
        if history['val_loss']:
            axes[0,0].plot(history['val_loss'], label='Val Loss')
        axes[0,0].set_title('Loss')
        axes[0,0].legend()
        
        # Accuracy
        axes[0,1].plot(history['train_acc'], label='Train Acc')
        if history['val_acc']:
            axes[0,1].plot(history['val_acc'], label='Val Acc')
        axes[0,1].set_title('Accuracy (%)')
        axes[0,1].legend()
        
        # Learning Rate
        axes[1,0].plot(history['lr'])
        axes[1,0].set_title('Learning Rate')
        
        # Speed comparison
        axes[1,1].text(0.1, 0.8, f'Model: {self.model_name}', transform=axes[1,1].transAxes)
        axes[1,1].text(0.1, 0.6, f'Classes: {self.num_classes}', transform=axes[1,1].transAxes)
        axes[1,1].text(0.1, 0.4, f'Device: {self.device}', transform=axes[1,1].transAxes)
        axes[1,1].set_title('Model Info')
        axes[1,1].axis('off')
        
        plt.tight_layout()
        plt.savefig(f'{self.model_name}_training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

def get_best_data_path():
    """
    ä½¿ç”¨å’Œ MemoryViT ç›¸åŒçš„è³‡æ–™è·¯å¾‘é…ç½®ï¼š
    - è¨“ç·´è³‡æ–™ï¼šaugmented/train/
    - é©—è­‰è³‡æ–™ï¼špreprocessed/val/
    """
    # æª¢æ¸¬ç’°å¢ƒ
    import platform
    is_wsl = "microsoft" in platform.uname().release.lower() or "WSL" in os.environ.get("WSL_DISTRO_NAME", "")
    
    if is_wsl:
        base_path = "/mnt/e/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset"
        augmented_train = f"{base_path}/augmented/train"
        preprocessed_val = f"{base_path}/preprocessed/val"
    else:
        base_path = "E:/NYCU/NYCU_IAII_ML2025/Ass2-Classification/Dataset"
        augmented_train = f"{base_path}/augmented/train"
        preprocessed_val = f"{base_path}/preprocessed/val"
    
    # æª¢æŸ¥å¿…è¦çš„è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨
    if os.path.exists(augmented_train) and os.path.exists(preprocessed_val):
        return {
            'train': augmented_train,
            'val': preprocessed_val,
            'use_existing_split': True
        }, "ğŸ¨ ä½¿ç”¨å¢å¼·è¨“ç·´è³‡æ–™ + é è™•ç†é©—è­‰è³‡æ–™"
    else:
        missing = []
        if not os.path.exists(augmented_train):
            missing.append(f"augmented/train: {augmented_train}")
        if not os.path.exists(preprocessed_val):
            missing.append(f"preprocessed/val: {preprocessed_val}")
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°å¿…è¦çš„è³‡æ–™å¤¾: {', '.join(missing)}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ EfficientNet Simpson è§’è‰²åˆ†é¡å™¨")
    print("=" * 60)
    
    # æª¢æŸ¥ GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {device}")
    
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"ğŸ® GPU: {gpu_name}")
        print(f"ğŸ’¾ GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # ä½¿ç”¨å’Œ MemoryViT ç›¸åŒçš„è³‡æ–™è·¯å¾‘
    try:
        data_paths, data_type = get_best_data_path()
        print(f"ğŸ“‚ ä½¿ç”¨è³‡æ–™: {data_type}")
        print(f"ğŸ“ è¨“ç·´è·¯å¾‘: {data_paths['train']}")
        print(f"ğŸ“ é©—è­‰è·¯å¾‘: {data_paths['val']}")
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        print("ğŸ’¡ è«‹ç¢ºèªä»¥ä¸‹è·¯å¾‘å­˜åœ¨:")
        print("  - Dataset/augmented/train (å¢å¼·è¨“ç·´è³‡æ–™)")
        print("  - Dataset/preprocessed/val (é è™•ç†é©—è­‰è³‡æ–™)")
        return
    
    # çµ±è¨ˆè³‡æ–™é‡
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif']
    total_images = 0
    
    # çµ±è¨ˆ train è³‡æ–™
    for ext in image_extensions:
        total_images += len(glob.glob(os.path.join(data_paths['train'], '**', ext), recursive=True))
    
    # çµ±è¨ˆ val è³‡æ–™
    if data_paths['val'] and os.path.exists(data_paths['val']):
        for ext in image_extensions:
            total_images += len(glob.glob(os.path.join(data_paths['val'], '**', ext), recursive=True))
    
    print(f"ğŸ“Š ç¸½åœ–ç‰‡æ•¸: {total_images} å¼µ")
    
    if total_images == 0:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡æª”æ¡ˆï¼")
        return
    
    # é¸æ“‡æ¨¡å‹
    print("\nğŸ¯ é¸æ“‡ EfficientNet æ¨¡å‹:")
    print("1. efficientnet_b0 - æœ€å¿« (5.3M åƒæ•¸)")
    print("2. efficientnet_b3 - å¹³è¡¡ (12M åƒæ•¸) [æ¨è–¦]")
    print("3. efficientnet_b5 - æº–ç¢º (30M åƒæ•¸)")
    
    choice = input("è«‹é¸æ“‡ (1/2/3ï¼Œé è¨­2): ").strip()
    model_mapping = {
        '1': 'efficientnet_b0',
        '2': 'efficientnet_b3',
        '3': 'efficientnet_b5'
    }
    model_name = model_mapping.get(choice, 'efficientnet_b3')
    
    # åˆå§‹åŒ–åˆ†é¡å™¨
    classifier = EfficientNetCharacterClassifier(
        num_classes=50,  # é è¨­50é¡ï¼Œå¯¦éš›æœƒæ ¹æ“šè³‡æ–™èª¿æ•´
        model_name=model_name,
        device=device
    )
    
    # æº–å‚™è³‡æ–™ - ä½¿ç”¨å’Œ MemoryViT ç›¸åŒçš„è³‡æ–™
    train_dataset, val_dataset, test_dataset = classifier.prepare_data(data_paths)
    
    # è¨“ç·´åƒæ•¸
    epochs = int(input("è¨“ç·´è¼ªæ•¸ (é è¨­ 30): ") or "30")
    lr = float(input("å­¸ç¿’ç‡ (é è¨­ 3e-5): ") or "3e-5")
    
    # é–‹å§‹è¨“ç·´
    history = classifier.train(
        train_dataset=train_dataset,
        val_dataset=val_dataset,
        epochs=epochs,
        lr=lr,
        auto_batch_size=True,
        patience=10
    )
    
    # ç¹ªè£½çµæœ
    classifier.plot_training_history(history)
    
    print("\nğŸ‰ è¨“ç·´å®Œæˆï¼")

if __name__ == "__main__":
    main()