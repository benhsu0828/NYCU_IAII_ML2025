[34m[1mwandb[0m: Detected [huggingface_hub.inference] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
ğŸ“‚ è¼‰å…¥é è™•ç†è³‡æ–™: ../data/cpt_dataset.parquet
Generating train split: 1150 examples [00:00, 72322.09 examples/s]
âœ… è¼‰å…¥å®Œæˆï¼ç¸½ç­†æ•¸: 1150
ğŸ“Š ç¬¬ä¸€ç­†è³‡æ–™é è¦½: å„ä½é„‰è¦ªé€å®¶å¥½ï¼Œç›¸ä¿¡é€å®¶åŠ åŠ æ¸›æ¸›ç†Ÿä¼¼å’±æºªæ±æ‘çš„æ‘é•·ä¼¯ä»”ï¼Œæ¯‹å…æˆ‘åŠ ä»‹ç´¹ã€‚æ¯‹éï¼Œä¹Ÿå°±æ˜¯å› ç‚ºé€å®¶å°æ‘é•·ä¼¯å‚·éäº†è§£ï¼Œæ”æ‘é•·ä¼¯ä»”ã€æ‘é•·ä¼¯ä»”æŒ‰å‘¢å…±å«ï¼Œæ‰æœ‰æˆ‘å¯«é€™ä»½å‚³å–®çš„å¿…è¦ã€‚æ˜¯tihï¼Œæ‘é•·ä¼¯ä»”æ¬²å‡ºä¾†é¸æœ¬å±†çš„é„‰é•·å›‰...
==((====))==  Unsloth 2025.12.4: Fast Llama patching. Transformers: 4.57.3.
   \\   /|    NVIDIA Graphics Device. Num GPUs = 1. Max memory: 7.536 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.9.1+cu128. CUDA: 12.0. CUDA Toolkit: 12.8. Triton: 3.5.1
\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
Unsloth 2025.12.4 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.
Unsloth: Tokenizing ["text"] (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1150/1150 [00:01<00:00, 1142.18 examples/s]
ğŸ¦¥ Unsloth: Padding-free auto-enabled, enabling faster training.
é–‹å§‹ CPT éšæ®µè¨“ç·´...
The model is already on multiple devices. Skipping the move to device specified in `args`.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 1,150 | Num Epochs = 28 | Total steps = 1,000
O^O/ \_/ \    Batch size per device = 2 | Gradient accumulation steps = 16
\        /    Data Parallel GPUs = 1 | Total batch size (2 x 16 x 1) = 32
 "-____-"     Trainable parameters = 72,613,888 of 6,133,649,408 (1.18% trained)
  0%|â–                                                                                                                  | 2/1000 [02:50<23:48:01, 85.85s/it]Traceback (most recent call last):
Unsloth: Will smartly offload gradients to save VRAM!
  File "/home/ben/æ¡Œé¢/NYCU_IAII_ML2025/Ass4-LLM/src/./main_CPT_SFT.py", line 299, in <module>
    cpt_trainer.train()
  File "/home/ben/æ¡Œé¢/NYCU_IAII_ML2025/Ass4-LLM/src/unsloth_compiled_cache/UnslothSFTTrainer.py", line 55, in wrapper
    output = f(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ben/miniconda3/envs/Ass4/lib/python3.11/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 330, in _fast_inner_training_loop
  File "/home/ben/æ¡Œé¢/NYCU_IAII_ML2025/Ass4-LLM/src/unsloth_compiled_cache/UnslothSFTTrainer.py", line 1082, in training_step
    return super().training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 91, in _unsloth_training_step
  File "/home/ben/miniconda3/envs/Ass4/lib/python3.11/site-packages/accelerate/accelerator.py", line 2852, in backward
    loss.backward(**kwargs)
  File "/home/ben/miniconda3/envs/Ass4/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ben/miniconda3/envs/Ass4/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ben/miniconda3/envs/Ass4/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ben/miniconda3/envs/Ass4/lib/python3.11/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ben/miniconda3/envs/Ass4/lib/python3.11/site-packages/unsloth_zoo/gradient_checkpointing.py", line 606, in backward
    torch.autograd.backward(outputs_with_grad, args_with_grad)
  File "/home/ben/miniconda3/envs/Ass4/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ben/miniconda3/envs/Ass4/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 7.54 GiB of which 348.69 MiB is free. Including non-PyTorch memory, this process has 7.18 GiB memory in use. Of the allocated memory 5.62 GiB is allocated by PyTorch, and 1.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
