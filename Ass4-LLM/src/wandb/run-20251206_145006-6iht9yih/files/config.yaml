_wandb:
    value:
        cli_version: 0.23.1
        e:
            8buteyn5y74pvnenrd7pnnt31vbehb16:
                codePath: main_CPT_SFT.py
                codePathLocal: main_CPT_SFT.py
                cpu_count: 8
                cpu_count_logical: 16
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "511032946688"
                        used: "181020024832"
                email: benten.hsu@gmail.com
                executable: C:\Users\bente\miniconda3\envs\Ass4\python.exe
                gpu: NVIDIA GeForce RTX 5050
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Blackwell
                      cudaCores: 2560
                      memoryTotal: "8546942976"
                      name: NVIDIA GeForce RTX 5050
                      uuid: GPU-b1c0431a-cc1f-6517-7e5a-48d0573e4eff
                host: ben
                memory:
                    total: "16340992000"
                os: Windows-10-10.0.26200-SP0
                program: C:\Users\bente\OneDrive\桌面\NYCU_IAII_ML2025\Ass4-LLM\src\main_CPT_SFT.py
                python: CPython 3.11.14
                root: C:\Users\bente\OneDrive\桌面\NYCU_IAII_ML2025\Ass4-LLM\src
                startedAt: "2025-12-06T06:50:06.383233Z"
                writerId: 8buteyn5y74pvnenrd7pnnt31vbehb16
        m: []
        python_version: 3.11.14
        t:
            "1":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 71
                - 84
                - 98
            "2":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 71
                - 84
                - 98
            "3":
                - 13
                - 15
                - 16
            "4": 3.11.14
            "5": 0.23.1
            "6": 4.57.2
            "8":
                - 3
            "12": 0.23.1
            "13": windows-amd64
batch_size:
    value: 1
gradient_accumulation:
    value: 16
learning_rate:
    value: 0.0002
lora_alpha:
    value: 128
lora_r:
    value: 64
max_seq_length:
    value: 1024
max_steps:
    value: 1000
model_name:
    value: Bohanlu/Taigi-Llama-2-7B
stage:
    value: CPT
vram:
    value: 8GB
