#!/usr/bin/env python3
"""
ä¸»ç¨‹å¼ï¼šæˆ¿åœ°ç”¢åƒ¹æ ¼é æ¸¬
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import warnings
import time
from datetime import datetime
warnings.filterwarnings('ignore')

# åŠ å…¥ src ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

from data_preprocess import preprocess_data, load_processed_data, validate_model_ready_data
from model import RegressionModels
import os

def get_timestamp():
    """ç”Ÿæˆæ™‚é–“æˆ³è¨˜ - æ ¼å¼: MMDD_HHMM
    
    ä¾‹å¦‚:
    - 12æœˆ25æ—¥ 14:30 -> "1225_1430"
    - 01æœˆ05æ—¥ 09:15 -> "0105_0915"
    """
    now = datetime.now()
    return now.strftime("%m%d_%H%M")

class DLModelWrapper:
    """æ·±åº¦å­¸ç¿’æ¨¡å‹åŒ…è£å™¨ - ç›´æ¥åŒ…è£è¨“ç·´å¥½çš„æ¨¡å‹"""
    
    def __init__(self, trained_model):
        self.trained_model = trained_model  # å®Œæ•´çš„è¨“ç·´å¥½çš„æ¨¡å‹
        
    def predict(self, X):
        """é æ¸¬å‡½æ•¸ - ç›´æ¥ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹"""
        return self.trained_model.predict(X)

def create_dl_model_wrapper(model, model_name, model_dir):
    """å‰µå»ºå¯åºåˆ—åŒ–çš„æ·±åº¦å­¸ç¿’æ¨¡å‹åŒ…è£å™¨"""
    
    try:
        print("   ğŸ”„ å‰µå»ºæ·±åº¦å­¸ç¿’æ¨¡å‹åŒ…è£å™¨...")
        
        # ğŸ¯ ç›´æ¥åŒ…è£æ•´å€‹è¨“ç·´å¥½çš„æ¨¡å‹ï¼ˆåŒ…å« scaler å’Œ keras æ¨¡å‹ï¼‰
        wrapper = DLModelWrapper(trained_model=model)
        
        print("   âœ… æ·±åº¦å­¸ç¿’æ¨¡å‹åŒ…è£å™¨å‰µå»ºæˆåŠŸ")
        return wrapper
        
    except Exception as e:
        print(f"   âŒ åŒ…è£å™¨å‰µå»ºå¤±æ•—: {e}")
        return None

def load_data_and_prepare():
    """è¼‰å…¥ä¸¦æº–å‚™è³‡æ–™"""
    print("=== è¼‰å…¥è³‡æ–™ ===")
    
    # 1. è³‡æ–™è®€å–
    train_df, valid_df, test_df = load_processed_data("processed")
    print(f"è³‡æ–™è¼‰å…¥å®Œæˆ - Train: {train_df.shape}, Valid: {valid_df.shape}, Test: {test_df.shape}")
    
    # 2. æº–å‚™è¨“ç·´è³‡æ–™
    print("\n2. æº–å‚™è³‡æ–™...")
    
    # ç¢ºå®šç›®æ¨™è®Šæ•¸åç¨±
    target_column = 'ç¸½åƒ¹å…ƒ'
    print(f"ä½¿ç”¨ç›®æ¨™è®Šæ•¸: {target_column}")
    
    # åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸
    X_train = train_df.drop([target_column], axis=1, errors='ignore')
    y_train = train_df[target_column]
    
    X_valid = valid_df.drop([target_column], axis=1, errors='ignore')
    y_valid = valid_df[target_column]
    
    X_test = test_df.drop(["ç·¨è™Ÿ"], axis=1, errors='ignore')
    
    # é©—è­‰è³‡æ–™æ˜¯å¦æº–å‚™å¥½
    is_ready = validate_model_ready_data(train_df, valid_df, test_df, target_column)
    if not is_ready:
        print("âŒ è³‡æ–™æœªæº–å‚™å¥½ï¼Œè«‹æª¢æŸ¥é è™•ç†æ­¥é©Ÿ")
        return None, None, None, None, None, None
    
    print(f"ç‰¹å¾µæ•¸é‡: {X_train.shape[1]}")
    print(f"è¨“ç·´æ¨£æœ¬: {X_train.shape[0]}")
    print(f"é©—è­‰æ¨£æœ¬: {X_valid.shape[0]}")
    print(f"æ¸¬è©¦æ¨£æœ¬: {X_test.shape[0]}")
    
    return X_train, y_train, X_valid, y_valid, X_test, test_df

def train_models(X_train, y_train, X_valid, y_valid, include_linear=False, include_deep_learning=False, tree_only=False):
    """è¨“ç·´æ¨¡å‹
    
    Args:
        X_train, y_train: è¨“ç·´è³‡æ–™
        X_valid, y_valid: é©—è­‰è³‡æ–™
        include_linear: æ˜¯å¦åŒ…å«ç·šæ€§æ¨¡å‹
        include_deep_learning: æ˜¯å¦åŒ…å«æ·±åº¦å­¸ç¿’æ¨¡å‹
        fast_tree_only: æ˜¯å¦åªè¨“ç·´å¿«é€Ÿæ¨¹æ¨¡å‹ï¼ˆç²¾é¸ç‰ˆæœ¬ï¼‰
    """
    print("\n=== é–‹å§‹æ¨¡å‹è¨“ç·´ ===")
    
    # åˆå§‹åŒ–æ¨¡å‹
    print("1. åˆå§‹åŒ–æ¨¡å‹...")
    models = RegressionModels(random_state=42)
    
    if tree_only:
        # å®Œæ•´ç‰ˆï¼šæ‰€æœ‰æ¨¹æ¨¡å‹åˆ†éšæ®µè¨“ç·´
        print("\n2. ç¬¬ä¸€éšæ®µï¼šå¿«é€ŸåŸºç¤æ¨¡å‹...")
        basic_models = models.get_tree_models()
        models.train_multiple_models(basic_models, X_train, y_train, X_valid, y_valid)
        
        # é¡¯ç¤ºç¬¬ä¸€éšæ®µçµæœ
        print("\n=== ç¬¬ä¸€éšæ®µçµæœ ===")
        results_stage1 = models.get_results_summary()
        print(results_stage1)
        
        # ç¬¬äºŒéšæ®µï¼šå„ªåŒ–æ¨¹æ¨¡å‹
        print("\n3. ç¬¬äºŒéšæ®µï¼šå„ªåŒ–æ¨¹æ¨¡å‹...")
        optimized_models = models.get_optimized_tree_models()
        models.train_multiple_models(optimized_models, X_train, y_train, X_valid, y_valid)
    
    # ç¬¬ä¸‰éšæ®µï¼šç·šæ€§æ¨¡å‹ï¼ˆå¯é¸ï¼‰
    if include_linear:
        print(f"ç·šæ€§æ¨¡å‹...")
        linear_models = models.get_linear_models()
        models.train_multiple_models(linear_models, X_train, y_train, X_valid, y_valid)
    
    # ç¬¬å››éšæ®µï¼šæ·±åº¦å­¸ç¿’æ¨¡å‹ï¼ˆå¯é¸ï¼‰
    if include_deep_learning:
        print(f"æ·±åº¦å­¸ç¿’æ¨¡å‹...")
        # æ³¨æ„ï¼šæ·±åº¦å­¸ç¿’éœ€è¦æ›´é•·æ™‚é–“è¨“ç·´
        try:
            dl_models = models.get_deep_learning_models()
            models.train_multiple_models(dl_models, X_train, y_train, X_valid, y_valid)
        except Exception as e:
            print(f"âš ï¸ æ·±åº¦å­¸ç¿’æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
    
    # é¡¯ç¤ºæœ€çµ‚çµæœ
    print("\n=== æœ€çµ‚è¨“ç·´çµæœ ===")
    final_results = models.get_results_summary()
    print(final_results)
    
    # åˆ†é¡åˆ¥å„²å­˜æœ€ä½³æ¨¡å‹
    print(f"\n{6 if not include_deep_learning else 7}. åˆ†é¡åˆ¥å„²å­˜æœ€ä½³æ¨¡å‹...")
    
    # ğŸ• ç”Ÿæˆçµ±ä¸€çš„æ™‚é–“æˆ³è¨˜
    timestamp = get_timestamp()
    best_models_by_type = models.save_best_models_by_type("../models", timestamp)
    
    # å–å¾—æ•´é«”æœ€ä½³æ¨¡å‹
    if best_models_by_type and 'overall_best' in best_models_by_type:
        overall_best = best_models_by_type['overall_best']
        best_model_name = overall_best['name']
        best_model = overall_best['model']
        
        # ç‰¹å¾µé‡è¦æ€§åˆ†æï¼ˆå¦‚æœæ˜¯æ¨¹æ¨¡å‹ï¼‰
        if hasattr(best_model, 'feature_importances_'):
            print(f"\n{7 if not include_deep_learning else 8}. ç‰¹å¾µé‡è¦æ€§åˆ†æ...")
            analyze_feature_importance(best_model, X_train.columns, best_model_name)
        
        print("\n=== è¨“ç·´å®Œæˆï¼===")
        print(f"æ•´é«”æœ€ä½³æ¨¡å‹: {best_model_name}")
        print(f"é©—è­‰é›† RMSE: {overall_best['rmse']:.2f}")
        print(f"é©—è­‰é›† RÂ²: {overall_best['r2']:.4f}")
        
        # é¡¯ç¤ºå„é¡åˆ¥æœ€ä½³æ¨¡å‹æ‘˜è¦
        print(f"\n=== å„é¡åˆ¥æœ€ä½³æ¨¡å‹æ‘˜è¦ ===")
        for category, info in best_models_by_type.items():
            if category != 'overall_best':
                print(f"{category.upper():15s}: {info['name']:20s} (RMSE: {info['rmse']:.2f}, RÂ²: {info['r2']:.4f})")
        
        return models, best_model_name, best_models_by_type
    else:
        print("âŒ æ²’æœ‰æˆåŠŸè¨“ç·´çš„æ¨¡å‹")
        return models, None, {}

def test_model(X_test, test_df, model_name=None):
    """ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹é€²è¡Œæ¸¬è©¦"""
    print("\n=== é–‹å§‹æ¨¡å‹æ¸¬è©¦ ===")
    
    # å°å…¥å¿…è¦å¥—ä»¶
    try:
        import joblib
    except ImportError:
        print("âŒ joblib å¥—ä»¶æœªå®‰è£ï¼Œç„¡æ³•è¼‰å…¥æ¨¡å‹")
        return
    
    model_dir = Path("../models")
    
    if model_name:
        # æŒ‡å®šæ¨¡å‹åç¨±
        print(f"ğŸ¯ æŒ‡å®šæ¸¬è©¦æ¨¡å‹: {model_name}")
        
        # ğŸ¯ æª¢æŸ¥æ˜¯å¦ç‚ºæ·±åº¦å­¸ç¿’æ¨¡å‹
        if model_name.startswith('DeepLearning'):
            keras_path = model_dir / f"{model_name}_keras"
            scaler_path = model_dir / f"{model_name}_scaler.joblib"
            
            if keras_path.exists() and scaler_path.exists():
                print(f"ğŸ§  æª¢æ¸¬åˆ°æ·±åº¦å­¸ç¿’æ¨¡å‹æª”æ¡ˆ")
                test_single_model_file(X_test, test_df, keras_path, model_name)
                return
            else:
                print(f"âŒ æ·±åº¦å­¸ç¿’æ¨¡å‹æª”æ¡ˆä¸å®Œæ•´:")
                print(f"   Keras æ¨¡å‹: {keras_path} ({'å­˜åœ¨' if keras_path.exists() else 'ä¸å­˜åœ¨'})")
                print(f"   Scaler: {scaler_path} ({'å­˜åœ¨' if scaler_path.exists() else 'ä¸å­˜åœ¨'})")
                return
        else:
            # å‚³çµ±æ¨¡å‹
            model_file = model_dir / f"{model_name}.joblib"
            if model_file.exists():
                test_single_model_file(X_test, test_df, model_file, model_name)
                return
            else:
                print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_file}")
                return
    else:
        # è‡ªå‹•å°‹æ‰¾æ¨¡å‹
        print("ğŸ” è‡ªå‹•å°‹æ‰¾å¯ç”¨æ¨¡å‹...")
        
        # å°‹æ‰¾å‚³çµ±æ¨¡å‹
        joblib_files = list(model_dir.glob("*.joblib"))
        joblib_models = [f for f in joblib_files if not f.name.endswith('_scaler.joblib')]
        
        # å°‹æ‰¾æ·±åº¦å­¸ç¿’æ¨¡å‹
        keras_dirs = [d for d in model_dir.iterdir() if d.is_dir() and d.name.endswith('_keras')]
        dl_models = []
        for keras_dir in keras_dirs:
            base_name = keras_dir.name.replace('_keras', '')
            scaler_file = model_dir / f"{base_name}_scaler.joblib"
            if scaler_file.exists():
                dl_models.append((keras_dir, base_name))
        
        all_models = []
        
        # åŠ å…¥å‚³çµ±æ¨¡å‹
        for f in joblib_models:
            all_models.append(('traditional', f, f.stem))
        
        # åŠ å…¥æ·±åº¦å­¸ç¿’æ¨¡å‹
        for keras_dir, base_name in dl_models:
            all_models.append(('deeplearning', keras_dir, base_name))
        
        if not all_models:
            print("âŒ æ²’æœ‰æ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹æª”æ¡ˆ")
            print("æç¤ºï¼šè«‹å…ˆåŸ·è¡Œè¨“ç·´æ¨¡å¼")
            return
        
        # é¸æ“‡æœ€æ–°çš„æ¨¡å‹ï¼ˆä»¥ä¿®æ”¹æ™‚é–“ç‚ºæº–ï¼‰
        def get_model_time(model_info):
            model_type, model_path, _ = model_info
            if model_type == 'traditional':
                return os.path.getctime(model_path)
            else:  # deeplearning
                return os.path.getctime(model_path)
        
        latest_model = max(all_models, key=get_model_time)
        model_type, model_path, model_name = latest_model
        
        print(f"ğŸ“Š ä½¿ç”¨æœ€æ–°æ¨¡å‹: {model_name} ({'æ·±åº¦å­¸ç¿’' if model_type == 'deeplearning' else 'å‚³çµ±æ¨¡å‹'})")
        test_single_model_file(X_test, test_df, model_path, model_name)

    print(f"\n=== æ¸¬è©¦å®Œæˆï¼===")

def main():
    """ä¸»å‡½æ•¸ - è¨“ç·´æ¨¡å¼"""
    print("=== æˆ¿åœ°ç”¢åƒ¹æ ¼é æ¸¬æ¨¡å‹è¨“ç·´ ===")
    
    # è¼‰å…¥ä¸¦æº–å‚™è³‡æ–™
    data = load_data_and_prepare()
    if data[0] is None:
        return
    
    X_train, y_train, X_valid, y_valid, X_test, test_df = data
    
    # é¸æ“‡è¦è¨“ç·´çš„æ¨¡å‹é¡å‹
    print("\n=== é¸æ“‡è¨“ç·´æ¨¡å‹é¡å‹ ===")
    print("1. è¨“ç·´æ¨¹æ¨¡å‹")
    print("2. è¨“ç·´ç·šæ€§æ¨¡å‹")
    print("3. è¨“ç·´DL")
    
    while True:
        try:
            choice = input("è«‹é¸æ“‡ (1-3): ").strip()
            if choice == '1':
                include_linear = False
                include_dl = False
                tree_only = True
                break
            elif choice == '2':
                include_linear = True
                include_dl = False
                tree_only = False
                break
            elif choice == '3':
                include_linear = False
                include_dl = True
                tree_only = False
                break
            else:
                print("è«‹è¼¸å…¥ 1ã€2ã€3 æˆ– 4")
        except KeyboardInterrupt:
            print("\nç¨‹åºå·²ä¸­æ­¢")
            return
    
    # è¨“ç·´æ¨¡å‹
    result = train_models(
        X_train, y_train, X_valid, y_valid, 
        include_linear=include_linear, 
        include_deep_learning=include_dl,
        fast_tree_only=tree_only
    )
    
    if len(result) == 3:
        models, best_model_name, best_models_by_type = result
    else:
        models, best_model_name = result
        best_models_by_type = {}

def test_only():
    """åªé€²è¡Œæ¸¬è©¦æ¨¡å¼"""
    print("=== æˆ¿åœ°ç”¢åƒ¹æ ¼é æ¸¬ - æ¸¬è©¦æ¨¡å¼ ===")
    
    # è¼‰å…¥ä¸¦æº–å‚™è³‡æ–™
    data = load_data_and_prepare()
    if data[0] is None:
        return
    
    X_train, y_train, X_valid, y_valid, X_test, test_df = data
    
    # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†é¡åˆ¥çš„æ¨¡å‹æª”æ¡ˆ
    model_dir = Path("../models")
    category_model_files = list(model_dir.glob("best_*_model_*.joblib"))
    
    if category_model_files:
        print("ç™¼ç¾åˆ†é¡åˆ¥è¨“ç·´çš„æ¨¡å‹ï¼Œå•Ÿç”¨é€²éšæ¸¬è©¦é¸é …")
        test_model_with_choice(X_test, test_df)
    else:
        print("ä½¿ç”¨ä¸€èˆ¬æ¸¬è©¦æ¨¡å¼")
        test_model(X_test, test_df)

def train_and_test():
    """è¨“ç·´ä¸¦æ¸¬è©¦æ¨¡å¼"""
    print("=== æˆ¿åœ°ç”¢åƒ¹æ ¼é æ¸¬ - è¨“ç·´ä¸¦æ¸¬è©¦æ¨¡å¼ ===")
    
    # è¼‰å…¥ä¸¦æº–å‚™è³‡æ–™
    data = load_data_and_prepare()
    if data[0] is None:
        return
    
    X_train, y_train, X_valid, y_valid, X_test, test_df = data
    
    # é¸æ“‡è¦è¨“ç·´çš„æ¨¡å‹é¡å‹ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
    print("\nå¿«é€Ÿè¨“ç·´æ¨¡å¼ï¼šåªè¨“ç·´åŸºç¤æ¨¹æ¨¡å‹")
    
    # è¨“ç·´æ¨¡å‹ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
    result = train_models(
        X_train, y_train, X_valid, y_valid, 
        include_linear=False, 
        include_deep_learning=False,
        fast_tree_only=True  # ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
    )
    
    if len(result) == 3:
        models, best_model_name, best_models_by_type = result
    else:
        models, best_model_name = result
        best_models_by_type = {}
    
    # é€²è¡Œæ¸¬è©¦
    print("\n" + "="*50)
    test_model(X_test, test_df, best_model_name)

def save_predictions(predictions, test_df, model_name):
    """å„²å­˜é æ¸¬çµæœï¼Œç·¨è™Ÿå°æ‡‰ test_df çš„ç·¨è™Ÿæ¬„ä½"""
    
    # ğŸ¯ ç›´æ¥å¾ test_df ç²å–ç·¨è™Ÿ
    if 'ç·¨è™Ÿ' in test_df.columns:
        test_ids = test_df['ç·¨è™Ÿ']
        print(f"âœ… ä½¿ç”¨æ¸¬è©¦è³‡æ–™çš„åŸå§‹ç·¨è™Ÿæ¬„ä½")
    else:
        # å¦‚æœæ²’æœ‰ç·¨è™Ÿæ¬„ä½ï¼Œå‰µå»ºé€£çºŒç·¨è™Ÿ
        test_ids = pd.Series(range(1, len(test_df) + 1))
        print(f"âœ… å‰µå»ºé€£çºŒç·¨è™Ÿ (1 åˆ° {len(test_df)})")
    
    # ç¢ºä¿é æ¸¬çµæœèˆ‡æ¸¬è©¦è³‡æ–™æ•¸é‡ä¸€è‡´
    assert len(predictions) == len(test_df), \
        f"é æ¸¬çµæœæ•¸é‡ ({len(predictions)}) èˆ‡æ¸¬è©¦è³‡æ–™æ•¸é‡ ({len(test_df)}) ä¸åŒ¹é…"
    
    # å»ºç«‹é æ¸¬çµæœ DataFrame
    results_df = pd.DataFrame({
        'ç·¨è™Ÿ': test_ids.values,
        'ç¸½åƒ¹å…ƒ': predictions
    })
    
    # å„²å­˜è·¯å¾‘
    results_dir = Path("../results")
    results_dir.mkdir(exist_ok=True)
    
    result_file = results_dir / f"predictions_{model_name}.csv"
    results_df.to_csv(result_file, index=False, encoding='utf-8-sig')
    
    print(f"é æ¸¬çµæœå·²å„²å­˜åˆ°: {result_file}")
    
    # é¡¯ç¤ºé æ¸¬çµ±è¨ˆ
    print(f"é æ¸¬åƒ¹æ ¼çµ±è¨ˆ:")
    print(f"  å¹³å‡å€¼: {predictions.mean():.2f}")
    print(f"  ä¸­ä½æ•¸: {np.median(predictions):.2f}")
    print(f"  æœ€å°å€¼: {predictions.min():.2f}")
    print(f"  æœ€å¤§å€¼: {predictions.max():.2f}")

def analyze_feature_importance(model, feature_names, model_name, top_n=20):
    """åˆ†æç‰¹å¾µé‡è¦æ€§"""
    importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    print(f"\\n{model_name} - Top {top_n} é‡è¦ç‰¹å¾µ:")
    print(importance_df.head(top_n))
    
    # å„²å­˜ç‰¹å¾µé‡è¦æ€§
    results_dir = Path("../results")
    results_dir.mkdir(exist_ok=True)
    
    importance_file = results_dir / f"feature_importance_{model_name}.csv"
    importance_df.to_csv(importance_file, index=False, encoding='utf-8-sig')
    
    print(f"ç‰¹å¾µé‡è¦æ€§å·²å„²å­˜åˆ°: {importance_file}")

def get_user_choice():
    """å–å¾—ç”¨æˆ¶é¸æ“‡çš„åŸ·è¡Œæ¨¡å¼"""
    print("\n=== è«‹é¸æ“‡åŸ·è¡Œæ¨¡å¼ ===")
    print("1. è¨“ç·´æ¨¡å¼ (train) - è¨“ç·´ä¸¦åˆ†é¡åˆ¥å„²å­˜æœ€ä½³æ¨¡å‹")
    print("2. æ¸¬è©¦æ¨¡å¼ (test) - é¸æ“‡æ¨¡å‹é¡å‹é€²è¡Œé æ¸¬")
    print("3. è¨“ç·´ä¸¦æ¸¬è©¦ (both) - å¿«é€Ÿè¨“ç·´å¾Œç«‹å³æ¸¬è©¦")
    print("4. é€€å‡º (exit)")
    
    print("\nğŸ’¡ æ–°åŠŸèƒ½èªªæ˜:")
    print("  - è¨“ç·´æ¨¡å¼æœƒåˆ†åˆ¥å„²å­˜æ¨¹æ¨¡å‹ã€ç·šæ€§æ¨¡å‹ã€æ·±åº¦å­¸ç¿’æ¨¡å‹çš„æœ€ä½³ç‰ˆæœ¬")
    print("  - æ¸¬è©¦æ¨¡å¼å¯ä»¥é¸æ“‡ä½¿ç”¨å“ªç¨®é¡å‹çš„æ¨¡å‹é€²è¡Œé æ¸¬")
    print("  - æ”¯æ´æ¯”è¼ƒä¸åŒé¡å‹æ¨¡å‹çš„é æ¸¬çµæœ")
    
    while True:
        try:
            choice = input("\nè«‹è¼¸å…¥é¸é … (1-4 æˆ– train/test/both/quick/exit): ").strip().lower()
            
            if choice in ['1', 'train']:
                return 'train'
            elif choice in ['2', 'test']:
                return 'test'
            elif choice in ['3', 'both']:
                return 'both'
            elif choice in ['4', 'exit']:
                return 'exit'
            else:
                print("âŒ ç„¡æ•ˆé¸é …ï¼Œè«‹é‡æ–°é¸æ“‡")
        except KeyboardInterrupt:
            print("\n\nç¨‹åºå·²ä¸­æ­¢")
            return 'exit'
        except Exception as e:
            print(f"âŒ è¼¸å…¥éŒ¯èª¤: {e}")

def get_available_models():
    """ç²å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹è³‡è¨Š"""
    model_dir = Path("../models")
    available_models = {}
    
    # ğŸ” å°‹æ‰¾å‚³çµ±æ¨¡å‹ (.joblib æª”æ¡ˆï¼Œä½†æ’é™¤ scaler æª”æ¡ˆ)
    joblib_files = list(model_dir.glob("*.joblib"))
    traditional_models = [f for f in joblib_files if not f.name.endswith('_scaler.joblib')]
    
    for model_file in traditional_models:
        model_name = model_file.stem
        
        # æ ¹æ“šæª”æ¡ˆåç¨±åˆ¤æ–·é¡å‹
        if 'linear' in model_name.lower() or 'ridge' in model_name.lower() or 'lasso' in model_name.lower():
            category = 'linear'
        elif any(tree_type in model_name.lower() for tree_type in ['tree', 'xgboost', 'lightgbm', 'catboost', 'gradient']):
            category = 'tree'
        else:
            category = 'other'
        
        if category not in available_models:
            available_models[category] = []
        
        available_models[category].append({
            'type': 'traditional',
            'name': model_name,
            'file': model_file,
            'display_name': model_name.replace('best_', '').replace('_model_', ' - ')
        })
    
    # ğŸ§  å°‹æ‰¾æ·±åº¦å­¸ç¿’æ¨¡å‹
    keras_dirs = [d for d in model_dir.iterdir() if d.is_dir() and d.name.endswith('_keras')]
    
    for keras_dir in keras_dirs:
        base_name = keras_dir.name.replace('_keras', '')
        scaler_file = model_dir / f"{base_name}_scaler.joblib"
        info_file = model_dir / f"{base_name}_info.txt"
        
        # æª¢æŸ¥æ·±åº¦å­¸ç¿’æ¨¡å‹æª”æ¡ˆå®Œæ•´æ€§
        if scaler_file.exists():
            if 'deep_learning' not in available_models:
                available_models['deep_learning'] = []
            
            available_models['deep_learning'].append({
                'type': 'deeplearning',
                'name': base_name,
                'keras_dir': keras_dir,
                'scaler_file': scaler_file,
                'info_file': info_file,
                'display_name': base_name.replace('_', ' ')
            })
    
    return available_models

def test_model_with_choice(X_test, test_df):
    """è®“ä½¿ç”¨è€…é¸æ“‡è¦æ¸¬è©¦çš„æ¨¡å‹"""
    print("\n=== é¸æ“‡æ¸¬è©¦æ¨¡å‹ ===")
    
    # ç²å–å¯ç”¨æ¨¡å‹
    available_models = get_available_models()
    
    if not available_models:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•å·²è¨“ç·´çš„æ¨¡å‹")
        print("æç¤ºï¼šè«‹å…ˆåŸ·è¡Œè¨“ç·´æ¨¡å¼")
        return
    
    # å»ºç«‹é¸é …åˆ—è¡¨
    all_options = []
    option_counter = 1
    
    # æŒ‰é¡åˆ¥é¡¯ç¤ºæ¨¡å‹
    category_names = {
        'linear': 'ğŸ“ˆ ç·šæ€§æ¨¡å‹',
        'tree': 'ğŸŒ³ æ¨¹æ¨¡å‹',
        'deep_learning': 'ğŸ§  æ·±åº¦å­¸ç¿’æ¨¡å‹',
        'other': 'ğŸ“Š å…¶ä»–æ¨¡å‹'
    }
    
    print("\nå¯ç”¨çš„æ¨¡å‹:")
    print("0. ğŸ”„ æ¸¬è©¦æ‰€æœ‰æ¨¡å‹")
    
    for category, models in available_models.items():
        if models:  # åªé¡¯ç¤ºæœ‰æ¨¡å‹çš„é¡åˆ¥
            category_display = category_names.get(category, f'ğŸ“ {category.upper()}')
            print(f"\n{category_display}:")
            
            for model_info in models:
                print(f"{option_counter}. {model_info['display_name']}")
                all_options.append((category, model_info))
                option_counter += 1
    
    print(f"{option_counter}. ğŸšª è¿”å›ä¸»é¸å–®")
    
    # ä½¿ç”¨è€…é¸æ“‡
    while True:
        try:
            choice = input(f"\nè«‹é¸æ“‡è¦æ¸¬è©¦çš„æ¨¡å‹ (0-{option_counter}): ").strip()
            
            if choice == str(option_counter):  # è¿”å›
                return
            elif choice == '0':  # æ¸¬è©¦æ‰€æœ‰æ¨¡å‹
                print("\nğŸ”„ é–‹å§‹æ¸¬è©¦æ‰€æœ‰å¯ç”¨æ¨¡å‹...")
                for category, model_info in all_options:
                    print(f"\n{'='*50}")
                    print(f"æ­£åœ¨æ¸¬è©¦: {model_info['display_name']}")
                    print('='*50)
                    test_single_model(X_test, test_df, model_info)
                print(f"\nğŸ‰ æ‰€æœ‰æ¨¡å‹æ¸¬è©¦å®Œæˆï¼")
                return
            else:
                choice_idx = int(choice) - 1
                if 0 <= choice_idx < len(all_options):
                    category, model_info = all_options[choice_idx]
                    print(f"\nğŸ¯ æ¸¬è©¦é¸å®šæ¨¡å‹: {model_info['display_name']}")
                    test_single_model(X_test, test_df, model_info)
                    return
                else:
                    print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥")
        except ValueError:
            print("âŒ è«‹è¼¸å…¥æœ‰æ•ˆæ•¸å­—")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ æ“ä½œå·²å–æ¶ˆ")
            return

def test_single_model(X_test, test_df, model_info):
    """æ¸¬è©¦å–®ä¸€æ¨¡å‹"""
    try:
        if model_info['type'] == 'traditional':
            # å‚³çµ±æ¨¡å‹
            print(f"ğŸ“Š è¼‰å…¥å‚³çµ±æ¨¡å‹: {model_info['file']}")
            import joblib
            model = joblib.load(model_info['file'])
            test_predictions = model.predict(X_test)
            
        elif model_info['type'] == 'deeplearning':
            # æ·±åº¦å­¸ç¿’æ¨¡å‹
            print(f"ğŸ§  è¼‰å…¥æ·±åº¦å­¸ç¿’æ¨¡å‹:")
            print(f"   Keras æ¨¡å‹: {model_info['keras_dir']}")
            print(f"   Scaler: {model_info['scaler_file']}")
            
            import tensorflow as tf
            import joblib
            
            # è¼‰å…¥æ¨¡å‹çµ„ä»¶
            keras_model = tf.keras.models.load_model(str(model_info['keras_dir']))
            scaler = joblib.load(model_info['scaler_file'])
            
            # é æ¸¬
            X_scaled = scaler.transform(X_test)
            test_predictions = keras_model.predict(X_scaled, verbose=0).flatten()
            
        else:
            print(f"âŒ æœªçŸ¥çš„æ¨¡å‹é¡å‹: {model_info['type']}")
            return
        
        # å„²å­˜é æ¸¬çµæœ
        save_predictions(test_predictions, test_df, model_info['name'])
        print(f"âœ… æ¸¬è©¦å®Œæˆï¼é æ¸¬æ¨£æœ¬æ•¸: {len(test_predictions)}")
        
    except ImportError as e:
        print(f"âŒ å¥—ä»¶è¼‰å…¥å¤±æ•—: {e}")
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

def test_single_model_file(X_test, test_df, model_file, model_name):
    """æ¸¬è©¦å–®ä¸€æ¨¡å‹æª”æ¡ˆ - æ”¯æ´å¤šç¨®æ ¼å¼"""
    try:
        model_path = Path(model_file)
        
        # ğŸ¯ æª¢æŸ¥æ˜¯å¦ç‚ºæ·±åº¦å­¸ç¿’æ¨¡å‹
        if model_name.startswith('DeepLearning') or '_keras' in str(model_file):
            print(f"ğŸ§  æª¢æ¸¬åˆ°æ·±åº¦å­¸ç¿’æ¨¡å‹: {model_name}")
            
            # å°‹æ‰¾å°æ‡‰çš„æª”æ¡ˆ
            model_dir = model_path.parent
            base_name = model_name.replace('_keras', '')
            
            keras_path = model_dir / f"{base_name}_keras"
            scaler_path = model_dir / f"{base_name}_scaler.joblib"
            
            if not keras_path.exists():
                print(f"âŒ æ‰¾ä¸åˆ° Keras æ¨¡å‹: {keras_path}")
                return
            
            if not scaler_path.exists():
                print(f"âŒ æ‰¾ä¸åˆ° Scaler: {scaler_path}")
                return
            
            try:
                # è¼‰å…¥æ·±åº¦å­¸ç¿’æ¨¡å‹
                import tensorflow as tf
                import joblib
                
                print(f"   è¼‰å…¥ Keras æ¨¡å‹: {keras_path}")
                keras_model = tf.keras.models.load_model(str(keras_path))
                
                print(f"   è¼‰å…¥ Scaler: {scaler_path}")
                scaler = joblib.load(scaler_path)
                
                print("   é€²è¡Œé æ¸¬...")
                X_scaled = scaler.transform(X_test)
                test_predictions = keras_model.predict(X_scaled, verbose=0).flatten()
                
            except ImportError:
                print("âŒ TensorFlow æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨æ·±åº¦å­¸ç¿’æ¨¡å‹")
                return
            except Exception as e:
                print(f"âŒ æ·±åº¦å­¸ç¿’æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
                return
        
        else:
            # å‚³çµ±æ¨¡å‹ï¼ˆæ¨¹æ¨¡å‹ã€ç·šæ€§æ¨¡å‹ï¼‰
            print(f"ğŸ“Š è¼‰å…¥å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ¨¡å‹: {model_file}")
            import joblib
            
            model = joblib.load(model_file)
            print("   é€²è¡Œé æ¸¬...")
            test_predictions = model.predict(X_test)
        
        print("å„²å­˜é æ¸¬çµæœ...")
        save_predictions(test_predictions, test_df, model_name)
        
        print(f"âœ… å®Œæˆï¼é æ¸¬æ¨£æœ¬æ•¸: {len(test_predictions)}")
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

def train_treeModel(X_train, y_train, X_valid, y_valid):
    """è¨“ç·´æ¨¹æ¨¡å‹"""
    print("\n=== é–‹å§‹æ¨¹æ¨¡å‹è¨“ç·´ ===")
    
    # åˆå§‹åŒ–æ¨¡å‹
    models = RegressionModels(random_state=42)
    
    # ç¬¬ä¸€éšæ®µï¼šåŸºç¤æ¨¹æ¨¡å‹
    print("\n1. ç¬¬ä¸€éšæ®µï¼šåŸºç¤æ¨¹æ¨¡å‹...")
    basic_models = models.get_tree_models()
    models.train_multiple_models(basic_models, X_train, y_train, X_valid, y_valid)
    
    # é¡¯ç¤ºç¬¬ä¸€éšæ®µçµæœ
    print("\n=== ç¬¬ä¸€éšæ®µçµæœ ===")
    results_stage1 = models.get_results_summary()
    print(results_stage1)
    
    # ç¬¬äºŒéšæ®µï¼šå„ªåŒ–æ¨¹æ¨¡å‹
    print("\n2. ç¬¬äºŒéšæ®µï¼šå„ªåŒ–æ¨¹æ¨¡å‹...")
    optimized_models = models.get_optimized_tree_models()
    models.train_multiple_models(optimized_models, X_train, y_train, X_valid, y_valid)
    
    # é¡¯ç¤ºæœ€çµ‚çµæœ
    print("\n=== æ¨¹æ¨¡å‹è¨“ç·´çµæœ ===")
    final_results = models.get_results_summary()
    print(final_results)
    
    # å„²å­˜æœ€ä½³æ¨¹æ¨¡å‹
    timestamp = get_timestamp()
    best_models = models.save_best_models_by_type("../models", timestamp)
    
    return models, best_models

def train_LinearModel(X_train, y_train, X_valid, y_valid):
    """è¨“ç·´ç·šæ€§æ¨¡å‹"""
    print("\n=== é–‹å§‹ç·šæ€§æ¨¡å‹è¨“ç·´ ===")
    
    # åˆå§‹åŒ–æ¨¡å‹
    models = RegressionModels(random_state=42)
    
    # è¨“ç·´ç·šæ€§æ¨¡å‹
    print("\n1. è¨“ç·´ç·šæ€§æ¨¡å‹...")
    linear_models = models.get_linear_models()
    models.train_multiple_models(linear_models, X_train, y_train, X_valid, y_valid)
    
    # é¡¯ç¤ºçµæœ
    print("\n=== ç·šæ€§æ¨¡å‹è¨“ç·´çµæœ ===")
    results = models.get_results_summary()
    print(results)
    
    # å„²å­˜æœ€ä½³ç·šæ€§æ¨¡å‹
    timestamp = get_timestamp()
    best_models = models.save_best_models_by_type("../models", timestamp)
    
    return models, best_models

def train_DLModel(X_train, y_train, X_valid, y_valid):
    """è¨“ç·´æ·±åº¦å­¸ç¿’æ¨¡å‹"""
    print("\n=== é–‹å§‹æ·±åº¦å­¸ç¿’æ¨¡å‹è¨“ç·´ ===")
    
    # æª¢æŸ¥ TensorFlow
    try:
        import tensorflow as tf
        gpus = tf.config.list_physical_devices('GPU')
        gpu_available = len(gpus) > 0
        print(f"ğŸ” GPU ç‹€æ…‹: {'å¯ç”¨' if gpu_available else 'ä¸å¯ç”¨'} ({len(gpus)} å€‹ GPU)")
    except ImportError:
        print("âš ï¸ TensorFlow æœªå®‰è£ï¼Œç„¡æ³•è¨“ç·´æ·±åº¦å­¸ç¿’æ¨¡å‹")
        return None, {}
    
    # ç²å–æ·±åº¦å­¸ç¿’æ¨¡å‹å·¥å» å‡½æ•¸
    models = RegressionModels()
    dl_model_factory = models.get_deep_learning_models()
    
    if not dl_model_factory:
        print("âŒ ç„¡æ³•ç²å–æ·±åº¦å­¸ç¿’æ¨¡å‹")
        return None, {}
    
    # ä½¿ç”¨å¯¦éš›çš„ç‰¹å¾µæ•¸é‡å‰µå»ºæ¨¡å‹
    input_dim = X_train.shape[1]
    print(f"ğŸ“Š è¨“ç·´æ•¸æ“šå½¢ç‹€: {X_train.shape}, ç‰¹å¾µæ•¸: {input_dim}")
    
    dl_models = dl_model_factory(input_dim)
    
    print("1. è¨“ç·´æ·±åº¦å­¸ç¿’æ¨¡å‹...")
    print("âš ï¸  æ³¨æ„ï¼šæ·±åº¦å­¸ç¿’æ¨¡å‹éœ€è¦è¼ƒé•·æ™‚é–“è¨“ç·´...")
    
    results = []
    best_score = float('inf')
    best_model = None
    best_model_name = None
    
    for name, model in dl_models.items():
        print(f"\nè¨“ç·´ {name}...")
        
        try:
            # è¨“ç·´æ¨¡å‹
            start_time = time.time()
            model.fit(X_train, y_train)
            training_time = time.time() - start_time
            
            # é©—è­‰æ¨¡å‹
            y_pred = model.predict(X_valid)
            
            # è¨ˆç®—æŒ‡æ¨™
            from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
            import numpy as np
            
            rmse = np.sqrt(mean_squared_error(y_valid, y_pred))
            mae = mean_absolute_error(y_valid, y_pred)
            r2 = r2_score(y_valid, y_pred)
            mape = np.mean(np.abs((y_valid - y_pred) / y_valid)) * 100
            
            results.append({
                'Model': name,
                'Valid_RMSE': rmse,
                'Valid_MAE': mae, 
                'Valid_R2': r2,
                'Valid_MAPE': mape,
                'Training_Time(s)': training_time
            })
            
            print(f"âœ… {name} è¨“ç·´å®Œæˆ")
            print(f"   RMSE: {rmse:,.0f}")
            print(f"   RÂ²: {r2:.4f}")
            print(f"   è¨“ç·´æ™‚é–“: {training_time:.1f} ç§’")
            
            # è¨˜éŒ„æœ€ä½³æ¨¡å‹
            if rmse < best_score:
                best_score = rmse
                best_model = model
                best_model_name = name
                
        except Exception as e:
            print(f"âŒ {name} è¨“ç·´å¤±æ•—: {str(e)}")
    
    # é¡¯ç¤ºçµæœ
    if results:
        results_df = pd.DataFrame(results)
        print(f"\nğŸ“Š æ·±åº¦å­¸ç¿’æ¨¡å‹è¨“ç·´çµæœ:")
        print(results_df.to_string(index=False))
        
        # å„²å­˜æœ€ä½³æ¨¡å‹
        if best_model is not None:
            # ğŸ• ç”Ÿæˆå¸¶æ™‚é–“æˆ³è¨˜çš„æ¨¡å‹åç¨±
            timestamp = get_timestamp()
            timestamped_model_name = f"{best_model_name}_{timestamp}"
            
            print(f"\nğŸ’¾ å„²å­˜æœ€ä½³æ·±åº¦å­¸ç¿’æ¨¡å‹: {timestamped_model_name}")
            try:
                model_dir = Path("../models")
                model_dir.mkdir(exist_ok=True)
                
                # ğŸ¯ ä½¿ç”¨ TensorFlow åŸç”Ÿæ ¼å¼å„²å­˜
                if hasattr(best_model, 'model') and hasattr(best_model, 'scaler'):
                    keras_model = best_model.model
                    scaler = best_model.scaler
                    
                    # å„²å­˜ Keras æ¨¡å‹
                    tf_model_path = model_dir / f"{timestamped_model_name}_keras"
                    keras_model.save(str(tf_model_path))
                    print(f"âœ… Keras æ¨¡å‹å·²å„²å­˜: {tf_model_path}")
                    
                    # å„²å­˜ Scaler
                    import joblib
                    scaler_path = model_dir / f"{timestamped_model_name}_scaler.joblib"
                    joblib.dump(scaler, scaler_path)
                    print(f"âœ… Scaler å·²å„²å­˜: {scaler_path}")
                    
                    # å„²å­˜æ¨¡å‹è³‡è¨Š
                    info_path = model_dir / f"{timestamped_model_name}_info.txt"
                    with open(info_path, 'w', encoding='utf-8') as f:
                        f.write(f"Model: {timestamped_model_name}\n")
                        f.write(f"Original_Name: {best_model_name}\n")
                        f.write(f"Timestamp: {timestamp}\n")
                        f.write(f"Training_Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                        f.write(f"Type: DeepLearning\n")
                        f.write(f"Input_dim: {best_model.input_dim}\n")
                        f.write(f"RMSE: {best_score:.2f}\n")
                        f.write(f"Keras_model: {timestamped_model_name}_keras\n")
                        f.write(f"Scaler: {timestamped_model_name}_scaler.joblib\n")
                    print(f"âœ… æ¨¡å‹è³‡è¨Šå·²å„²å­˜: {info_path}")
                    
                    print("   æ ¼å¼: TensorFlow åŸç”Ÿæ ¼å¼")
                    print(f"   æ™‚é–“æˆ³è¨˜: {timestamp}")
                    print("   æ¸¬è©¦: éœ€è¦ç‰¹æ®Šè¼‰å…¥æ–¹æ³•")
                else:
                    print("âŒ æ¨¡å‹æ ¼å¼ä¸æ­£ç¢ºï¼Œç„¡æ³•å„²å­˜")
                    
            except Exception as e:
                print(f"âŒ æ·±åº¦å­¸ç¿’æ¨¡å‹å„²å­˜å¤±æ•—: {str(e)}")
        
        return models, {'deep_learning': {'name': best_model_name, 'timestamped_name': timestamped_model_name, 'model': best_model, 'rmse': best_score, 'timestamp': timestamp}}
    else:
        print("âŒ æ²’æœ‰æˆåŠŸè¨“ç·´çš„æ·±åº¦å­¸ç¿’æ¨¡å‹")
        return None, {}

def get_main_mode():
    """å–å¾—ä¸»è¦æ¨¡å¼é¸æ“‡"""
    print("\nè«‹é¸æ“‡æ¨¡å¼:")
    print("1. Train (è¨“ç·´æ¨¡å‹)")
    print("2. Test (æ¸¬è©¦é æ¸¬)")
    print("0. é€€å‡º")
    
    while True:
        choice = input("\nè«‹è¼¸å…¥é¸æ“‡ (0-2): ").strip()
        if choice == '0':
            return 'exit'
        elif choice == '1':
            return 'train'
        elif choice == '2':
            return 'test'
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥")

def get_train_mode():
    """å–å¾—è¨“ç·´æ¨¡å¼é¸æ“‡"""
    print("\nè«‹é¸æ“‡è¨“ç·´æ¨¡å¼:")
    print("1. æ¨¹æ¨¡å‹ (Tree Models)")
    print("2. ç·šæ€§æ¨¡å‹ (Linear Models)")
    print("3. æ·±åº¦å­¸ç¿’æ¨¡å‹ (Deep Learning)")
    print("4. å…¨éƒ¨è¨“ç·´ (All Models)")
    print("0. è¿”å›ä¸»é¸å–®")
    
    while True:
        choice = input("\nè«‹è¼¸å…¥é¸æ“‡ (0-4): ").strip()
        if choice == '0':
            return 'back'
        elif choice == '1':
            return 'tree'
        elif choice == '2':
            return 'linear'
        elif choice == '3':
            return 'dl'
        elif choice == '4':
            return 'all'
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥")

def train_all_models(X_train, y_train, X_valid, y_valid):
    """è¨“ç·´æ‰€æœ‰é¡å‹çš„æ¨¡å‹"""
    print("\n=== é–‹å§‹è¨“ç·´æ‰€æœ‰æ¨¡å‹ ===")
    
    all_models = RegressionModels(random_state=42)
    
    # 1. æ¨¹æ¨¡å‹
    print("\nğŸŒ³ ç¬¬ä¸€éšæ®µï¼šæ¨¹æ¨¡å‹...")
    tree_models = all_models.get_tree_models()
    all_models.train_multiple_models(tree_models, X_train, y_train, X_valid, y_valid)
    
    optimized_tree_models = all_models.get_optimized_tree_models()
    all_models.train_multiple_models(optimized_tree_models, X_train, y_train, X_valid, y_valid)
    
    # 2. ç·šæ€§æ¨¡å‹
    print("\nğŸ“Š ç¬¬äºŒéšæ®µï¼šç·šæ€§æ¨¡å‹...")
    linear_models = all_models.get_linear_models()
    all_models.train_multiple_models(linear_models, X_train, y_train, X_valid, y_valid)
    
    # 3. æ·±åº¦å­¸ç¿’æ¨¡å‹
    print("\nğŸ§  ç¬¬ä¸‰éšæ®µï¼šæ·±åº¦å­¸ç¿’æ¨¡å‹...")
    try:
        dl_models = all_models.get_deep_learning_models()
        if dl_models:
            all_models.train_multiple_models(dl_models, X_train, y_train, X_valid, y_valid)
        else:
            print("âš ï¸ è·³éæ·±åº¦å­¸ç¿’æ¨¡å‹ï¼ˆTensorFlow æœªå®‰è£ï¼‰")
    except Exception as e:
        print(f"âš ï¸ æ·±åº¦å­¸ç¿’æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
    
    # é¡¯ç¤ºæœ€çµ‚çµæœ
    print("\n=== æ‰€æœ‰æ¨¡å‹è¨“ç·´çµæœ ===")
    results = all_models.get_results_summary()
    print(results)
    
    # å„²å­˜æœ€ä½³æ¨¡å‹
    timestamp = get_timestamp()
    best_models = all_models.save_best_models_by_type("../models", timestamp)
    
    return all_models, best_models

def main_menu():
    """ä¸»é¸å–®æµç¨‹"""
    while True:
        mode = get_main_mode()
        
        if mode == 'exit':
            print("æ„Ÿè¬ä½¿ç”¨ï¼")
            break
        
        elif mode == 'train':
            # è¼‰å…¥è³‡æ–™
            data = load_data_and_prepare()
            if data[0] is None:
                print("âŒ è³‡æ–™è¼‰å…¥å¤±æ•—")
                continue
            
            X_train, y_train, X_valid, y_valid, X_test, test_df = data
            
            # é¸æ“‡è¨“ç·´æ¨¡å¼
            train_mode = get_train_mode()
            
            if train_mode == 'back':
                continue
            elif train_mode == 'tree':
                train_treeModel(X_train, y_train, X_valid, y_valid)
            elif train_mode == 'linear':
                train_LinearModel(X_train, y_train, X_valid, y_valid)
            elif train_mode == 'dl':
                train_DLModel(X_train, y_train, X_valid, y_valid)
            elif train_mode == 'all':
                train_all_models(X_train, y_train, X_valid, y_valid)
        
        elif mode == 'test':
            # è¼‰å…¥è³‡æ–™
            data = load_data_and_prepare()
            model_name = input("è«‹è¼¸å…¥è¦æ¸¬è©¦çš„æ¨¡å‹åç¨± (ç•™ç©ºè¡¨ç¤ºè‡ªå‹•é¸æ“‡æœ€æ–°æ¨¡å‹): ").strip()
            if data[0] is None:
                print("âŒ è³‡æ–™è¼‰å…¥å¤±æ•—")
                continue
            
            X_train, y_train, X_valid, y_valid, X_test, test_df = data
            test_model(X_test, test_df, model_name)

if __name__ == "__main__":
    print("ğŸ  æˆ¿åœ°ç”¢åƒ¹æ ¼é æ¸¬ç³»çµ±")
    print("=" * 50)
    
    try:
        main_menu()
    except KeyboardInterrupt:
        print("\n\nç¨‹åºå·²ä¸­æ­¢")
    except Exception as e:
        print(f"âŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nç¨‹åºçµæŸ")
