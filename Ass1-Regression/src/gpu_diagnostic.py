#!/usr/bin/env python3
"""
GPU å’Œ CUDA è¨ºæ–·å·¥å…·
å¹«åŠ©è¨ºæ–·ç‚ºä»€éº¼ TensorFlow ä½¿ç”¨ CPU è€Œä¸æ˜¯ GPU
"""

def check_nvidia_gpu():
    """æª¢æŸ¥ NVIDIA GPU å’Œé©…å‹•"""
    print("ğŸ” æª¢æŸ¥ NVIDIA GPU å’Œé©…å‹•...")
    
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("âœ… NVIDIA GPU å’Œé©…å‹•æ­£å¸¸")
            print("GPU è³‡è¨Š:")
            # åªé¡¯ç¤ºå‰å¹¾è¡Œé‡è¦è³‡è¨Š
            lines = result.stdout.split('\n')[:15]
            for line in lines:
                if line.strip():
                    print(f"   {line}")
            return True
        else:
            print("âŒ nvidia-smi åŸ·è¡Œå¤±æ•—")
            return False
    except subprocess.TimeoutExpired:
        print("âŒ nvidia-smi åŸ·è¡Œè¶…æ™‚")
        return False
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° nvidia-smi æŒ‡ä»¤")
        print("ğŸ’¡ å¯èƒ½åŸå› :")
        print("   1. æœªå®‰è£ NVIDIA é©…å‹•")
        print("   2. ç³»çµ±ç’°å¢ƒè®Šæ•¸æœªè¨­å®š")
        print("   3. æ²’æœ‰ NVIDIA GPU")
        return False
    except Exception as e:
        print(f"âŒ æª¢æŸ¥ GPU æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def check_cuda_installation():
    """æª¢æŸ¥ CUDA å®‰è£"""
    print("\nğŸ” æª¢æŸ¥ CUDA å®‰è£...")
    
    try:
        import subprocess
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("âœ… CUDA ç·¨è­¯å™¨ (nvcc) å¯ç”¨")
            version_line = [line for line in result.stdout.split('\n') if 'release' in line.lower()]
            if version_line:
                print(f"   ç‰ˆæœ¬: {version_line[0].strip()}")
            return True
        else:
            print("âŒ CUDA ç·¨è­¯å™¨ (nvcc) ä¸å¯ç”¨")
            return False
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° nvcc æŒ‡ä»¤")
        print("ğŸ’¡ å¯èƒ½åŸå› :")
        print("   1. æœªå®‰è£ CUDA Toolkit")
        print("   2. CUDA æœªåŠ å…¥ PATH ç’°å¢ƒè®Šæ•¸")
        return False
    except Exception as e:
        print(f"âŒ æª¢æŸ¥ CUDA æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def check_tensorflow():
    """æª¢æŸ¥ TensorFlow å®‰è£å’Œ GPU æ”¯æ´"""
    print("\nğŸ” æª¢æŸ¥ TensorFlow...")
    
    try:
        import tensorflow as tf
        print(f"âœ… TensorFlow å·²å®‰è£ï¼Œç‰ˆæœ¬: {tf.__version__}")
        
        # æª¢æŸ¥ç·¨è­¯æ™‚æ˜¯å¦åŒ…å« CUDA æ”¯æ´
        is_cuda_built = tf.test.is_built_with_cuda()
        print(f"   ç·¨è­¯æ™‚æ˜¯å¦åŒ…å« CUDA: {is_cuda_built}")
        
        if not is_cuda_built:
            print("âŒ TensorFlow æœªåŒ…å« CUDA æ”¯æ´")
            print("ğŸ’¡ è§£æ±ºæ–¹æ³•:")
            print("   é‡æ–°å®‰è£ GPU ç‰ˆæœ¬:")
            print("   pip uninstall tensorflow")
            print("   pip install tensorflow[and-cuda]")
            return False
        
        # æª¢æŸ¥å»ºç½®è³‡è¨Š
        build_info = tf.sysconfig.get_build_info()
        print(f"   ç·¨è­¯æ™‚ CUDA ç‰ˆæœ¬: {build_info.get('cuda_version', 'N/A')}")
        print(f"   ç·¨è­¯æ™‚ cuDNN ç‰ˆæœ¬: {build_info.get('cudnn_version', 'N/A')}")
        
        # æª¢æŸ¥å¯ç”¨è¨­å‚™
        physical_devices = tf.config.list_physical_devices()
        print("   å¯ç”¨è¨­å‚™:")
        for device in physical_devices:
            print(f"     {device}")
        
        # å°ˆé–€æª¢æŸ¥ GPU
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"   ğŸš€ æª¢æ¸¬åˆ° {len(gpus)} å€‹ GPU")
            
            # æ¸¬è©¦ GPU è¨ˆç®—
            try:
                with tf.device('/GPU:0'):
                    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
                    b = tf.constant([[5.0, 6.0], [7.0, 8.0]])
                    c = tf.matmul(a, b)
                print("   âœ… GPU è¨ˆç®—æ¸¬è©¦æˆåŠŸ")
                print(f"   æ¸¬è©¦çµæœ: {c.numpy()}")
                return True
                
            except Exception as e:
                print(f"   âŒ GPU è¨ˆç®—æ¸¬è©¦å¤±æ•—: {e}")
                return False
        else:
            print("   âŒ æœªæª¢æ¸¬åˆ° GPU")
            return False
            
    except ImportError:
        print("âŒ TensorFlow æœªå®‰è£")
        print("ğŸ’¡ å®‰è£æŒ‡ä»¤:")
        print("   CPU ç‰ˆæœ¬: pip install tensorflow")
        print("   GPU ç‰ˆæœ¬: pip install tensorflow[and-cuda]")
        return False
    except Exception as e:
        print(f"âŒ æª¢æŸ¥ TensorFlow æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def check_environment_variables():
    """æª¢æŸ¥ç›¸é—œç’°å¢ƒè®Šæ•¸"""
    print("\nğŸ” æª¢æŸ¥ç’°å¢ƒè®Šæ•¸...")
    
    import os
    
    important_vars = [
        'CUDA_PATH',
        'CUDA_HOME',
        'LD_LIBRARY_PATH',
        'PATH'
    ]
    
    for var in important_vars:
        value = os.environ.get(var)
        if value:
            if var == 'PATH':
                # PATH å¤ªé•·ï¼Œåªé¡¯ç¤ºåŒ…å« cuda çš„éƒ¨åˆ†
                cuda_paths = [p for p in value.split(os.pathsep) if 'cuda' in p.lower()]
                if cuda_paths:
                    print(f"   {var} (CUDA ç›¸é—œ): {cuda_paths}")
                else:
                    print(f"   {var}: æœªåŒ…å« CUDA è·¯å¾‘")
            else:
                print(f"   {var}: {value}")
        else:
            print(f"   {var}: æœªè¨­å®š")

def provide_solutions():
    """æä¾›è§£æ±ºæ–¹æ¡ˆ"""
    print("\nğŸ”§ å¸¸è¦‹å•é¡Œè§£æ±ºæ–¹æ¡ˆ:")
    
    print("\n1. å¦‚æœé¡¯ç¤º 'TensorFlow æœªåŒ…å« CUDA æ”¯æ´':")
    print("   pip uninstall tensorflow")
    print("   pip install tensorflow[and-cuda]")
    
    print("\n2. å¦‚æœ nvidia-smi ä¸å¯ç”¨:")
    print("   - å®‰è£æœ€æ–°çš„ NVIDIA é©…å‹•ç¨‹å¼")
    print("   - é‡æ–°å•Ÿå‹•é›»è…¦")
    
    print("\n3. å¦‚æœ CUDA ç‰ˆæœ¬ä¸åŒ¹é…:")
    print("   - æª¢æŸ¥ TensorFlow æ–‡ä»¶çš„ CUDA ç‰ˆæœ¬éœ€æ±‚")
    print("   - å®‰è£å°æ‡‰ç‰ˆæœ¬çš„ CUDA Toolkit")
    
    print("\n4. å¦‚æœç’°å¢ƒè®Šæ•¸å•é¡Œ:")
    print("   - ç¢ºèª CUDA å®‰è£è·¯å¾‘åŠ å…¥ PATH")
    print("   - Windows: é€šå¸¸åœ¨ C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.x\\bin")
    print("   - Linux: é€šå¸¸åœ¨ /usr/local/cuda/bin")

def main():
    """ä¸»è¨ºæ–·æµç¨‹"""
    print("ğŸ  GPU å’Œ CUDA è¨ºæ–·å·¥å…·")
    print("=" * 50)
    
    # é€æ­¥æª¢æŸ¥
    gpu_ok = check_nvidia_gpu()
    cuda_ok = check_cuda_installation()
    tf_ok = check_tensorflow()
    
    check_environment_variables()
    
    # ç¸½çµ
    print("\n" + "=" * 50)
    print("ğŸ“Š è¨ºæ–·çµæœç¸½çµ:")
    print(f"   NVIDIA GPU: {'âœ…' if gpu_ok else 'âŒ'}")
    print(f"   CUDA å®‰è£: {'âœ…' if cuda_ok else 'âŒ'}")
    print(f"   TensorFlow GPU: {'âœ…' if tf_ok else 'âŒ'}")
    
    if gpu_ok and cuda_ok and tf_ok:
        print("\nğŸ‰ æ‰€æœ‰æª¢æŸ¥é€šéï¼TensorFlow æ‡‰è©²å¯ä»¥ä½¿ç”¨ GPU")
    else:
        print("\nâš ï¸ ç™¼ç¾å•é¡Œï¼Œè«‹åƒè€ƒè§£æ±ºæ–¹æ¡ˆ")
        provide_solutions()

if __name__ == "__main__":
    main()
