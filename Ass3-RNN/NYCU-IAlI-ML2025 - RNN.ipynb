{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5863,
     "status": "ok",
     "timestamp": 1761922805717,
     "user": {
      "displayName": "å¾è‘†é©Šï¼ˆBenï¼‰",
      "userId": "03817416447319536364"
     },
     "user_tz": -480
    },
    "id": "e8a8381e",
    "outputId": "73d70e8b-0671-4235-9dd8-aa248d999452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "# Install the Kaggle library\n",
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19028,
     "status": "ok",
     "timestamp": 1761925591368,
     "user": {
      "displayName": "å¾è‘†é©Šï¼ˆBenï¼‰",
      "userId": "03817416447319536364"
     },
     "user_tz": -480
    },
    "id": "24bda685",
    "outputId": "6ca49e10-81a5-4ace-f1bb-d05b03a2b534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nycu-i-al-i-ml-2025-recurrent-neural-networks.zip to /content/Dataset/Dataset\n",
      "100% 1.31G/1.31G [00:08<00:00, 259MB/s]\n",
      "100% 1.31G/1.31G [00:08<00:00, 170MB/s]\n",
      "ls: cannot access './Dataset': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "api_token = {\"username\":\"paohuah\",\"key\":\"009c81a93477f603c39ec21a6205948b\"}\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"/root/.kaggle\"):\n",
    "    os.makedirs(\"/root/.kaggle\")\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# ä½¿ç”¨ ./Dataset ä½œç‚ºä¸‹è¼‰ç›®éŒ„\n",
    "if not os.path.exists(\"./Dataset\"):\n",
    "    os.makedirs(\"./Dataset\")\n",
    "os.chdir('./Dataset')\n",
    "!kaggle competitions download -c nycu-i-al-i-ml-2025-recurrent-neural-networks\n",
    "!ls ./Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qne6E_IP2DsE"
   },
   "source": [
    "## ä¸Šå‚³ç·šä¸‹ç·¨è¼¯å¥½çš„è³‡æ–™é›†\n",
    "\n",
    "## whisperæ¨¡å‹å¾®èª¿\n",
    "é€™å€‹æ¨¡å‹æ˜¯ç”±åœ‹ç«‹è‡ºå—å¤§å­¸åŸ·è¡Œåœ‹ç§‘æœƒç”¢å­¸åˆä½œè¨ˆç•«ï¼Œä½¿ç”¨ openai/whisper-large-v3-turbo å¾®èª¿çš„ç‰ˆæœ¬ï¼Œä¸¦åŸ·è¡Œåœ‹ç§‘æœƒTAIDEå°è‹±èªå®¶åº­å…ˆå°è¨ˆç•«ï¼Œèˆ‡çœŸå¹³å‡ºç‰ˆç¤¾åˆä½œï¼Œä½¿ç”¨ä¸­å°å­¸æ•™æå…§å®¹åŠå­¸ç”Ÿå­¸ç¿’è³‡æ–™é€²è¡Œæ¨¡å‹å¾®èª¿ï¼Œç”¨æ–¼çœŸå¹³æ•™æå°èªè¾¨è­˜ã€‚ä¸¦èˆ‡åœ‹ç ”é™¢åœ‹ç¶²ä¸­å¿ƒåˆä½œï¼Œé‹ç”¨åœ‹ç¶²ä¸­å¿ƒç®—åŠ›ä»¥åŠTAIDEæ¨¡å‹ï¼Œå…±åŒå»ºæ§‹ä¸­å°å­¸å°èªAIå­¸ç¿’æ¨¡å‹ã€‚\n",
    "\n",
    "```\n",
    "pip install torch torchvision torchaudio transformers\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ RawBoost è³‡æ–™å¢å¼·\n",
    "\n",
    "ä½¿ç”¨ RawBoost æ¼”ç®—æ³•å°è¨“ç·´è³‡æ–™é€²è¡Œå¢å¼·ï¼Œæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›\n",
    "\n",
    "**RawBoost æ¼”ç®—æ³•èªªæ˜ï¼š**\n",
    "- **Algorithm 1 (LnL)**: ç·šæ€§/éç·šæ€§å·ç©å™ªéŸ³\n",
    "- **Algorithm 2 (ISD)**: è„ˆè¡è¨Šè™Ÿç›¸ä¾å™ªéŸ³\n",
    "- **Algorithm 3 (SSI)**: å¹³ç©©è¨Šè™Ÿç¨ç«‹å™ªéŸ³ âœ… **æ¨è–¦ç”¨æ–¼èªéŸ³è¾¨è­˜**\n",
    "- **Algorithm 6 (1+3)**: çµåˆ LnL å’Œ SSI âœ… **æ¨è–¦ç”¨æ–¼èªéŸ³è¾¨è­˜**\n",
    "\n",
    "**å»ºè­°è¨­å®šï¼š**\n",
    "- å°æ–¼å°èªèªéŸ³è¾¨è­˜ï¼Œå»ºè­°ä½¿ç”¨ **Algorithm 3 (SSI)** æˆ– **Algorithm 6 (1+3)**\n",
    "- é€™äº›æ¼”ç®—æ³•æœƒæ·»åŠ è‡ªç„¶çš„èƒŒæ™¯å™ªéŸ³ï¼Œæ¨¡æ“¬çœŸå¯¦ç’°å¢ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ RawBoost è³‡æ–™å¢å¼· - ä½¿ç”¨è…³æœ¬ç‰ˆæœ¬\n",
    "\n",
    "# æ–¹æ³• 1: ä½¿ç”¨å‘½ä»¤åˆ—åŸ·è¡Œ\n",
    "# !python data_augmentation_rawboost.py \\\n",
    "#     --input_dir \"./train/preprocessed\" \\\n",
    "#     --output_dir \"./train/rawboost_augmented\" \\\n",
    "#     --csv_input \"./train/trainAgg-toneless.csv\" \\\n",
    "#     --csv_output \"./train/trainAgg-toneless-rawboost.csv\" \\\n",
    "#     --algo_types 3 6 \\\n",
    "#     --num_aug 1\n",
    "\n",
    "# æ–¹æ³• 2: ç›´æ¥åœ¨ Notebook ä¸­åŸ·è¡Œ (æ¨è–¦)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from RawBoost import ISD_additive_noise, LnL_convolutive_noise, SSI_additive_noise, normWav\n",
    "\n",
    "# RawBoost åƒæ•¸è¨­å®š\n",
    "class RawBoostConfig:\n",
    "    def __init__(self):\n",
    "        # Algorithm 1: LnL\n",
    "        self.N_f = 5\n",
    "        self.nBands = 5\n",
    "        self.minF = 20\n",
    "        self.maxF = 8000\n",
    "        self.minBW = 100\n",
    "        self.maxBW = 1000\n",
    "        self.minCoeff = 10\n",
    "        self.maxCoeff = 100\n",
    "        self.minG = 0\n",
    "        self.maxG = 0\n",
    "        self.minBiasLinNonLin = 5\n",
    "        self.maxBiasLinNonLin = 20\n",
    "        \n",
    "        # Algorithm 2: ISD\n",
    "        self.P = 10\n",
    "        self.g_sd = 2\n",
    "        \n",
    "        # Algorithm 3: SSI\n",
    "        self.SNRmin = 10\n",
    "        self.SNRmax = 40\n",
    "\n",
    "def apply_rawboost(audio, sr, args, algo_type):\n",
    "    \"\"\"æ‡‰ç”¨ RawBoost å¢å¼·\"\"\"\n",
    "    if algo_type == 1:\n",
    "        return LnL_convolutive_noise(\n",
    "            audio, args.N_f, args.nBands, args.minF, args.maxF,\n",
    "            args.minBW, args.maxBW, args.minCoeff, args.maxCoeff,\n",
    "            args.minG, args.maxG, args.minBiasLinNonLin, args.maxBiasLinNonLin, sr\n",
    "        )\n",
    "    elif algo_type == 2:\n",
    "        return ISD_additive_noise(audio, args.P, args.g_sd)\n",
    "    elif algo_type == 3:\n",
    "        return SSI_additive_noise(\n",
    "            audio, args.SNRmin, args.SNRmax, args.nBands, args.minF, args.maxF,\n",
    "            args.minBW, args.maxBW, args.minCoeff, args.maxCoeff,\n",
    "            args.minG, args.maxG, sr\n",
    "        )\n",
    "    elif algo_type == 6:  # 1+3\n",
    "        audio = LnL_convolutive_noise(\n",
    "            audio, args.N_f, args.nBands, args.minF, args.maxF,\n",
    "            args.minBW, args.maxBW, args.minCoeff, args.maxCoeff,\n",
    "            args.minG, args.maxG, args.minBiasLinNonLin, args.maxBiasLinNonLin, sr\n",
    "        )\n",
    "        return SSI_additive_noise(\n",
    "            audio, args.SNRmin, args.SNRmax, args.nBands, args.minF, args.maxF,\n",
    "            args.minBW, args.maxBW, args.minCoeff, args.maxCoeff,\n",
    "            args.minG, args.maxG, sr\n",
    "        )\n",
    "    return audio\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    \"\"\"æ­£è¦åŒ–éŸ³è¨Š\"\"\"\n",
    "    if np.max(np.abs(audio)) > 0:\n",
    "        audio = audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "def audio_to_int16(audio):\n",
    "    \"\"\"è½‰æ›ç‚º int16\"\"\"\n",
    "    audio = normalize_audio(audio)\n",
    "    return (audio * 32767).astype(np.int16)\n",
    "\n",
    "# ==================== åŸ·è¡Œå¢å¼· ====================\n",
    "\n",
    "# è¨­å®šè·¯å¾‘\n",
    "input_dir = \"./train/preprocessed\"\n",
    "# input_dir = \"./train/train/train\"\n",
    "output_dir = \"./train/rawboost_augmentedV2\"\n",
    "csv_input = \"./train/train/trainAgg-toneless.csv\"\n",
    "csv_output = \"./train/train/trainAgg-toneless-rawboost.csv\"\n",
    "\n",
    "# è¨­å®šåƒæ•¸\n",
    "algo_types = [3, 6]  # ä½¿ç”¨ SSI å’Œ LnL+SSI\n",
    "target_sr = 16000\n",
    "\n",
    "# å»ºç«‹è¼¸å‡ºç›®éŒ„\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# è¼‰å…¥ CSV\n",
    "df = pd.read_csv(csv_input)\n",
    "print(f\"ğŸ“Š è®€å– {csv_input}ï¼Œå…± {len(df)} ç­†è³‡æ–™\\n\")\n",
    "\n",
    "# åˆå§‹åŒ–åƒæ•¸\n",
    "rawboost_args = RawBoostConfig()\n",
    "new_rows = []\n",
    "\n",
    "# å–å¾—éŸ³è¨Šæª”æ¡ˆ\n",
    "audio_files = [f for f in os.listdir(input_dir) if f.endswith('.wav')]\n",
    "\n",
    "print(f\"ğŸµ é–‹å§‹è™•ç† {len(audio_files)} å€‹éŸ³è¨Šæª”æ¡ˆ...\")\n",
    "print(f\"ğŸ“Œ ä½¿ç”¨æ¼”ç®—æ³•: {algo_types}\\n\")\n",
    "\n",
    "# è™•ç†æ¯å€‹æª”æ¡ˆ\n",
    "for file in tqdm(audio_files, desc=\"RawBoost å¢å¼·\"):\n",
    "    try:\n",
    "        # è¼‰å…¥éŸ³è¨Š\n",
    "        audio_path = os.path.join(input_dir, file)\n",
    "        audio, sr = librosa.load(audio_path, sr=target_sr)\n",
    "        \n",
    "        file_id = file.replace('.wav', '')\n",
    "\n",
    "        # âœ… æª¢æŸ¥ file_id æ˜¯å¦ç‚ºç´”æ•¸å­—\n",
    "        if not file_id.isdigit():\n",
    "            print(f\"\\nâš ï¸ è·³ééæ•¸å­—æª”å: {file}\")\n",
    "            continue\n",
    "                \n",
    "        # å„²å­˜åŸå§‹æª”æ¡ˆ (æ¨™æº–åŒ–)\n",
    "        audio_normalized = audio_to_int16(audio)\n",
    "        wavfile.write(os.path.join(output_dir, file), target_sr, audio_normalized)\n",
    "        \n",
    "        # å°æ¯ç¨®æ¼”ç®—æ³•ç”Ÿæˆå¢å¼·ç‰ˆæœ¬\n",
    "        for algo_type in algo_types:\n",
    "            # æ‡‰ç”¨ RawBoost\n",
    "            augmented_audio = apply_rawboost(audio.copy(), sr, rawboost_args, algo_type)\n",
    "            augmented_audio_int16 = audio_to_int16(augmented_audio)\n",
    "            \n",
    "            # ç”Ÿæˆæ–°æª”å\n",
    "            aug_filename = f\"{file_id}_rawboost_algo{algo_type}.wav\"\n",
    "            \n",
    "            # å„²å­˜\n",
    "            wavfile.write(\n",
    "                os.path.join(output_dir, aug_filename),\n",
    "                target_sr,\n",
    "                augmented_audio_int16\n",
    "            )\n",
    "            \n",
    "            # æ›´æ–° CSV\n",
    "            original_row = df.loc[df['id'] == int(file_id)].iloc[0].copy()\n",
    "            original_row['id'] = aug_filename.replace('.wav', '')\n",
    "            new_rows.append(original_row)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ è™•ç†å¤±æ•— {file}: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… éŸ³è¨Šè™•ç†å®Œæˆï¼\")\n",
    "print(f\"   åŸå§‹æª”æ¡ˆ: {len(audio_files)}\")\n",
    "print(f\"   å¢å¼·æª”æ¡ˆ: {len(new_rows)}\")\n",
    "print(f\"   ç¸½è¨ˆ: {len(audio_files) + len(new_rows)}\")\n",
    "\n",
    "# åˆä½µä¸¦å„²å­˜ CSV\n",
    "df_augmented = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "df_augmented.to_csv(csv_output, index=False)\n",
    "\n",
    "print(f\"\\nâœ… CSV æª”æ¡ˆå·²æ›´æ–°: {csv_output}\")\n",
    "print(f\"   ç¸½ç­†æ•¸: {len(df_augmented)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è³‡æ–™åŠ å¼·V2\n",
    "æ··å’ŒèˆŠæ–¹æ³•+Rawboost 3&6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== è³‡æ–™åŠ å¼·V2: æ··åˆèˆŠæ–¹æ³• + RawBoost (å¤šåŸ·è¡Œç·’åŠ é€Ÿç‰ˆ) ====================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "# è¨­å®šè·¯å¾‘\n",
    "input_Old_dir = \"./train/preprocessed\"\n",
    "input_RawBoost_dir = \"./train/rawboost_augmentedV1\"\n",
    "output_dir = \"./train/rawboost_augmentedV2\"\n",
    "\n",
    "csv_Old_input = \"./train/train/trainAgg-toneless.csv\"\n",
    "csv_RawBoost_input = \"./train/train/train-toneless-rawboost.csv\"\n",
    "csv_output = \"./train/train/trainAgg-toneless-rawboost.csv\"\n",
    "\n",
    "# âœ… å¤šåŸ·è¡Œç·’è¨­å®š\n",
    "NUM_WORKERS = 8  # Colab å»ºè­° 4-8ï¼Œæœ¬åœ°å¯ç”¨ 8-16\n",
    "\n",
    "# âœ… æ¸…ç©ºä¸¦é‡å»ºè¼¸å‡ºç›®éŒ„\n",
    "if os.path.exists(output_dir):\n",
    "    print(f\"âš ï¸ è¼¸å‡ºç›®éŒ„å·²å­˜åœ¨ï¼Œåˆªé™¤èˆŠè³‡æ–™...\")\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"âœ… å·²å»ºç«‹è¼¸å‡ºç›®éŒ„: {output_dir}\\n\")\n",
    "\n",
    "# ==================== è¼‰å…¥ CSV ====================\n",
    "\n",
    "df_old = pd.read_csv(csv_Old_input)\n",
    "print(f\"ğŸ“Š è®€å–èˆŠæ–¹æ³• CSV: {csv_Old_input}\")\n",
    "print(f\"   ç­†æ•¸: {len(df_old)}\\n\")\n",
    "\n",
    "df_RawBoost = pd.read_csv(csv_RawBoost_input)\n",
    "print(f\"ğŸ“Š è®€å– RawBoost CSV: {csv_RawBoost_input}\")\n",
    "print(f\"   ç­†æ•¸: {len(df_RawBoost)}\\n\")\n",
    "\n",
    "# âœ… è½‰æ› ID ç‚ºå­—ä¸²\n",
    "df_old['id'] = df_old['id'].astype(str)\n",
    "df_RawBoost['id'] = df_RawBoost['id'].astype(str)\n",
    "\n",
    "# ==================== å®šç¾©è¤‡è£½å‡½æ•¸ ====================\n",
    "\n",
    "def copy_single_file(file, src_dir, dst_dir):\n",
    "    \"\"\"è¤‡è£½å–®å€‹æª”æ¡ˆï¼ˆç”¨æ–¼å¤šåŸ·è¡Œç·’ï¼‰\"\"\"\n",
    "    try:\n",
    "        src_path = os.path.join(src_dir, file)\n",
    "        dst_path = os.path.join(dst_dir, file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        return (True, file, None)\n",
    "    except Exception as e:\n",
    "        return (False, file, str(e))\n",
    "\n",
    "def copy_rawboost_file(file, src_dir, dst_dir, df_RawBoost):\n",
    "    \"\"\"è¤‡è£½ RawBoost æª”æ¡ˆä¸¦å–å¾— CSV row\"\"\"\n",
    "    try:\n",
    "        file_id = file.replace('.wav', '')\n",
    "        \n",
    "        # è¤‡è£½æª”æ¡ˆ\n",
    "        src_path = os.path.join(src_dir, file)\n",
    "        dst_path = os.path.join(dst_dir, file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        \n",
    "        # æŸ¥æ‰¾ CSV row\n",
    "        matching_rows = df_RawBoost[df_RawBoost['id'] == file_id]\n",
    "        \n",
    "        if len(matching_rows) > 0:\n",
    "            row = matching_rows.iloc[0].copy()\n",
    "            return (True, file, row)\n",
    "        else:\n",
    "            return (True, file, None)\n",
    "    except Exception as e:\n",
    "        return (False, file, str(e))\n",
    "\n",
    "# ==================== æ­¥é©Ÿ 1: è¤‡è£½èˆŠæ–¹æ³•éŸ³è¨Šï¼ˆå¤šåŸ·è¡Œç·’ï¼‰ ====================\n",
    "\n",
    "print(\"ğŸ“ æ­¥é©Ÿ 1: è¤‡è£½èˆŠæ–¹æ³•çš„éŸ³è¨Šæª”æ¡ˆ...\")\n",
    "\n",
    "audio_old_files = [\n",
    "    f for f in os.listdir(input_Old_dir) \n",
    "    if f.endswith('.wav')\n",
    "]\n",
    "\n",
    "print(f\"   æ‰¾åˆ° {len(audio_old_files)} å€‹èˆŠæ–¹æ³•éŸ³è¨Šæª”æ¡ˆ\")\n",
    "print(f\"   ä½¿ç”¨ {NUM_WORKERS} å€‹åŸ·è¡Œç·’åŠ é€Ÿ...\\n\")\n",
    "\n",
    "copied_old = 0\n",
    "failed_old = 0\n",
    "\n",
    "# âœ… ä½¿ç”¨ ThreadPoolExecutor ä¸¦è¡Œè¤‡è£½\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    # æäº¤æ‰€æœ‰ä»»å‹™\n",
    "    futures = {\n",
    "        executor.submit(copy_single_file, file, input_Old_dir, output_dir): file\n",
    "        for file in audio_old_files\n",
    "    }\n",
    "    \n",
    "    # ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦\n",
    "    with tqdm(total=len(audio_old_files), desc=\"è¤‡è£½èˆŠæ–¹æ³•éŸ³è¨Š\") as pbar:\n",
    "        for future in as_completed(futures):\n",
    "            success, file, error = future.result()\n",
    "            if success:\n",
    "                copied_old += 1\n",
    "            else:\n",
    "                failed_old += 1\n",
    "                print(f\"\\nâŒ è¤‡è£½å¤±æ•— {file}: {error}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "print(f\"âœ… å·²è¤‡è£½ {copied_old} å€‹èˆŠæ–¹æ³•éŸ³è¨Šæª”æ¡ˆ\")\n",
    "if failed_old > 0:\n",
    "    print(f\"âš ï¸ å¤±æ•— {failed_old} å€‹\\n\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "# ==================== æ­¥é©Ÿ 2: è¤‡è£½ RawBoost å¢å¼·æª”æ¡ˆï¼ˆå¤šåŸ·è¡Œç·’ï¼‰ ====================\n",
    "\n",
    "print(\"ğŸ“ æ­¥é©Ÿ 2: è¤‡è£½ RawBoost å¢å¼·æª”æ¡ˆ...\")\n",
    "\n",
    "# âœ… åªå–å¾—å¢å¼·éçš„æª”æ¡ˆï¼ˆæª”ååŒ…å« _algoï¼‰\n",
    "audio_RawBoost_files = [\n",
    "    f for f in os.listdir(input_RawBoost_dir) \n",
    "    if f.endswith('.wav') and ('_algo3' in f or '_algo6' in f)\n",
    "]\n",
    "\n",
    "print(f\"   æ‰¾åˆ° {len(audio_RawBoost_files)} å€‹ RawBoost å¢å¼·æª”æ¡ˆ\")\n",
    "print(f\"   ä½¿ç”¨ {NUM_WORKERS} å€‹åŸ·è¡Œç·’åŠ é€Ÿ...\\n\")\n",
    "\n",
    "copied_rawboost = 0\n",
    "failed_rawboost = 0\n",
    "rawboost_rows = []\n",
    "\n",
    "# âœ… ä½¿ç”¨ Lock ä¿è­· listï¼ˆå¤šåŸ·è¡Œç·’å®‰å…¨ï¼‰\n",
    "rows_lock = Lock()\n",
    "\n",
    "# âœ… ä½¿ç”¨ ThreadPoolExecutor ä¸¦è¡Œè¤‡è£½\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    # æäº¤æ‰€æœ‰ä»»å‹™\n",
    "    futures = {\n",
    "        executor.submit(copy_rawboost_file, file, input_RawBoost_dir, output_dir, df_RawBoost): file\n",
    "        for file in audio_RawBoost_files\n",
    "    }\n",
    "    \n",
    "    # ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦\n",
    "    with tqdm(total=len(audio_RawBoost_files), desc=\"è¤‡è£½ RawBoost éŸ³è¨Š\") as pbar:\n",
    "        for future in as_completed(futures):\n",
    "            success, file, result = future.result()\n",
    "            if success:\n",
    "                copied_rawboost += 1\n",
    "                if result is not None:\n",
    "                    # âœ… ä½¿ç”¨ Lock ä¿è­· list append\n",
    "                    with rows_lock:\n",
    "                        rawboost_rows.append(result)\n",
    "                else:\n",
    "                    print(f\"\\nâš ï¸ CSV ä¸­æ‰¾ä¸åˆ° {file.replace('.wav', '')}\")\n",
    "            else:\n",
    "                failed_rawboost += 1\n",
    "                print(f\"\\nâŒ è¤‡è£½å¤±æ•— {file}: {result}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "print(f\"âœ… å·²è¤‡è£½ {copied_rawboost} å€‹ RawBoost å¢å¼·æª”æ¡ˆ\")\n",
    "if failed_rawboost > 0:\n",
    "    print(f\"âš ï¸ å¤±æ•— {failed_rawboost} å€‹\\n\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "# ==================== æ­¥é©Ÿ 3: åˆä½µ CSV ====================\n",
    "\n",
    "print(\"ğŸ“Š æ­¥é©Ÿ 3: åˆä½µ CSV...\")\n",
    "\n",
    "# âœ… åˆä½µæ‰€æœ‰ DataFrame\n",
    "if len(rawboost_rows) > 0:\n",
    "    df_rawboost_new = pd.DataFrame(rawboost_rows)\n",
    "    df_augmented = pd.concat([df_old, df_rawboost_new], ignore_index=True)\n",
    "else:\n",
    "    print(\"âš ï¸ æ²’æœ‰ RawBoost è³‡æ–™ï¼Œåªä½¿ç”¨èˆŠæ–¹æ³•\")\n",
    "    df_augmented = df_old.copy()\n",
    "\n",
    "# å„²å­˜åˆä½µå¾Œçš„ CSV\n",
    "df_augmented.to_csv(csv_output, index=False)\n",
    "\n",
    "# ==================== çµ±è¨ˆçµæœ ====================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ… åˆä½µå®Œæˆï¼\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ğŸ“Š CSV çµ±è¨ˆ:\")\n",
    "print(f\"   èˆŠæ–¹æ³•è³‡æ–™: {len(df_old)} ç­†\")\n",
    "print(f\"   RawBoost å¢å¼·: {len(rawboost_rows)} ç­†\")\n",
    "print(f\"   åˆä½µå¾Œç¸½è¨ˆ: {len(df_augmented)} ç­†\")\n",
    "print(f\"\\nğŸ“ éŸ³è¨Šæª”æ¡ˆçµ±è¨ˆ:\")\n",
    "print(f\"   èˆŠæ–¹æ³•éŸ³è¨Š: {copied_old} å€‹\")\n",
    "print(f\"   RawBoost éŸ³è¨Š: {copied_rawboost} å€‹\")\n",
    "print(f\"   ç¸½è¨ˆ: {len(os.listdir(output_dir))} å€‹\")\n",
    "print(f\"\\nğŸ’¾ è¼¸å‡ºä½ç½®:\")\n",
    "print(f\"   éŸ³è¨Šç›®éŒ„: {output_dir}\")\n",
    "print(f\"   CSV æª”æ¡ˆ: {csv_output}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ==================== é©—è­‰çµæœ ====================\n",
    "\n",
    "print(f\"\\nğŸ” é©—è­‰ CSV å’ŒéŸ³è¨Šæª”æ¡ˆæ˜¯å¦åŒ¹é…...\")\n",
    "\n",
    "# å–å¾—æ‰€æœ‰éŸ³è¨Šæª”æ¡ˆçš„ ID\n",
    "audio_ids = set([f.replace('.wav', '') for f in os.listdir(output_dir) if f.endswith('.wav')])\n",
    "\n",
    "# å–å¾— CSV ä¸­çš„ ID\n",
    "csv_ids = set(df_augmented['id'].astype(str))\n",
    "\n",
    "# æ‰¾å‡ºä¸åŒ¹é…çš„\n",
    "audio_not_in_csv = audio_ids - csv_ids\n",
    "csv_not_in_audio = csv_ids - audio_ids\n",
    "\n",
    "if len(audio_not_in_csv) > 0:\n",
    "    print(f\"âš ï¸ æœ‰éŸ³è¨Šä½† CSV ä¸­æ²’æœ‰: {len(audio_not_in_csv)} å€‹\")\n",
    "    print(f\"   å‰ 10 å€‹: {list(audio_not_in_csv)[:10]}\")\n",
    "\n",
    "if len(csv_not_in_audio) > 0:\n",
    "    print(f\"âš ï¸ CSV ä¸­æœ‰ä½†æ²’éŸ³è¨Š: {len(csv_not_in_audio)} å€‹\")\n",
    "    print(f\"   å‰ 10 å€‹: {list(csv_not_in_audio)[:10]}\")\n",
    "\n",
    "if len(audio_not_in_csv) == 0 and len(csv_not_in_audio) == 0:\n",
    "    print(f\"âœ… å®Œç¾åŒ¹é…ï¼CSV å’ŒéŸ³è¨Šæª”æ¡ˆå®Œå…¨ä¸€è‡´\")\n",
    "\n",
    "print(f\"\\nâš¡ ä½¿ç”¨äº† {NUM_WORKERS} å€‹åŸ·è¡Œç·’ï¼Œå¤§å¹…åŠ é€Ÿè¤‡è£½éç¨‹ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š æ›´æ–°è¨“ç·´é…ç½® - é‡å°æ¯”è³½å„ªåŒ–\n",
    "\n",
    "æ ¹æ“šæ¯”è³½è©•åˆ†æ¨™æº– (Mean Levenshtein Distance) å’Œè¨“ç·´ç©©å®šæ€§é€²è¡Œå„ªåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£æ‰€éœ€å¥—ä»¶\n",
    "%pip install pandas numpy seaborn transformers datasets\n",
    "%pip install scikit-learn librosa soundfile jiwer\n",
    "%pip install accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ è¼‰å…¥è³‡æ–™\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dir = \"./train/preprocessed\"\n",
    "train_csv = \"./train/trainAgg-toneless.csv\"\n",
    "\n",
    "# è®€å– CSV ä¸¦åˆ†å‰²è¨“ç·´/é©—è­‰è³‡æ–™\n",
    "df = pd.read_csv(train_csv)\n",
    "print(f\"ğŸ“Š ç¸½è³‡æ–™ç­†æ•¸: {len(df)}\")\n",
    "\n",
    "# åˆ†å‰²è¨“ç·´å’Œé©—è­‰è³‡æ–™ (90% è¨“ç·´, 10% é©—è­‰)\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "print(f\"âœ… è¨“ç·´é›†: {len(train_df)} ç­†\")\n",
    "print(f\"âœ… é©—è­‰é›†: {len(val_df)} ç­†\")\n",
    "\n",
    "# å„²å­˜åˆ†å‰²å¾Œçš„ CSV (å¯é¸)\n",
    "train_df.to_csv(\"./train/train_split.csv\", index=False)\n",
    "val_df.to_csv(\"./train/val_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ï¸âƒ£ å»ºç«‹ PyTorch Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "class TaiwaneseAudioDataset(Dataset):\n",
    "    \"\"\"å°èªéŸ³è¨Šè³‡æ–™é›†\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, audio_dir, processor, max_length=40):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: åŒ…å« 'id' å’Œ 'text' æ¬„ä½çš„ DataFrame\n",
    "            audio_dir: éŸ³è¨Šæª”æ¡ˆæ‰€åœ¨ç›®éŒ„\n",
    "            processor: Whisper processor\n",
    "            max_length: æœ€å¤§éŸ³è¨Šé•·åº¦ï¼ˆç§’ï¼‰\n",
    "        \"\"\"\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # å–å¾—è³‡æ–™\n",
    "        row = self.df.iloc[idx]\n",
    "        audio_id = str(row['id'])\n",
    "        text = row['text']\n",
    "        \n",
    "        # éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ (è™•ç† augmented æª”æ¡ˆ)\n",
    "        if 'augmented' in audio_id:\n",
    "            audio_path = os.path.join(self.audio_dir, f\"{audio_id}.wav\")\n",
    "        else:\n",
    "            audio_path = os.path.join(self.audio_dir, f\"{audio_id}.wav\")\n",
    "        \n",
    "        # è¼‰å…¥éŸ³è¨Š (16kHz)\n",
    "        try:\n",
    "            audio, sr = librosa.load(audio_path, sr=16000)\n",
    "            \n",
    "            # é™åˆ¶é•·åº¦\n",
    "            max_samples = int(self.max_length * sr)\n",
    "            if len(audio) > max_samples:\n",
    "                audio = audio[:max_samples]\n",
    "            \n",
    "            # ä½¿ç”¨ processor è™•ç†éŸ³è¨Š\n",
    "            inputs = self.processor(\n",
    "                audio, \n",
    "                sampling_rate=16000,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\"\n",
    "            )\n",
    "            \n",
    "            # è™•ç†æ–‡å­—æ¨™ç±¤\n",
    "            labels = self.processor.tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\"\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"input_features\": inputs.input_features.squeeze(0),\n",
    "                \"labels\": labels.input_ids.squeeze(0)\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è¼‰å…¥å¤±æ•— {audio_path}: {e}\")\n",
    "            # å›å‚³ç©ºè³‡æ–™\n",
    "            return {\n",
    "                \"input_features\": torch.zeros(80, 3000),  # Whisper é è¨­ç‰¹å¾µç¶­åº¦\n",
    "                \"labels\": torch.zeros(1, dtype=torch.long)\n",
    "            }\n",
    "\n",
    "print(\"âœ… Dataset é¡åˆ¥å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ï¸âƒ£ è¼‰å…¥æ¨¡å‹å’Œ Processor\n",
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "import torch\n",
    "\n",
    "# æª¢æŸ¥ GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}\")\n",
    "\n",
    "# è¼‰å…¥ processor å’Œæ¨¡å‹\n",
    "model_name = \"NUTN-KWS/Whisper-Taiwanese-model-v0.5\"\n",
    "\n",
    "print(f\"ğŸ“¥ è¼‰å…¥ Processor å’Œæ¨¡å‹: {model_name}\")\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name)\n",
    "\n",
    "# ç§»è‡³ GPU\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹å·²è¼‰å…¥\")\n",
    "print(f\"   åƒæ•¸é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
    "print(f\"   å¯è¨“ç·´åƒæ•¸: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ å»ºç«‹ DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import torch\n",
    "\n",
    "# å»ºç«‹è¨“ç·´å’Œé©—è­‰è³‡æ–™é›†\n",
    "train_dataset = TaiwaneseAudioDataset(train_df, train_dir, processor, max_length=30)\n",
    "val_dataset = TaiwaneseAudioDataset(val_df, train_dir, processor, max_length=30)\n",
    "\n",
    "print(f\"âœ… è¨“ç·´é›†å¤§å°: {len(train_dataset)}\")\n",
    "print(f\"âœ… é©—è­‰é›†å¤§å°: {len(val_dataset)}\")\n",
    "\n",
    "# è‡ªå®šç¾© Data Collator\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    \"\"\"\n",
    "    è‡ªå®šç¾© Data Collator,ç”¨æ–¼è™•ç†èªéŸ³è½‰æ–‡å­—ä»»å‹™çš„æ‰¹æ¬¡è³‡æ–™\n",
    "    \"\"\"\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "    \n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # åˆ†é›¢éŸ³è¨Šç‰¹å¾µå’Œæ¨™ç±¤\n",
    "        input_features = [feature[\"input_features\"] for feature in features]\n",
    "        label_features = [feature[\"labels\"] for feature in features]\n",
    "        \n",
    "        # âœ… Whisper è¦æ±‚å›ºå®šé•·åº¦\n",
    "        batch_size = len(input_features)\n",
    "        feature_dim = 128      # Whisper å›ºå®šä½¿ç”¨ 128 å€‹ Mel bins\n",
    "        max_length = 3000     # Whisper å›ºå®šæ™‚é–“æ­¥é•·\n",
    "        \n",
    "        # å»ºç«‹å›ºå®šå¤§å°çš„ tensor (åˆå§‹åŒ–ç‚º 0)\n",
    "        input_features_padded = torch.zeros(batch_size, feature_dim, max_length)\n",
    "        \n",
    "        # è™•ç†æ¯å€‹éŸ³è¨Šç‰¹å¾µ\n",
    "        for i, features_tensor in enumerate(input_features):\n",
    "            # å–å¾—å¯¦éš›ç¶­åº¦\n",
    "            actual_feature_dim = features_tensor.shape[0]  # å¯èƒ½æ˜¯ 80 æˆ– 128\n",
    "            actual_time_steps = features_tensor.shape[1]   # å¯¦éš›æ™‚é–“æ­¥é•·\n",
    "            \n",
    "            # æ±ºå®šè¦è¤‡è£½çš„ç¶­åº¦\n",
    "            copy_feature_dim = min(actual_feature_dim, feature_dim)  # æœ€å¤šå– 80\n",
    "            copy_time_steps = min(actual_time_steps, max_length)     # æœ€å¤šå– 3000\n",
    "            \n",
    "            # ä¸€æ¬¡æ€§è¤‡è£½åˆ°æ­£ç¢ºä½ç½®\n",
    "            input_features_padded[i, :copy_feature_dim, :copy_time_steps] = \\\n",
    "                features_tensor[:copy_feature_dim, :copy_time_steps]\n",
    "        \n",
    "        # è™•ç†æ¨™ç±¤ (padding)\n",
    "        max_label_length = max(len(label) for label in label_features)\n",
    "        \n",
    "        # æ‰‹å‹• padding æ¨™ç±¤\n",
    "        labels_padded = []\n",
    "        for label in label_features:\n",
    "            padding_length = max_label_length - len(label)\n",
    "            padded_label = torch.cat([\n",
    "                label,\n",
    "                torch.full((padding_length,), -100, dtype=label.dtype)\n",
    "            ])\n",
    "            labels_padded.append(padded_label)\n",
    "        \n",
    "        labels = torch.stack(labels_padded)\n",
    "        \n",
    "        # å¦‚æœæ‰€æœ‰æ¨™ç±¤éƒ½æ˜¯ paddingï¼Œå‰‡ç§»é™¤ decoder_start_token\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all():\n",
    "            labels = labels[:, 1:]\n",
    "        \n",
    "        batch = {\n",
    "            \"input_features\": input_features_padded,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "        return batch\n",
    "\n",
    "# å»ºç«‹ Data Collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id\n",
    ")\n",
    "\n",
    "print(\"âœ… Data Collator å»ºç«‹å®Œæˆ\")\n",
    "\n",
    "# å»ºç«‹ DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… DataLoader å»ºç«‹å®Œæˆ\")\n",
    "print(f\"   è¨“ç·´æ‰¹æ¬¡æ•¸: {len(train_loader)}\")\n",
    "print(f\"   é©—è­‰æ‰¹æ¬¡æ•¸: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ï¸âƒ£ è¨­å®šè¨“ç·´åƒæ•¸ (é‡å°æ¯”è³½å„ªåŒ–)\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    # è¼¸å‡ºè¨­å®š\n",
    "    output_dir=\"./whisper-taiwanese-finetuned-RawBoost\",\n",
    "    \n",
    "    # è¨“ç·´è¨­å®š\n",
    "    per_device_train_batch_size=8,      # âœ… æ¸›å°æ‰¹æ¬¡å¤§å° (æ›´ç©©å®š)\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,      # âœ… å¢åŠ æ¢¯åº¦ç´¯ç© (æœ‰æ•ˆ batch=16)\n",
    "    \n",
    "    # âœ… æ¢¯åº¦è£å‰ª (é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œæœ€é‡è¦ï¼)\n",
    "    max_grad_norm=1.0,\n",
    "    \n",
    "    # å­¸ç¿’ç‡è¨­å®š\n",
    "    learning_rate=1e-5,                 # âœ… æé«˜å­¸ç¿’ç‡ (è³‡æ–™å¤šäº†ï¼Œå¯ä»¥å­¸æ›´å¿«)\n",
    "    warmup_steps=1000,                  # âœ… å¢åŠ  warmup (æ­¥æ•¸æ›´å¤šéœ€è¦æ›´é•· warmup)\n",
    "    lr_scheduler_type=\"cosine\",         # âœ… ä½¿ç”¨é¤˜å¼¦å­¸ç¿’ç‡è¡°æ¸›\n",
    "    weight_decay=0.01,                  # âœ… L2 æ­£å‰‡åŒ–\n",
    "    \n",
    "    # è¨“ç·´è¼ªæ•¸\n",
    "    num_train_epochs=5,\n",
    "    \n",
    "    # è©•ä¼°èˆ‡å„²å­˜\n",
    "    eval_strategy=\"steps\",              # æ¯ N æ­¥è©•ä¼°ä¸€æ¬¡\n",
    "    eval_steps=300,                     # âœ… æ›´é »ç¹è©•ä¼° (æ¯ 300 æ­¥ï¼Œç´„æ¯åŠå€‹ epoch)\n",
    "    save_strategy=\"steps\",              # æ¯ N æ­¥å„²å­˜\n",
    "    save_steps=300,                     # âœ… æ›´é »ç¹å„²å­˜ (æ¯ 300 æ­¥)\n",
    "    save_total_limit=5,                 # âœ… ä¿ç•™æœ€æ–° 5 å€‹ checkpoint (è¨“ç·´æ›´é•·)\n",
    "    \n",
    "    # è¨˜éŒ„è¨­å®š\n",
    "    logging_steps=50,                   # âœ… æ›´é »ç¹è¨˜éŒ„\n",
    "    logging_dir=\"./logs\",\n",
    "    \n",
    "    # æœ€ä½³æ¨¡å‹\n",
    "    load_best_model_at_end=True,       # è¨“ç·´çµæŸè¼‰å…¥æœ€ä½³æ¨¡å‹\n",
    "    metric_for_best_model=\"wer\",       # ä½¿ç”¨ WER ä½œç‚ºè©•ä¼°æŒ‡æ¨™\n",
    "    greater_is_better=False,           # WER è¶Šå°è¶Šå¥½\n",
    "    \n",
    "    # ç¡¬é«”è¨­å®š\n",
    "    fp16=True,                         # ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ (åŠ é€Ÿ+çœè¨˜æ†¶é«”)\n",
    "    dataloader_num_workers=4,          # âœ… è³‡æ–™è¼‰å…¥åŸ·è¡Œç·’æ•¸\n",
    "    \n",
    "    # å…¶ä»–\n",
    "    predict_with_generate=True,        # è©•ä¼°æ™‚ä½¿ç”¨ç”Ÿæˆæ¨¡å¼\n",
    "    generation_max_length=225,         # ç”Ÿæˆæœ€å¤§é•·åº¦\n",
    "    push_to_hub=False,                 # ä¸ä¸Šå‚³åˆ° HuggingFace Hub\n",
    ")\n",
    "\n",
    "print(\"âœ… è¨“ç·´åƒæ•¸è¨­å®šå®Œæˆ (é‡å°æ¯”è³½å„ªåŒ–)\")\n",
    "print(f\"   æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"   ç¸½è¨“ç·´æ­¥æ•¸: {len(train_loader) * training_args.num_train_epochs // training_args.gradient_accumulation_steps}\")\n",
    "print(\"\\nğŸ”§ å„ªåŒ–é …ç›®:\")\n",
    "print(\"   âœ… æ¢¯åº¦è£å‰ª (max_grad_norm=1.0)\")\n",
    "print(\"   âœ… é™ä½å­¸ç¿’ç‡ (5e-6)\")\n",
    "print(\"   âœ… å¢åŠ  warmup (500 steps)\")\n",
    "print(\"   âœ… é¤˜å¼¦å­¸ç¿’ç‡è¡°æ¸›\")\n",
    "print(\"   âœ… L2 æ­£å‰‡åŒ– (weight_decay=0.01)\")\n",
    "print(\"   âœ… ä½¿ç”¨ Levenshtein Distance è©•ä¼°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6ï¸âƒ£ å®šç¾©è©•ä¼°æŒ‡æ¨™ (WER - Word Error Rate)\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# è¼‰å…¥ WER è©•ä¼°å™¨\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"è¨ˆç®— WER (Word Error Rate)\"\"\"\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    \n",
    "    # å°‡ -100 æ›¿æ›ç‚º pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    \n",
    "    # è§£ç¢¼é æ¸¬å’Œæ¨™ç±¤\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # è¨ˆç®— WER\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    return {\"wer\": wer}\n",
    "\n",
    "print(\"âœ… è©•ä¼°æŒ‡æ¨™å®šç¾©å®Œæˆ (WER)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7ï¸âƒ£ å»ºç«‹ Trainer ä¸¦é–‹å§‹è¨“ç·´\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "# å»ºç«‹ Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "print(\"âœ… Trainer å»ºç«‹å®Œæˆ\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ é–‹å§‹è¨“ç·´...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# é–‹å§‹è¨“ç·´\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… è¨“ç·´å®Œæˆï¼\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8ï¸âƒ£ è©•ä¼°æ¨¡å‹\n",
    "print(\"ğŸ“Š åœ¨é©—è­‰é›†ä¸Šè©•ä¼°æ¨¡å‹...\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“ˆ é©—è­‰é›†çµæœ:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"   {key}: {value:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9ï¸âƒ£ å„²å­˜å¾®èª¿å¾Œçš„æ¨¡å‹\n",
    "output_model_dir = \"./whisper-taiwanese-final\"\n",
    "\n",
    "print(f\"ğŸ’¾ å„²å­˜æ¨¡å‹åˆ°: {output_model_dir}\")\n",
    "trainer.save_model(output_model_dir)\n",
    "processor.save_pretrained(output_model_dir)\n",
    "\n",
    "print(\"âœ… æ¨¡å‹å„²å­˜å®Œæˆï¼\")\n",
    "print(f\"ğŸ“ æ¨¡å‹ä½ç½®: {output_model_dir}\")\n",
    "print(\"\\nå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤è¼‰å…¥æ¨¡å‹:\")\n",
    "print(f'   processor = AutoProcessor.from_pretrained(\"{output_model_dir}\")')\n",
    "print(f'   model = AutoModelForSpeechSeq2Seq.from_pretrained(\"{output_model_dir}\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§ª æ¸¬è©¦å¾®èª¿å¾Œçš„æ¨¡å‹\n",
    "\n",
    "è¼‰å…¥å¾®èª¿å¾Œçš„æ¨¡å‹ä¸¦é€²è¡Œæ¨ç†æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¤ ç”Ÿæˆæ¸¬è©¦é›†é æ¸¬çµæœ\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "\n",
    "# âœ… æ˜ç¢ºæŒ‡å®šè¦è¼‰å…¥çš„æ¨¡å‹è·¯å¾‘\n",
    "MODEL_PATH = \"./whisper-taiwanese-final\"  # æˆ–ä½ å„²å­˜çš„è·¯å¾‘\n",
    "\n",
    "print(f\"ğŸ“¥ è¼‰å…¥å¾®èª¿å¾Œçš„æ¨¡å‹: {MODEL_PATH}\")\n",
    "\n",
    "# è¼‰å…¥ processor å’Œ model\n",
    "processor = AutoProcessor.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# ç§»è‡³ GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()  # è¨­ç‚ºè©•ä¼°æ¨¡å¼\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹å·²è¼‰å…¥\")\n",
    "print(f\"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}\")\n",
    "\n",
    "# ğŸ”§ å®šç¾©è½‰éŒ„å‡½æ•¸\n",
    "def transcribe_audio(audio_path, model, processor, device=\"cuda\"):\n",
    "    \"\"\"å°å–®å€‹éŸ³è¨Šæª”æ¡ˆé€²è¡Œè½‰éŒ„\"\"\"\n",
    "    # è¼‰å…¥éŸ³è¨Š\n",
    "    audio, sr = librosa.load(audio_path, sr=16000)\n",
    "    \n",
    "    # è™•ç†éŸ³è¨Š\n",
    "    inputs = processor(\n",
    "        audio,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # ç§»è‡³ GPU\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # ç”Ÿæˆé æ¸¬\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            inputs[\"input_features\"],\n",
    "            max_length=225\n",
    "        )\n",
    "    \n",
    "    # è§£ç¢¼\n",
    "    transcription = processor.batch_decode(\n",
    "        generated_ids,\n",
    "        skip_special_tokens=True\n",
    "    )[0]\n",
    "    \n",
    "    return transcription\n",
    "\n",
    "# ğŸ“‚ è¨­å®šæ¸¬è©¦é›†è·¯å¾‘\n",
    "test_dir = \"./test-random/preprocessed\"\n",
    "test_files = sorted([f for f in os.listdir(test_dir) if f.endswith('.wav')])\n",
    "\n",
    "print(f\"ğŸ“Š æ¸¬è©¦é›†æª”æ¡ˆæ•¸: {len(test_files)}\")\n",
    "\n",
    "# é€²è¡Œé æ¸¬\n",
    "predictions = []\n",
    "\n",
    "for test_file in tqdm(test_files, desc=\"é æ¸¬æ¸¬è©¦é›†\"):\n",
    "    audio_path = os.path.join(test_dir, test_file)\n",
    "    \n",
    "    try:\n",
    "        transcription = transcribe_audio(audio_path, model, processor, device)\n",
    "        predictions.append({\n",
    "            \"id\": test_file.replace(\".wav\", \"\"),\n",
    "            \"text\": transcription\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é æ¸¬å¤±æ•— {test_file}: {e}\")\n",
    "        predictions.append({\n",
    "            \"id\": test_file.replace(\".wav\", \"\"),\n",
    "            \"text\": \"\"\n",
    "        })\n",
    "\n",
    "# å„²å­˜é æ¸¬çµæœ\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(f\"\\nâœ… é æ¸¬å®Œæˆï¼\")\n",
    "print(f\"ğŸ“ çµæœå·²å„²å­˜åˆ°: submission.csv\")\n",
    "print(f\"\\nå‰ 5 ç­†é æ¸¬çµæœ:\")\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š è¨“ç·´ç›£æ§èˆ‡è¦–è¦ºåŒ–\n",
    "\n",
    "æŸ¥çœ‹è¨“ç·´éç¨‹çš„ loss å’Œ WER è®ŠåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ è¦–è¦ºåŒ–è¨“ç·´éç¨‹\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "# è®€å–è¨“ç·´æ—¥èªŒ\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "# æå–è¨“ç·´ loss å’Œé©—è­‰ WER\n",
    "train_loss = [log['loss'] for log in log_history if 'loss' in log]\n",
    "eval_wer = [log['eval_wer'] for log in log_history if 'eval_wer' in log]\n",
    "steps_loss = [log['step'] for log in log_history if 'loss' in log]\n",
    "steps_eval = [log['step'] for log in log_history if 'eval_wer' in log]\n",
    "\n",
    "# ç¹ªåœ–\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# è¨“ç·´ Loss\n",
    "ax1.plot(steps_loss, train_loss, label='Training Loss', color='blue', linewidth=2)\n",
    "ax1.set_xlabel('Steps', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# é©—è­‰ WER\n",
    "ax2.plot(steps_eval, eval_wer, label='Validation WER', color='red', linewidth=2, marker='o')\n",
    "ax2.set_xlabel('Steps', fontsize=12)\n",
    "ax2.set_ylabel('WER', fontsize=12)\n",
    "ax2.set_title('Validation WER (Word Error Rate)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… è¨“ç·´æ›²ç·šå·²å„²å­˜: training_curves.png\")\n",
    "print(f\"\\nğŸ“Š æœ€çµ‚çµæœ:\")\n",
    "print(f\"   æœ€ä½è¨“ç·´ Loss: {min(train_loss):.4f}\")\n",
    "print(f\"   æœ€ä½é©—è­‰ WER: {min(eval_wer):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMOogwsWWjNbblZUJrfo6hs",
   "mount_file_id": "1YacgIExqVQd5U_vLLUkH3vab2j6VhxP8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
