# ğŸ™ï¸ Ass3 - å°èªèªéŸ³è¾¨è­˜ (Taiwanese ASR)

ä½¿ç”¨ Whisper æ¨¡å‹é€²è¡Œå°èªè‡ªå‹•èªéŸ³è¾¨è­˜ï¼ˆAutomatic Speech Recognitionï¼‰çš„è¨“ç·´èˆ‡æ¸¬è©¦ã€‚

---

## ğŸ“‹ ç›®éŒ„

- [è³‡æ–™æº–å‚™](#è³‡æ–™æº–å‚™)
- [è¨“ç·´æµç¨‹](#è¨“ç·´æµç¨‹)
- [ç›¸é—œæ–‡ä»¶](#ç›¸é—œæ–‡ä»¶)
- [æ¨¡å‹ç‰ˆæœ¬è¨˜éŒ„](#æ¨¡å‹ç‰ˆæœ¬è¨˜éŒ„)

---

## ğŸ› ï¸ ç’°å¢ƒéœ€æ±‚

```bash
# ä¸»è¦å¥—ä»¶
- Python 3.8+
- PyTorch
- Transformers
- librosa
- pandas
```

---

## ğŸ“Š è³‡æ–™æº–å‚™

### æ­¥é©Ÿ 1ï¼šä¸‹è¼‰è³‡æ–™å¢å¼·ç´ æ

åŸ·è¡Œ `downloadData.py` å¾ä»¥ä¸‹ä¸‰å€‹è³‡æ–™é›†ä¸‹è¼‰è³‡æ–™å¢å¼·ç”¨çš„ç´ æï¼š

| è³‡æ–™é›† | èªªæ˜ | æª”æ¡ˆæ•¸é‡ |
|--------|------|----------|
| **MS-SNSD** | å¾®è»ŸèƒŒæ™¯å™ªéŸ³è³‡æ–™é›† | ~900 å€‹æª”æ¡ˆ |
| **ESC-50** | ç’°å¢ƒè²éŸ³åˆ†é¡è³‡æ–™é›† | 100 å€‹çŸ­æš«å™ªéŸ³ |
| **OpenSLR RIR** | æˆ¿é–“è„ˆè¡éŸ¿æ‡‰è³‡æ–™é›† | 50 å€‹ RIR æª”æ¡ˆ |

```bash
python downloadData.py
```

### æ­¥é©Ÿ 2ï¼šæº–å‚™ Kaggle è³‡æ–™

å°‡ Kaggle ç«¶è³½è³‡æ–™è§£å£“ç¸®åˆ°å°ˆæ¡ˆç›®éŒ„ï¼Œå½¢æˆä»¥ä¸‹çµæ§‹ï¼š

```
Ass3-RNN/
â”œâ”€â”€ train/
â”‚   â””â”€â”€ train/
â”‚       â””â”€â”€ train/*.wav          # è¨“ç·´éŸ³è¨Šæª”æ¡ˆ
â””â”€â”€ test-random/
    â””â”€â”€ test-random/*.wav        # æ¸¬è©¦éŸ³è¨Šæª”æ¡ˆ
```

### æ­¥é©Ÿ 3ï¼šéŸ³è¨Šé è™•ç†

åŸ·è¡Œ `datapreprocess.py` é€²è¡ŒéŸ³è¨Šæ¨™æº–åŒ–ï¼š

```bash
python datapreprocess.py
```

**é è™•ç†å…§å®¹**ï¼š
- âœ… æ¡æ¨£ç‡çµ±ä¸€åˆ° 22050 Hz
- âœ… æ ¼å¼è½‰æ›ç‚º 16-bit PCM
- âœ… ç”Ÿæˆè³‡æ–™å¤¾çµæ§‹èˆ‡çµ±è¨ˆè³‡è¨Š

---

## ğŸš€ è¨“ç·´æµç¨‹

### æ­¥é©Ÿ 1ï¼šè³‡æ–™å¢å¼·ï¼ˆæˆ–æ˜¯ç›´æ¥åœ¨.ipynbåŸ·è¡Œè³‡æ–™å¢å¼·ä¹Ÿå¯ä»¥ï¼‰

ä½¿ç”¨ **RawBoost** æŠ€è¡“é€²è¡Œè³‡æ–™å¢å¼·ï¼Œå¯å¤§å¹…æå‡æ¨¡å‹æ•ˆèƒ½ï¼š

```bash
python data_augmentation_rawboost.py
```

ğŸ“– **è©³ç´°èªªæ˜**ï¼šè«‹åƒè€ƒ [RawBoost ä½¿ç”¨æŒ‡å—](./RAWBOOST_USAGE_GUIDE.md)

**æ•ˆæœ**ï¼š
- ğŸ¯ å°‡è¨“ç·´è³‡æ–™é‡æ“´å¢è‡³ **3-4 å€**
- ğŸ“ˆ é¡¯è‘—é™ä½ Mean Levenshtein Distance (MDL)
- ğŸ›¡ï¸ å¢å¼·æ¨¡å‹å°å™ªéŸ³çš„é­¯æ£’æ€§

### æ­¥é©Ÿ 2ï¼šé–‹å§‹è¨“ç·´

é‹è¡Œä¸»è¦è¨“ç·´ç­†è¨˜æœ¬ï¼š

```bash
jupyter notebook NYCU_IAlI_ML2025_RNN.ipynb
```

LoRA å¾®èª¿ç‰ˆæœ¬æ²’æœ‰å¯«å‡ºä¾†ä¸èƒ½ç”¨...


**è¨“ç·´é¸é …**ï¼š
- ğŸ“ å¯æŒ‡å®šä¸åŒç‰ˆæœ¬çš„ Whisper æ¨¡å‹ï¼ˆtiny/base/small/medium/largeï¼‰
- âš™ï¸ å¯èª¿æ•´è¨“ç·´è¶…åƒæ•¸
- ğŸ’¾ è‡ªå‹•å„²å­˜æœ€ä½³æ¨¡å‹

---

## ğŸ“š ç›¸é—œæ–‡ä»¶

| æ–‡ä»¶ | èªªæ˜ |
|------|------|
| [RawBoost ä½¿ç”¨æŒ‡å—](./RAWBOOST_USAGE_GUIDE.md) | è³‡æ–™å¢å¼·è©³ç´°èªªæ˜èˆ‡åƒæ•¸èª¿æ•´ |
| [NYCU_IAlI_ML2025_RNN.ipynb](./NYCU_IAlI_ML2025_RNN.ipynb) | åŸºç¤ Whisper è¨“ç·´æµç¨‹ |

---

## ğŸ“ˆ æ¨¡å‹ç‰ˆæœ¬è¨˜éŒ„

# Whisper-Taiwanese model V0.5 (Tv0.5)
- ç¬¬ä¸€ç‰ˆ:
    ```
    training_args = Seq2SeqTrainingArguments(
        # è¼¸å‡ºè¨­å®š
        output_dir="./whisper-taiwanese-finetuned",
        
        # è¨“ç·´è¨­å®š
        per_device_train_batch_size=8,      # âœ… æ¸›å°æ‰¹æ¬¡å¤§å° (æ›´ç©©å®š)
        per_device_eval_batch_size=8,
        gradient_accumulation_steps=2,      # âœ… å¢åŠ æ¢¯åº¦ç´¯ç© (æœ‰æ•ˆ batch=16)

        
        # å­¸ç¿’ç‡è¨­å®š
        learning_rate=1e-5,                 # âœ… é™ä½å­¸ç¿’ç‡ (æ›´ç©©å®š)
        warmup_steps=300,                   # âœ… å¢åŠ  warmup (æ›´å¹³æ»‘)
        
        # è¨“ç·´è¼ªæ•¸
        num_train_epochs=5,
        
        # è©•ä¼°èˆ‡å„²å­˜
        eval_strategy="steps",              # æ¯ N æ­¥è©•ä¼°ä¸€æ¬¡
        eval_steps=500,                     # æ¯ 500 æ­¥è©•ä¼°
        save_strategy="steps",              # æ¯ N æ­¥å„²å­˜
        save_steps=500,                     # æ¯ 500 æ­¥å„²å­˜
        save_total_limit=3,                 # åªä¿ç•™æœ€æ–° 3 å€‹ checkpoint
        
        # è¨˜éŒ„è¨­å®š
        logging_steps=50,                   # âœ… æ›´é »ç¹è¨˜éŒ„
        logging_dir="./logs",
        
        # æœ€ä½³æ¨¡å‹
        load_best_model_at_end=True,       # è¨“ç·´çµæŸè¼‰å…¥æœ€ä½³æ¨¡å‹
        metric_for_best_model="wer",       # ä½¿ç”¨ WER ä½œç‚ºè©•ä¼°æŒ‡æ¨™
        greater_is_better=False,           # WER è¶Šå°è¶Šå¥½
        
        # ç¡¬é«”è¨­å®š
        fp16=True,                         # ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ (åŠ é€Ÿ+çœè¨˜æ†¶é«”)
        dataloader_num_workers=32,          # è³‡æ–™è¼‰å…¥åŸ·è¡Œç·’æ•¸
        
        # å…¶ä»–
        predict_with_generate=True,        # è©•ä¼°æ™‚ä½¿ç”¨ç”Ÿæˆæ¨¡å¼
        generation_max_length=225,         # ç”Ÿæˆæœ€å¤§é•·åº¦
        push_to_hub=False,                 # ä¸ä¸Šå‚³åˆ° HuggingFace Hub
    )
    ```
    è³‡æ–™ç‚ºåŸå§‹è³‡æ–™+åŸå§‹è³‡æ–™ä½¿ç”¨è€å¸«çš„Data agg
    MDL = 8.13131
    - ç¬¬äºŒç‰ˆ:
    ```
    training_args = Seq2SeqTrainingArguments(
        # è¼¸å‡ºè¨­å®š
        output_dir="./whisper-taiwanese-finetuned-RawBoost",
        
        # è¨“ç·´è¨­å®š
        per_device_train_batch_size=8,      # âœ… æ¸›å°æ‰¹æ¬¡å¤§å° (æ›´ç©©å®š)
        per_device_eval_batch_size=8,
        gradient_accumulation_steps=2,      # âœ… å¢åŠ æ¢¯åº¦ç´¯ç© (æœ‰æ•ˆ batch=16)
        
        # âœ… æ¢¯åº¦è£å‰ª (é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œæœ€é‡è¦ï¼)
        max_grad_norm=1.0,
        
        # å­¸ç¿’ç‡è¨­å®š
        learning_rate=5e-6,                 # âœ… é™ä½å­¸ç¿’ç‡ (æ›´ç©©å®š)
        warmup_steps=500,                   # âœ… å¢åŠ  warmup (æ›´å¹³æ»‘)
        lr_scheduler_type="cosine",         # âœ… ä½¿ç”¨é¤˜å¼¦å­¸ç¿’ç‡è¡°æ¸›
        weight_decay=0.01,                  # âœ… L2 æ­£å‰‡åŒ–
        
        # è¨“ç·´è¼ªæ•¸
        num_train_epochs=5,
        
        # è©•ä¼°èˆ‡å„²å­˜
        eval_strategy="steps",              # æ¯ N æ­¥è©•ä¼°ä¸€æ¬¡
        eval_steps=500,                     # æ¯ 500 æ­¥è©•ä¼°
        save_strategy="steps",              # æ¯ N æ­¥å„²å­˜
        save_steps=500,                     # æ¯ 500 æ­¥å„²å­˜
        save_total_limit=3,                 # åªä¿ç•™æœ€æ–° 3 å€‹ checkpoint
        
        # è¨˜éŒ„è¨­å®š
        logging_steps=50,                   # âœ… æ›´é »ç¹è¨˜éŒ„
        logging_dir="./logs",
        
        # æœ€ä½³æ¨¡å‹
        load_best_model_at_end=True,       # è¨“ç·´çµæŸè¼‰å…¥æœ€ä½³æ¨¡å‹
        metric_for_best_model="wer",       # ä½¿ç”¨ WER ä½œç‚ºè©•ä¼°æŒ‡æ¨™
        greater_is_better=False,           # WER è¶Šå°è¶Šå¥½
        
        # ç¡¬é«”è¨­å®š
        fp16=True,                         # ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ (åŠ é€Ÿ+çœè¨˜æ†¶é«”)
        dataloader_num_workers=32,          # è³‡æ–™è¼‰å…¥åŸ·è¡Œç·’æ•¸
        
        # å…¶ä»–
        predict_with_generate=True,        # è©•ä¼°æ™‚ä½¿ç”¨ç”Ÿæˆæ¨¡å¼
        generation_max_length=225,         # ç”Ÿæˆæœ€å¤§é•·åº¦
        push_to_hub=False,                 # ä¸ä¸Šå‚³åˆ° HuggingFace Hub
    )
    ```
    è³‡æ–™ç‚ºåŸå§‹è³‡æ–™+RawBoost 3å’Œ6(è³‡æ–™é‡è®Šæˆ3å€)
    MDL = 11.47474

 - ç¬¬ä¸‰ç‰ˆ:
    ```
        training_args = Seq2SeqTrainingArguments(
        # è¼¸å‡ºè¨­å®š
        output_dir="./whisper-taiwanese-finetuned-RawBoost",
        
        # è¨“ç·´è¨­å®š
        per_device_train_batch_size=8,      # âœ… æ¸›å°æ‰¹æ¬¡å¤§å° (æ›´ç©©å®š)
        per_device_eval_batch_size=8,
        gradient_accumulation_steps=2,      # âœ… å¢åŠ æ¢¯åº¦ç´¯ç© (æœ‰æ•ˆ batch=16)
        
        # âœ… æ¢¯åº¦è£å‰ª (é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œæœ€é‡è¦ï¼)
        max_grad_norm=1.0,
        
        # å­¸ç¿’ç‡è¨­å®š
        learning_rate=1e-5,                 # âœ… æé«˜å­¸ç¿’ç‡ (è³‡æ–™å¤šäº†ï¼Œå¯ä»¥å­¸æ›´å¿«)
        warmup_steps=1000,                  # âœ… å¢åŠ  warmup (æ­¥æ•¸æ›´å¤šéœ€è¦æ›´é•· warmup)
        lr_scheduler_type="cosine",         # âœ… ä½¿ç”¨é¤˜å¼¦å­¸ç¿’ç‡è¡°æ¸›
        weight_decay=0.01,                  # âœ… L2 æ­£å‰‡åŒ–
        
        # è¨“ç·´è¼ªæ•¸
        num_train_epochs=5,
        
        # è©•ä¼°èˆ‡å„²å­˜
        eval_strategy="steps",              # æ¯ N æ­¥è©•ä¼°ä¸€æ¬¡
        eval_steps=300,                     # âœ… æ›´é »ç¹è©•ä¼° (æ¯ 300 æ­¥ï¼Œç´„æ¯åŠå€‹ epoch)
        save_strategy="steps",              # æ¯ N æ­¥å„²å­˜
        save_steps=300,                     # âœ… æ›´é »ç¹å„²å­˜ (æ¯ 300 æ­¥)
        save_total_limit=5,                 # âœ… ä¿ç•™æœ€æ–° 5 å€‹ checkpoint (è¨“ç·´æ›´é•·)
        
        # è¨˜éŒ„è¨­å®š
        logging_steps=50,                   # âœ… æ›´é »ç¹è¨˜éŒ„
        logging_dir="./logs",
        
        # æœ€ä½³æ¨¡å‹
        load_best_model_at_end=True,       # è¨“ç·´çµæŸè¼‰å…¥æœ€ä½³æ¨¡å‹
        metric_for_best_model="wer",       # ä½¿ç”¨ WER ä½œç‚ºè©•ä¼°æŒ‡æ¨™
        greater_is_better=False,           # WER è¶Šå°è¶Šå¥½
        
        # ç¡¬é«”è¨­å®š
        fp16=True,                         # ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ (åŠ é€Ÿ+çœè¨˜æ†¶é«”)
        dataloader_num_workers=4,          # âœ… è³‡æ–™è¼‰å…¥åŸ·è¡Œç·’æ•¸
        
        # å…¶ä»–
        predict_with_generate=True,        # è©•ä¼°æ™‚ä½¿ç”¨ç”Ÿæˆæ¨¡å¼
        generation_max_length=225,         # ç”Ÿæˆæœ€å¤§é•·åº¦
        push_to_hub=False,                 # ä¸ä¸Šå‚³åˆ° HuggingFace Hub
    )
    ```
    è³‡æ–™ä½¿ç”¨è€å¸«çš„+RawBoost3å’Œ6ï¼Œç¸½å…±è³‡æ–™é‡ç‚º4å€
    MDL = 7.34343