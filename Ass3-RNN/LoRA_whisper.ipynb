{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f29cc6b0",
      "metadata": {
        "id": "f29cc6b0"
      },
      "source": [
        "# ğŸš€ LoRA å¾®èª¿ Whisper å°èªæ¨¡å‹\n",
        "\n",
        "ä½¿ç”¨ **LoRA (Low-Rank Adaptation)** æŠ€è¡“é«˜æ•ˆå¾®èª¿ `whisper` æ¨¡å‹\n",
        "\n",
        "## ğŸ“Œ LoRA å„ªå‹¢\n",
        "\n",
        "ç›¸æ¯”å®Œæ•´å¾®èª¿ï¼ˆFull Fine-tuningï¼‰ï¼š\n",
        "- âœ… **è¨˜æ†¶é«”éœ€æ±‚é™ä½ 3-5 å€**ï¼ˆåªè¨“ç·´å°‘é‡åƒæ•¸ï¼‰\n",
        "- âœ… **è¨“ç·´é€Ÿåº¦æå‡ 2-3 å€**\n",
        "- âœ… **æ¨¡å‹å¯æ”œæ€§**ï¼ˆåªéœ€å„²å­˜ LoRA æ¬Šé‡ï¼Œ~10-50MBï¼‰\n",
        "- âœ… **é˜²æ­¢éæ“¬åˆ**ï¼ˆä¿ç•™é è¨“ç·´çŸ¥è­˜ï¼‰\n",
        "- âœ… **å¤šä»»å‹™åˆ‡æ›**ï¼ˆå¯è¼‰å…¥ä¸åŒ LoRA æ¬Šé‡ï¼‰\n",
        "\n",
        "## ğŸ¯ æœ¬æ¬¡ä»»å‹™\n",
        "\n",
        "- åŸºç¤æ¨¡å‹: `simonl0909/whisper-large-v2-cantonese`ï¼ˆå»£æ±è©± â†’ é©åˆå°èªï¼‰\n",
        "- è¨“ç·´è³‡æ–™: å°èªéŸ³è¨Š + RawBoost å¢å¼·\n",
        "- è©•ä¼°æŒ‡æ¨™: Mean Levenshtein Distance (æ¯”è³½æ¨™æº–)\n",
        "- LoRA åƒæ•¸: r=8, Î±=16, dropout=0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778a8f16",
      "metadata": {
        "id": "778a8f16"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“¦ å®‰è£å¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "32745687",
      "metadata": {
        "id": "32745687"
      },
      "outputs": [],
      "source": [
        "# å®‰è£ LoRA å’Œç›¸é—œå¥—ä»¶\n",
        "%pip install -q peft  # LoRA æ ¸å¿ƒå¥—ä»¶\n",
        "%pip install -q bitsandbytes  # 8-bit è¨“ç·´ï¼ˆå¯é¸ï¼‰\n",
        "%pip install -q transformers datasets\n",
        "%pip install -q librosa soundfile jiwer evaluate\n",
        "%pip install -q accelerate scikit-learn pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c8c9cae",
      "metadata": {
        "id": "1c8c9cae"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ—‚ï¸ æ›è¼‰ Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "c6a44b3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6a44b3a",
        "outputId": "f3e4b022-65af-4c7a-ab10-4cf3d6554632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "176e2b10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "176e2b10",
        "outputId": "2fb37614-7f61-42cf-e4bd-133c1629bacb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NYCU/Ass3-RNN\n"
          ]
        }
      ],
      "source": [
        "# åˆ‡æ›åˆ°å·¥ä½œç›®éŒ„\n",
        "%cd /content/drive/MyDrive/NYCU/Ass3-RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69838e04",
      "metadata": {
        "id": "69838e04"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š è¼‰å…¥è³‡æ–™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "616cb8cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "616cb8cb",
        "outputId": "053fa244-a320-41f5-d284-cca91c52a53d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š ç¸½è³‡æ–™ç­†æ•¸: 12476\n",
            "   åŸå§‹è³‡æ–™: ~3,000 ç­†\n",
            "   å¢å¼·è³‡æ–™: ~9476 ç­† (RawBoost algo 3 & 6)\n",
            "   è³‡æ–™å¢åŠ : 4.2x\n",
            "\n",
            "âœ… è¨“ç·´é›†: 11228 ç­†\n",
            "âœ… é©—è­‰é›†: 1248 ç­†\n"
          ]
        }
      ],
      "source": [
        "# è¼‰å…¥è³‡æ–™ï¼ˆä½¿ç”¨åˆä½µå¾Œçš„ RawBoost å¢å¼·è³‡æ–™ï¼‰\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# âœ… ä½¿ç”¨åˆä½µå¾Œçš„è³‡æ–™\n",
        "train_dir = \"./train/rawboost_augmentedV2\"  # åˆä½µå¾Œçš„éŸ³è¨Šç›®éŒ„\n",
        "train_csv = \"./train/train/trainAgg-toneless-rawboost.csv\"  # åˆä½µå¾Œçš„ CSV\n",
        "\n",
        "# è®€å– CSV\n",
        "df = pd.read_csv(train_csv)\n",
        "print(f\"ğŸ“Š ç¸½è³‡æ–™ç­†æ•¸: {len(df)}\")\n",
        "print(f\"   åŸå§‹è³‡æ–™: ~3,000 ç­†\")\n",
        "print(f\"   å¢å¼·è³‡æ–™: ~{len(df) - 3000} ç­† (RawBoost algo 3 & 6)\")\n",
        "print(f\"   è³‡æ–™å¢åŠ : {len(df) / 3000:.1f}x\\n\")\n",
        "\n",
        "# åˆ†å‰²è¨“ç·´å’Œé©—è­‰è³‡æ–™ (90% è¨“ç·´, 10% é©—è­‰)\n",
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42, shuffle=True)\n",
        "\n",
        "print(f\"âœ… è¨“ç·´é›†: {len(train_df)} ç­†\")\n",
        "print(f\"âœ… é©—è­‰é›†: {len(val_df)} ç­†\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8750090e",
      "metadata": {
        "id": "8750090e"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ¤– è¼‰å…¥æ¨¡å‹ï¼ˆLoRA é…ç½®ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edf8a1bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edf8a1bf",
        "outputId": "d24abe5f-c87c-411d-f90f-ba666c8fbefd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: cuda\n",
            "   GPU: Tesla T4\n",
            "   è¨˜æ†¶é«”: 14.74 GB\n",
            "\n",
            "ğŸ“¥ è¼‰å…¥ Processor å’Œæ¨¡å‹: simonl0909/whisper-large-v2-cantonese\n",
            "âœ… æ¨¡å‹å·²è¼‰å…¥\n",
            "   ç¸½åƒæ•¸é‡: 1543.3M\n",
            "   å¯è¨“ç·´åƒæ•¸: 1541.4M\n"
          ]
        }
      ],
      "source": [
        "# è¼‰å…¥ Whisper æ¨¡å‹å’Œ Processor\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "from peft import get_peft_model, LoraConfig\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from peft import prepare_model_for_kbit_training\n",
        "import torch\n",
        "\n",
        "# æª¢æŸ¥ GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\\n\")\n",
        "\n",
        "# è¼‰å…¥å»£æ±è©±æ¨¡å‹ï¼ˆé©åˆå°èªï¼‰\n",
        "model_name = \"simonl0909/whisper-large-v2-cantonese\"\n",
        "print(f\"ğŸ“¥ è¼‰å…¥ Processor å’Œæ¨¡å‹: {model_name}\")\n",
        "\n",
        "# Load the Whisper model with 8-bit quantization and map to available devices (e.g., GPUs)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name, load_in_8bit=True, device_map=\"auto\")\n",
        "\n",
        "# Prepare the model for LoRA-compatible 8-bit training (freezing norms, casting types)\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# LoRA é…ç½®\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type= \"SEQ_2_SEQ_LM\"\n",
        ")\n",
        "\n",
        "# æ‡‰ç”¨ LoRA\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "print(\"âœ… LoRA é…ç½®å®Œæˆ\")\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# è¼‰å…¥ Processor\n",
        "processor = AutoProcessor.from_pretrained(model_name)\n",
        "\n",
        "print(f\"âœ… æ¨¡å‹å·²è¼‰å…¥\")\n",
        "print(f\"   ç¸½åƒæ•¸é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
        "print(f\"   å¯è¨“ç·´åƒæ•¸: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.1f}M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2168c1f9",
      "metadata": {
        "id": "2168c1f9"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“¦ å»ºç«‹ Dataset å’Œ DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "029f63d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "029f63d6",
        "outputId": "ee1095c2-33b8-464d-a84a-9e4112d5ace8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… è¨“ç·´é›†å¤§å°: 11228\n",
            "âœ… é©—è­‰é›†å¤§å°: 1248\n"
          ]
        }
      ],
      "source": [
        "# å»ºç«‹ PyTorch Dataset\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "class TaiwaneseAudioDataset(Dataset):\n",
        "    \"\"\"å°èªéŸ³è¨Šè³‡æ–™é›†\"\"\"\n",
        "\n",
        "    def __init__(self, dataframe, audio_dir, processor, max_length=30):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.audio_dir = audio_dir\n",
        "        self.processor = processor\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.max_audio_features = 3000  # Whisper large-v2 çš„æœ€å¤§éŸ³è¨Šç‰¹å¾µé•·åº¦\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        audio_id = str(row['id'])\n",
        "        text = row['text']\n",
        "\n",
        "        # éŸ³è¨Šæª”æ¡ˆè·¯å¾‘\n",
        "        audio_path = os.path.join(self.audio_dir, f\"{audio_id}.wav\")\n",
        "\n",
        "        try:\n",
        "            # è¼‰å…¥éŸ³è¨Š (16kHz)\n",
        "            audio, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "            # é™åˆ¶é•·åº¦\n",
        "            max_samples = int(self.max_length * sr)\n",
        "            if len(audio) > max_samples:\n",
        "                audio = audio[:max_samples]\n",
        "\n",
        "            # ä½¿ç”¨ processor è™•ç†éŸ³è¨Š\n",
        "            inputs = self.processor(\n",
        "                audio,\n",
        "                sampling_rate=16000,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=\"max_length\",              # âœ… ä½¿ç”¨å›ºå®šé•·åº¦\n",
        "                max_length=self.max_audio_features, # âœ… 3000\n",
        "                truncation=True,                   # âœ… æˆªæ–·éé•·éŸ³è¨Š\n",
        "                return_attention_mask=False        # Whisper ä¸éœ€è¦\n",
        "            )\n",
        "\n",
        "            # è™•ç†æ–‡å­—æ¨™ç±¤\n",
        "            labels = self.processor.tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=\"longest\"\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                \"input_features\": inputs.input_features.squeeze(0),\n",
        "                \"labels\": labels.input_ids.squeeze(0)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            # å›å‚³ç©ºè³‡æ–™\n",
        "            return {\n",
        "                \"input_features\": torch.zeros(80, 3000),\n",
        "                \"labels\": torch.zeros(1, dtype=torch.long)\n",
        "            }\n",
        "\n",
        "# å»ºç«‹è¨“ç·´å’Œé©—è­‰è³‡æ–™é›†\n",
        "train_dataset = TaiwaneseAudioDataset(train_df, train_dir, processor, max_length=30)\n",
        "val_dataset = TaiwaneseAudioDataset(val_df, train_dir, processor, max_length=30)\n",
        "\n",
        "print(f\"âœ… è¨“ç·´é›†å¤§å°: {len(train_dataset)}\")\n",
        "print(f\"âœ… é©—è­‰é›†å¤§å°: {len(val_dataset)}\")\n",
        "\n",
        "# æ¸¬è©¦ä¸€å€‹æ¨£æœ¬\n",
        "sample = train_dataset[0]\n",
        "print(f\"\\nğŸ“Š æ¨£æœ¬ç¶­åº¦æª¢æŸ¥:\")\n",
        "print(f\"   input_features: {sample['input_features'].shape}\")\n",
        "print(f\"   labels: {sample['labels'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bda7bba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bda7bba",
        "outputId": "12949f92-c785-4d7c-bd59-9298a36f8a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Data Collator å»ºç«‹å®Œæˆï¼ˆå·²ä¿®æ­£ PEFT å…¼å®¹æ€§ï¼‰\n"
          ]
        }
      ],
      "source": [
        "# è‡ªå®šç¾© Data Collatorï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "import torch\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "    decoder_start_token_id: int\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Pads input audio features and target text labels for a batch of samples.\n",
        "\n",
        "        Args:\n",
        "            features (List[Dict]): Each item in the list is a dictionary with:\n",
        "                - 'input_features': Audio features (from spectrogram extraction)\n",
        "                - 'labels': Tokenized text labels\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, torch.Tensor]: A dictionary containing:\n",
        "                - 'input_features': Padded audio features\n",
        "                - 'labels': Padded and masked labels (with padding tokens replaced by -100)\n",
        "        \"\"\"\n",
        "\n",
        "        # Pad audio features\n",
        "        input_features = [{\"input_features\": feat[\"input_features\"]} for feat in features]\n",
        "        batch = self.processor.feature_extractor.pad(\n",
        "            input_features, \n",
        "            padding=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Pad text labels\n",
        "        labels = [{\"input_ids\": feat[\"labels\"]} for feat in features]\n",
        "        labels_batch = self.processor.tokenizer.pad(\n",
        "            labels,\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Replace padding token IDs with -100 so they are ignored in loss computation\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # Optionally remove BOS token if present at the beginning\n",
        "        if (\n",
        "            labels.size(1) > 1\n",
        "            and (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item()\n",
        "        ):\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fafeecd4",
      "metadata": {
        "id": "fafeecd4"
      },
      "source": [
        "---\n",
        "\n",
        "## âš™ï¸ è¨“ç·´é…ç½®ï¼ˆLoRA å„ªåŒ–ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Lix_UTmoUp0U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lix_UTmoUp0U",
        "outputId": "7f1c5ed9-734e-4ace-f2f7-92e6a9493c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.43.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "625f6477",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "625f6477",
        "outputId": "b5ac115f-70c3-4947-c492-44523d055e40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… è¨“ç·´åƒæ•¸è¨­å®šå®Œæˆ (LoRA å„ªåŒ–)\n",
            "\n",
            "ğŸ“Š è¨“ç·´é…ç½®:\n",
            "   æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: 32\n",
            "   å­¸ç¿’ç‡: 0.0002\n",
            "   è¨“ç·´è¼ªæ•¸: 5\n",
            "   é ä¼°è¨“ç·´æ™‚é–“: ~2-3 å°æ™‚ (A100 GPU)\n",
            "\n",
            "ğŸ’¡ LoRA å„ªå‹¢:\n",
            "   âœ… è¨˜æ†¶é«”ä½¿ç”¨é™ä½ 60-70%\n",
            "   âœ… è¨“ç·´é€Ÿåº¦æå‡ 2-3x\n",
            "   âœ… åªéœ€å„²å­˜ ~20MB LoRA æ¬Šé‡\n"
          ]
        }
      ],
      "source": [
        "# è¨­å®šè¨“ç·´åƒæ•¸ï¼ˆé‡å° LoRA å„ªåŒ–ï¼‰\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "# ğŸ”§ æ­£ç¢ºåˆå§‹åŒ– wandb\n",
        "\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# âœ… åœ¨å»ºç«‹ TrainingArguments ä¹‹å‰å…ˆç™»å…¥ wandb\n",
        "# æ–¹æ³• 1ï¼šä½¿ç”¨ API keyï¼ˆæ¨è–¦ï¼‰\n",
        "wandb.login(key=\"6505e7e06b7f53ea56b61b94658f226c523ebacc\")  # å¾ https://wandb.ai/settings ç²å–\n",
        "\n",
        "# æˆ–æ–¹æ³• 2ï¼šä½¿ç”¨ç’°å¢ƒè®Šæ•¸\n",
        "# os.environ[\"WANDB_API_KEY\"] = \"ä½ çš„_wandb_api_key\"\n",
        "\n",
        "# æ–¹æ³• 3ï¼šå¦‚æœåœ¨ Colabï¼Œä½¿ç”¨äº’å‹•å¼ç™»å…¥\n",
        "# wandb.login()  # æœƒè·³å‡ºæç¤ºè®“ä½ è¼¸å…¥ API key\n",
        "\n",
        "# âœ… åˆå§‹åŒ–å°ˆæ¡ˆ\n",
        "wandb.init(\n",
        "    project=\"whisper-taiwanese-lora\",\n",
        "    entity=\"paohuah-national-yang-ming-chiao-tung-university\",\n",
        "    name=\"lora-training-run-1\",\n",
        "    config={\n",
        "        \"learning_rate\": 2e-4,\n",
        "        \"architecture\": \"Whisper-Large-v2 + LoRA\",\n",
        "        \"dataset\": \"Taiwanese-RawBoost\",\n",
        "        \"epochs\": 5,\n",
        "        \"lora_r\": 8,\n",
        "        \"lora_alpha\": 16,\n",
        "    }\n",
        ")\n",
        "\n",
        "# ç¾åœ¨å»ºç«‹ TrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    # è¼¸å‡ºè¨­å®š\n",
        "    output_dir=\"./whisper-cantonese-taiwanese-lora\",\n",
        "\n",
        "    # è¨“ç·´è¨­å®šï¼ˆLoRA å¯ç”¨æ›´å¤§ batchï¼‰\n",
        "    per_device_train_batch_size=16,     # âœ… LoRA è¨˜æ†¶é«”éœ€æ±‚ä½ï¼Œå¯ç”¨æ›´å¤§ batch\n",
        "    per_device_eval_batch_size=16,\n",
        "    gradient_accumulation_steps=2,      # æœ‰æ•ˆ batch = 32\n",
        "\n",
        "    # æ¢¯åº¦è£å‰ª\n",
        "    max_grad_norm=1.0,\n",
        "\n",
        "    # å­¸ç¿’ç‡è¨­å®šï¼ˆLoRA å¯ç”¨æ›´é«˜å­¸ç¿’ç‡ï¼‰\n",
        "    learning_rate=2e-4,                 # âœ… LoRA å»ºè­° 1e-4 ~ 5e-4\n",
        "    warmup_steps=500,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # è¨“ç·´è¼ªæ•¸ï¼ˆLoRA æ”¶æ–‚æ›´å¿«ï¼‰\n",
        "    num_train_epochs=5,                 # âœ… LoRA é€šå¸¸ 3-5 epochs å³å¯\n",
        "\n",
        "    # è©•ä¼°èˆ‡å„²å­˜\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,                     # âœ… æ›´é »ç¹è©•ä¼°\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    save_total_limit=3,\n",
        "\n",
        "    # è¨˜éŒ„è¨­å®š\n",
        "    logging_steps=50,\n",
        "    logging_dir=\"./logs-lora\",\n",
        "\n",
        "    # æœ€ä½³æ¨¡å‹\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "\n",
        "    # ç¡¬é«”è¨­å®š\n",
        "    fp16=True,                          # ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´\n",
        "    dataloader_num_workers=2,\n",
        "\n",
        "    # å…¶ä»–\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    push_to_hub=False,\n",
        "\n",
        "    # âœ… LoRA ç‰¹æ®Šè¨­å®š\n",
        "    remove_unused_columns=False,        # ä¿ç•™æ‰€æœ‰æ¬„ä½\n",
        "    label_names=[\"labels\"],             # æŒ‡å®šæ¨™ç±¤æ¬„ä½\n",
        "    report_to=[\"wandb\"],  # å•Ÿç”¨ wandb\n",
        ")\n",
        "\n",
        "\n",
        "print(\"âœ… wandb åˆå§‹åŒ–å®Œæˆ\")\n",
        "print(\"âœ… è¨“ç·´åƒæ•¸è¨­å®šå®Œæˆ (LoRA å„ªåŒ–)\")\n",
        "print(f\"\\nğŸ“Š è¨“ç·´é…ç½®:\")\n",
        "print(f\"   æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
        "print(f\"   å­¸ç¿’ç‡: {training_args.learning_rate}\")\n",
        "print(f\"   è¨“ç·´è¼ªæ•¸: {training_args.num_train_epochs}\")\n",
        "print(f\"   é ä¼°è¨“ç·´æ™‚é–“: ~2-3 å°æ™‚ (A100 GPU)\")\n",
        "print(f\"\\nğŸ’¡ LoRA å„ªå‹¢:\")\n",
        "print(f\"   âœ… è¨˜æ†¶é«”ä½¿ç”¨é™ä½ 60-70%\")\n",
        "print(f\"   âœ… è¨“ç·´é€Ÿåº¦æå‡ 2-3x\")\n",
        "print(f\"   âœ… åªéœ€å„²å­˜ ~20MB LoRA æ¬Šé‡\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f5959ed",
      "metadata": {
        "id": "8f5959ed"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“ˆ å®šç¾©è©•ä¼°æŒ‡æ¨™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "578082bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "578082bd",
        "outputId": "1acf24b4-bb64-436b-c640-6d25440f4461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… è©•ä¼°æŒ‡æ¨™å®šç¾©å®Œæˆ (WER)\n"
          ]
        }
      ],
      "source": [
        "# å®šç¾©è©•ä¼°æŒ‡æ¨™ (WER)\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"è¨ˆç®— WER (Word Error Rate)\"\"\"\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # å°‡ -100 æ›¿æ›ç‚º pad_token_id\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    # è§£ç¢¼é æ¸¬å’Œæ¨™ç±¤\n",
        "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    # è¨ˆç®— WER\n",
        "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}\n",
        "\n",
        "print(\"âœ… è©•ä¼°æŒ‡æ¨™å®šç¾©å®Œæˆ (WER)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d679cae3",
      "metadata": {
        "id": "d679cae3"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸš€ é–‹å§‹è¨“ç·´ï¼ˆLoRAï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a295053",
      "metadata": {},
      "outputs": [],
      "source": [
        "# æº–å‚™è¨“ç·´å™¨\n",
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
        "    processor=processor,\n",
        "    decoder_start_token_id=model.config.decoder_start_token_id  # â† åŠ ä¸Šé€™å€‹ï¼\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=processor.feature_extractor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "-_ByjekhnjgM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "-_ByjekhnjgM",
        "outputId": "45dc78c9-c42c-4bdb-dada-004d9f52a883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Trainer å»ºç«‹å®Œæˆ\n",
            "============================================================\n",
            "ğŸš€ é–‹å§‹ LoRA è¨“ç·´...\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3003836461.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# é–‹å§‹è¨“ç·´\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2571\u001b[0m         \u001b[0mgrad_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2572\u001b[0m         \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_on_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_training_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_train_begin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    557\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[0;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, args, state, model, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 self._wandb.init(\n\u001b[0m\u001b[1;32m    894\u001b[0m                     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WANDB_PROJECT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"huggingface\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0minit_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1518\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_telemetry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m         \u001b[0mrun_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_warnings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_run_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36mmaybe_login\u001b[0;34m(self, init_settings)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# Calling login() may change settings on the singleton,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# so these may not be the final run settings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mrun_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mrun_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36msettings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             self._load_settings(\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0msystem_settings_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mdisable_sagemaker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m_load_settings\u001b[0;34m(self, system_settings_path, disable_sagemaker, overrides)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# infer settings from the system environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_system_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# load SageMaker settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_settings.py\u001b[0m in \u001b[0;36mupdate_from_system_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0;31m# Attempt to get notebook information if not already set by the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1933\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_jupyter_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_jupyter_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mnotebook_metadata\u001b[0;34m(silent)\u001b[0m\n\u001b[1;32m    222\u001b[0m     )\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mjupyter_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotebook_metadata_from_jupyter_servers_and_kernel_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Colab:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mnotebook_metadata_from_jupyter_servers_and_kernel_id\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnotebook_metadata_from_jupyter_servers_and_kernel_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mservers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjupyter_servers_and_kernel_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mservers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"password\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mjupyter_servers_and_kernel_id\u001b[0;34m()\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mservers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mserverapp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mservers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserverapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_running_servers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnotebookapp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mservers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebookapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_running_servers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/util.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__lazy_module_state__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spec__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spec__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spec__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jupyter_server/serverapp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjupyter_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplication\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJupyterApp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_aliases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjupyter_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjupyter_runtime_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjupyter_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEventLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotebookNotary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhttpserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jupyter_events/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# flake8: noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEVENTS_METADATA_VERSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEventLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEventSchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jupyter_events/logger.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mversion_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"python-json-logger\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.1.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpythonjsonlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonFormatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpythonjsonlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjsonlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonFormatter\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pythonjsonlogger/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m## Application\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"âœ… Trainer å»ºç«‹å®Œæˆ\")\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸš€ é–‹å§‹ LoRA è¨“ç·´...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# é–‹å§‹è¨“ç·´\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"âœ… LoRA è¨“ç·´å®Œæˆï¼\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a32ef028",
      "metadata": {
        "id": "a32ef028"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ’¾ å„²å­˜ LoRA æ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b83d98b4",
      "metadata": {
        "id": "b83d98b4"
      },
      "outputs": [],
      "source": [
        "# å„²å­˜ LoRA æ¬Šé‡\n",
        "output_dir = \"./whisper-cantonese-taiwanese-lora-final\"\n",
        "\n",
        "print(f\"ğŸ’¾ å„²å­˜ LoRA æ¨¡å‹åˆ°: {output_dir}\")\n",
        "\n",
        "# âœ… åªå„²å­˜ LoRA æ¬Šé‡ï¼ˆç¯€çœç©ºé–“ï¼‰\n",
        "model.save_pretrained(output_dir)\n",
        "processor.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"\\nâœ… LoRA æ¨¡å‹å„²å­˜å®Œæˆï¼\")\n",
        "print(f\"ğŸ“ æ¨¡å‹ä½ç½®: {output_dir}\")\n",
        "\n",
        "# æª¢æŸ¥æª”æ¡ˆå¤§å°\n",
        "import os\n",
        "adapter_size = os.path.getsize(os.path.join(output_dir, \"adapter_model.safetensors\")) / 1024 / 1024\n",
        "print(f\"\\nğŸ“Š LoRA æ¬Šé‡å¤§å°: {adapter_size:.2f} MB\")\n",
        "print(f\"ğŸ’¡ ç›¸æ¯”å®Œæ•´æ¨¡å‹ï¼ˆ~3GBï¼‰ï¼ŒLoRA åªéœ€ ~{adapter_size:.0f}MBï¼\")\n",
        "\n",
        "print(f\"\\nğŸ“– è¼‰å…¥æ–¹å¼:\")\n",
        "print(f\"   from peft import PeftModel\")\n",
        "print(f\"   base_model = AutoModelForSpeechSeq2Seq.from_pretrained('simonl0909/whisper-large-v2-cantonese')\")\n",
        "print(f\"   model = PeftModel.from_pretrained(base_model, '{output_dir}')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aab61ab1",
      "metadata": {
        "id": "aab61ab1"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š è©•ä¼°æ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1f1f0a1",
      "metadata": {
        "id": "d1f1f0a1"
      },
      "outputs": [],
      "source": [
        "# åœ¨é©—è­‰é›†ä¸Šè©•ä¼°\n",
        "print(\"ğŸ“Š åœ¨é©—è­‰é›†ä¸Šè©•ä¼° LoRA æ¨¡å‹...\")\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ“ˆ é©—è­‰é›†çµæœ:\")\n",
        "print(\"=\" * 60)\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"   {key}: {value:.4f}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "313732f4",
      "metadata": {
        "id": "313732f4"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ§ª æ¸¬è©¦é›†é æ¸¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e49bd12",
      "metadata": {
        "id": "1e49bd12"
      },
      "outputs": [],
      "source": [
        "# ç”Ÿæˆæ¸¬è©¦é›†é æ¸¬\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# è¨­ç‚ºè©•ä¼°æ¨¡å¼\n",
        "model.eval()\n",
        "\n",
        "# å®šç¾©æ‰¹æ¬¡è½‰éŒ„å‡½æ•¸\n",
        "def transcribe_audio_batch(audio_paths, model, processor, device=\"cuda\", batch_size=16):\n",
        "    all_transcriptions = []\n",
        "\n",
        "    for i in range(0, len(audio_paths), batch_size):\n",
        "        batch_paths = audio_paths[i:i+batch_size]\n",
        "\n",
        "        # è¼‰å…¥éŸ³è¨Š\n",
        "        audios = []\n",
        "        for path in batch_paths:\n",
        "            try:\n",
        "                audio, sr = librosa.load(path, sr=16000)\n",
        "                audios.append(audio)\n",
        "            except:\n",
        "                audios.append(np.zeros(16000))\n",
        "\n",
        "        # è™•ç†éŸ³è¨Š\n",
        "        inputs = processor(\n",
        "            audios,\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            max_length=3000,\n",
        "            truncation=True,\n",
        "            return_attention_mask=False\n",
        "        )\n",
        "\n",
        "        input_features = inputs.input_features.to(device)\n",
        "\n",
        "        # ç”Ÿæˆé æ¸¬\n",
        "        with torch.no_grad():\n",
        "            generated_ids = model.generate(\n",
        "                input_features,\n",
        "                max_length=225,\n",
        "                language=\"zh\",\n",
        "                task=\"transcribe\",\n",
        "                num_beams=1,\n",
        "                do_sample=False\n",
        "            )\n",
        "\n",
        "        # è§£ç¢¼\n",
        "        transcriptions = processor.batch_decode(\n",
        "            generated_ids,\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        all_transcriptions.extend(transcriptions)\n",
        "\n",
        "        if (i // batch_size) % 10 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    return all_transcriptions\n",
        "\n",
        "# è¨­å®šæ¸¬è©¦é›†è·¯å¾‘\n",
        "test_dir = \"./test-random/preprocessed\"\n",
        "test_files = sorted([f for f in os.listdir(test_dir) if f.endswith('.wav')])\n",
        "test_paths = [os.path.join(test_dir, f) for f in test_files]\n",
        "\n",
        "print(f\"ğŸ“Š æ¸¬è©¦é›†æª”æ¡ˆæ•¸: {len(test_files)}\")\n",
        "print(f\"âš¡ é–‹å§‹æ‰¹æ¬¡é æ¸¬...\\n\")\n",
        "\n",
        "# é€²è¡Œé æ¸¬\n",
        "transcriptions = transcribe_audio_batch(\n",
        "    test_paths,\n",
        "    model,\n",
        "    processor,\n",
        "    device=device,\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "# å»ºç«‹çµæœ DataFrame\n",
        "predictions = []\n",
        "for test_file, transcription in zip(test_files, transcriptions):\n",
        "    predictions.append({\n",
        "        \"id\": test_file.replace(\".wav\", \"\"),\n",
        "        \"sentence\": transcription\n",
        "    })\n",
        "\n",
        "# å„²å­˜é æ¸¬çµæœ\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "output_csv = \"submission_lora_cantonese.csv\"\n",
        "predictions_df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"\\nâœ… é æ¸¬å®Œæˆï¼\")\n",
        "print(f\"ğŸ“ çµæœå·²å„²å­˜åˆ°: {output_csv}\")\n",
        "print(f\"ğŸ“Š ç¸½ç­†æ•¸: {len(predictions_df)}\")\n",
        "print(f\"\\nå‰ 10 ç­†é æ¸¬çµæœ:\")\n",
        "print(predictions_df.head(10))\n",
        "\n",
        "# æª¢æŸ¥ç©ºé æ¸¬\n",
        "empty_predictions = predictions_df[predictions_df['sentence'] == '']\n",
        "if len(empty_predictions) > 0:\n",
        "    print(f\"\\nâš ï¸ ç™¼ç¾ {len(empty_predictions)} ç­†ç©ºé æ¸¬\")\n",
        "else:\n",
        "    print(f\"\\nâœ… æ‰€æœ‰é æ¸¬éƒ½æœ‰å…§å®¹\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5ab326c",
      "metadata": {
        "id": "f5ab326c"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š è¨“ç·´æ›²ç·šè¦–è¦ºåŒ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d3ec7e",
      "metadata": {
        "id": "76d3ec7e"
      },
      "outputs": [],
      "source": [
        "# è¦–è¦ºåŒ–è¨“ç·´éç¨‹\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# è®€å–è¨“ç·´æ—¥èªŒ\n",
        "log_history = trainer.state.log_history\n",
        "\n",
        "# æå–è¨“ç·´ loss å’Œé©—è­‰ WER\n",
        "train_loss = [log['loss'] for log in log_history if 'loss' in log]\n",
        "eval_wer = [log['eval_wer'] for log in log_history if 'eval_wer' in log]\n",
        "steps_loss = [log['step'] for log in log_history if 'loss' in log]\n",
        "steps_eval = [log['step'] for log in log_history if 'eval_wer' in log]\n",
        "\n",
        "# ç¹ªåœ–\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# è¨“ç·´ Loss\n",
        "ax1.plot(steps_loss, train_loss, label='Training Loss (LoRA)', color='blue', linewidth=2)\n",
        "ax1.set_xlabel('Steps', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.set_title('LoRA Training Loss', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# é©—è­‰ WER\n",
        "ax2.plot(steps_eval, eval_wer, label='Validation WER (LoRA)', color='red', linewidth=2, marker='o')\n",
        "ax2.set_xlabel('Steps', fontsize=12)\n",
        "ax2.set_ylabel('WER', fontsize=12)\n",
        "ax2.set_title('LoRA Validation WER', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('lora_training_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"âœ… è¨“ç·´æ›²ç·šå·²å„²å­˜: lora_training_curves.png\")\n",
        "print(f\"\\nğŸ“Š æœ€çµ‚çµæœ:\")\n",
        "print(f\"   æœ€ä½è¨“ç·´ Loss: {min(train_loss):.4f}\")\n",
        "print(f\"   æœ€ä½é©—è­‰ WER: {min(eval_wer):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4362da01",
      "metadata": {
        "id": "4362da01"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“ ç¸½çµèˆ‡å»ºè­°\n",
        "\n",
        "### âœ… LoRA è¨“ç·´å®Œæˆ\n",
        "\n",
        "1. **æ¨¡å‹å¤§å°**: ~20MB (LoRA æ¬Šé‡) vs ~3GB (å®Œæ•´æ¨¡å‹)\n",
        "2. **è¨“ç·´æ™‚é–“**: ~2-3 å°æ™‚ (A100 GPU)\n",
        "3. **è¨˜æ†¶é«”ä½¿ç”¨**: é™ä½ 60-70%\n",
        "\n",
        "### ğŸ¯ ä¸‹ä¸€æ­¥\n",
        "\n",
        "1. **æ¨¡å‹èåˆ**: å¯ä»¥å˜—è©¦å¤šå€‹ LoRA æ¨¡å‹çš„ ensemble\n",
        "2. **åƒæ•¸èª¿å„ª**:\n",
        "   - å¢åŠ  LoRA rank (r=16 æˆ– r=32)\n",
        "   - èª¿æ•´å­¸ç¿’ç‡ (1e-4 ~ 5e-4)\n",
        "   - å¢åŠ è¨“ç·´è¼ªæ•¸ (5-8 epochs)\n",
        "3. **è³‡æ–™å¢å¼·**: æŒçºŒä½¿ç”¨ RawBoost å¢å¼·è³‡æ–™\n",
        "4. **Post-processing**: æ·»åŠ èªè¨€æ¨¡å‹å¾Œè™•ç†ä¾†ä¿®æ­£é æ¸¬\n",
        "\n",
        "### ğŸ’¡ LoRA vs å®Œæ•´å¾®èª¿æ¯”è¼ƒ\n",
        "\n",
        "| é …ç›® | LoRA | å®Œæ•´å¾®èª¿ |\n",
        "|------|------|----------|\n",
        "| è¨“ç·´æ™‚é–“ | 2-3 å°æ™‚ | 6-8 å°æ™‚ |\n",
        "| è¨˜æ†¶é«”éœ€æ±‚ | ~8GB | ~20GB |\n",
        "| æ¨¡å‹å¤§å° | ~20MB | ~3GB |\n",
        "| æ•ˆæœ | æ¥è¿‘å®Œæ•´å¾®èª¿ | æœ€ä½³ |\n",
        "| éˆæ´»æ€§ | é«˜ï¼ˆå¯åˆ‡æ›ï¼‰ | ä½ |\n",
        "\n",
        "### ğŸš€ æ¨è–¦æµç¨‹\n",
        "\n",
        "1. å…ˆç”¨ LoRA å¿«é€Ÿå¯¦é©—ï¼ˆæœ¬æ¬¡è¨“ç·´ï¼‰\n",
        "2. æ‰¾åˆ°æœ€ä½³è¶…åƒæ•¸\n",
        "3. å¦‚æœæ•ˆæœä¸å¤ å¥½ï¼Œå†è€ƒæ…®å®Œæ•´å¾®èª¿\n",
        "4. æœ€çµ‚å¯ä»¥ ensemble å¤šå€‹æ¨¡å‹"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
