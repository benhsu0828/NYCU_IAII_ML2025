# ğŸ“ æ–¹æ¡ˆ 1: åŸºæ–¼è¨“ç·´é›†è©é »çš„æ‹¼å¯«ä¿®æ­£ï¼ˆæ¨è–¦ï¼‰

import pandas as pd
from collections import Counter
import re
from Levenshtein import distance as levenshtein_distance

# ==================== æ­¥é©Ÿ 1: å»ºç«‹è¨“ç·´é›†è©å½™è¡¨ ====================

print("ğŸ“š æ­¥é©Ÿ 1: å»ºç«‹è¨“ç·´é›†è©å½™è¡¨...")

# è®€å–è¨“ç·´é›†
train_csv = "./train/train/trainAgg-toneless.csv"
train_df = pd.read_csv(train_csv)

# æå–æ‰€æœ‰æ–‡å­—
all_texts = ' '.join(train_df['text'].astype(str))

# âœ… åˆ†è© æŒ‰ç©ºæ ¼åˆ†å‰²ï¼ˆå¦‚æœè¨“ç·´é›†æœ‰åˆ†è©ï¼‰
words = all_texts.split()

# çµ±è¨ˆè©é »
word_freq = Counter(words)

print(f"âœ… è©å½™è¡¨å¤§å°: {len(word_freq)}")
print(f"   ç¸½è©æ•¸: {sum(word_freq.values())}")
print(f"\nå‰ 20 å€‹é«˜é »å­—:")
for word, freq in word_freq.most_common(20):
    print(f"   '{word}': {freq} æ¬¡")

# ==================== æ­¥é©Ÿ 2: å®šç¾©æ‹¼å¯«ä¿®æ­£å‡½æ•¸ ====================

def get_candidates(word, word_freq, max_distance=2):
    """
    å–å¾—å€™é¸ä¿®æ­£è©ï¼ˆåŸºæ–¼ç·¨è¼¯è·é›¢ï¼‰
    
    Args:
        word: å¾…ä¿®æ­£çš„è©
        word_freq: è©é »å­—å…¸
        max_distance: æœ€å¤§ç·¨è¼¯è·é›¢
    
    Returns:
        å€™é¸è©åˆ—è¡¨ [(å€™é¸è©, ç·¨è¼¯è·é›¢, è©é »)]
    """
    candidates = []
    
    for vocab_word, freq in word_freq.items():
        dist = levenshtein_distance(word, vocab_word)
        if dist <= max_distance and dist > 0:  # âœ… æ’é™¤åŸè©
            candidates.append((vocab_word, dist, freq))
    
    # æŒ‰å„ªå…ˆç´šæ’åºï¼šç·¨è¼¯è·é›¢è¶Šå°è¶Šå¥½ï¼Œè©é »è¶Šé«˜è¶Šå¥½
    candidates.sort(key=lambda x: (x[1], -x[2]))
    
    return candidates

def correct_word(word, word_freq, threshold=2):
    """
    ä¿®æ­£å–®å€‹è©
    
    Args:
        word: å¾…ä¿®æ­£çš„è©
        word_freq: è©é »å­—å…¸
        threshold: ç·¨è¼¯è·é›¢é–¾å€¼
    
    Returns:
        ä¿®æ­£å¾Œçš„è©
    """
    # å¦‚æœè©åœ¨è©å½™è¡¨ä¸­ï¼Œç›´æ¥è¿”å›
    if word in word_freq:
        return word
    
    # å–å¾—å€™é¸è©
    candidates = get_candidates(word, word_freq, max_distance=threshold)
    
    # å¦‚æœæœ‰å€™é¸è©ï¼Œè¿”å›æœ€ä½³å€™é¸
    if candidates:
        best_candidate = candidates[0][0]
        return best_candidate
    
    # æ²’æœ‰å€™é¸è©ï¼Œè¿”å›åŸè©
    return word

def correct_sentence(sentence, word_freq, threshold=2):
    """
    ä¿®æ­£æ•´å€‹å¥å­
    
    Args:
        sentence: å¾…ä¿®æ­£çš„å¥å­
        word_freq: è©é »å­—å…¸
        threshold: ç·¨è¼¯è·é›¢é–¾å€¼
    
    Returns:
        ä¿®æ­£å¾Œçš„å¥å­
    """
    # âœ… æ–¹æ³• 1: æŒ‰å­—å…ƒä¿®æ­£ï¼ˆå°èªå¸¸è¦‹ï¼‰
    words = list(sentence.replace(' ', ''))
    
    # âœ… æ–¹æ³• 2: æŒ‰ç©ºæ ¼ä¿®æ­£ï¼ˆå¦‚æœæœ‰åˆ†è©ï¼‰
    # words = sentence.split()
    
    corrected_words = [correct_word(word, word_freq, threshold) for word in words]
    
    # âœ… æ–¹æ³• 1: ä¸åŠ ç©ºæ ¼ï¼ˆå°èªå¸¸è¦‹ï¼‰
    return ''.join(corrected_words)
    
    # âœ… æ–¹æ³• 2: åŠ ç©ºæ ¼ï¼ˆå¦‚æœæœ‰åˆ†è©ï¼‰
    # return ' '.join(corrected_words)

print("âœ… æ‹¼å¯«ä¿®æ­£å‡½æ•¸å®šç¾©å®Œæˆ")

# ==================== æ­¥é©Ÿ 3: ä¿®æ­£æ¸¬è©¦é›†é æ¸¬çµæœ ====================

print("\nğŸ“ æ­¥é©Ÿ 3: ä¿®æ­£æ¸¬è©¦é›†é æ¸¬çµæœ...")

# è®€å–é æ¸¬çµæœ
submission_csv = "submission_JacobLinCool.csv"
predictions_df = pd.read_csv(submission_csv)

print(f"ğŸ“Š åŸå§‹é æ¸¬ç­†æ•¸: {len(predictions_df)}")

# ä¿®æ­£æ¯å€‹é æ¸¬
corrected_sentences = []
correction_count = 0

for idx, row in predictions_df.iterrows():
    original_sentence = row['sentence']
    corrected_sentence = correct_sentence(original_sentence, word_freq, threshold=2)
    
    corrected_sentences.append(corrected_sentence)
    
    # çµ±è¨ˆä¿®æ­£æ¬¡æ•¸
    if original_sentence != corrected_sentence:
        correction_count += 1
        if correction_count <= 10:  # é¡¯ç¤ºå‰ 10 å€‹ä¿®æ­£ç¯„ä¾‹
            print(f"\nä¿®æ­£ç¯„ä¾‹ {correction_count}:")
            print(f"   åŸå§‹: {original_sentence}")
            print(f"   ä¿®æ­£: {corrected_sentence}")

# æ›´æ–° DataFrame
predictions_df['sentence'] = corrected_sentences

# ==================== æ­¥é©Ÿ 4: å„²å­˜ä¿®æ­£å¾Œçš„çµæœ ====================

corrected_csv = submission_csv + "_corrected.csv"
predictions_df.to_csv(corrected_csv, index=False)

print(f"\n{'='*60}")
print(f"âœ… æ‹¼å¯«ä¿®æ­£å®Œæˆï¼")
print(f"{'='*60}")
print(f"ğŸ“Š çµ±è¨ˆ:")
print(f"   ç¸½ç­†æ•¸: {len(predictions_df)}")
print(f"   ä¿®æ­£ç­†æ•¸: {correction_count}")
print(f"   ä¿®æ­£æ¯”ä¾‹: {correction_count / len(predictions_df) * 100:.2f}%")
print(f"\nğŸ’¾ è¼¸å‡ºæª”æ¡ˆ:")
print(f"   åŸå§‹: {submission_csv}")
print(f"   ä¿®æ­£: {corrected_csv}")
print(f"{'='*60}")